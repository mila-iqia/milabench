Training with a single process on 1 device (cuda:0).
Model resnet152 created, param count:60192808
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.95
	crop_mode: center
Learning rate (0.1) calculated from base learning rate (0.1) and global batch size (256) with linear scaling.
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/16 (  0%)]  Loss: 6.929 (6.93)  Time: 11.209s,   22.84/s  (11.209s,   22.84/s)  LR: 1.000e-05  Data: 1.321 (1.321)
Train: 0 [  15/16 (100%)]  Loss: 6.934 (6.94)  Time: 0.359s,  712.33/s  (1.071s,  239.13/s)  LR: 1.000e-05  Data: 0.000 (0.092)
Test: [   0/16]  Time: 1.406 (1.406)  Loss:  6.9339 (6.9339)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.891 (0.325)  Loss:  6.8981 (6.9128)  Acc@1:  0.0000 ( 0.1453)  Acc@5: 28.1250 ( 0.5329)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D3/20230510-140206-resnet152-224/checkpoint-0.pth.tar', 0.14534883720930233)

Train: 1 [   0/16 (  0%)]  Loss: 6.964 (6.96)  Time: 1.700s,  150.57/s  (1.700s,  150.57/s)  LR: 2.001e-02  Data: 1.065 (1.065)
Train: 1 [  15/16 (100%)]  Loss: 6.978 (6.92)  Time: 0.360s,  710.91/s  (0.453s,  565.14/s)  LR: 2.001e-02  Data: 0.000 (0.076)
Test: [   0/16]  Time: 1.219 (1.219)  Loss:  6.8471 (6.8471)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.018 (0.260)  Loss:  6.5640 (6.8342)  Acc@1: 18.7500 ( 0.2422)  Acc@5: 28.1250 ( 1.2355)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D3/20230510-140206-resnet152-224/checkpoint-1.pth.tar', 0.24224806201550386)

Train: 2 [   0/16 (  0%)]  Loss: 6.832 (6.83)  Time: 1.443s,  177.43/s  (1.443s,  177.43/s)  LR: 4.001e-02  Data: 1.084 (1.084)
Train: 2 [  15/16 (100%)]  Loss: 6.938 (6.92)  Time: 0.359s,  712.28/s  (0.439s,  582.62/s)  LR: 4.001e-02  Data: 0.001 (0.077)
Test: [   0/16]  Time: 1.076 (1.076)  Loss:  6.8031 (6.8031)  Acc@1:  3.1250 ( 3.1250)  Acc@5:  3.1250 ( 3.1250)
Test: [  16/16]  Time: 0.016 (0.250)  Loss:  6.3638 (6.8030)  Acc@1:  0.0000 ( 0.1938)  Acc@5: 28.1250 ( 1.1143)
Train: 3 [   0/16 (  0%)]  Loss: 6.863 (6.86)  Time: 1.425s,  179.63/s  (1.425s,  179.63/s)  LR: 6.000e-02  Data: 1.066 (1.066)
Train: 3 [  15/16 (100%)]  Loss: 7.023 (6.96)  Time: 0.358s,  714.75/s  (0.435s,  589.16/s)  LR: 6.000e-02  Data: 0.000 (0.076)
Test: [   0/16]  Time: 1.091 (1.091)  Loss:  6.8906 (6.8906)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.249)  Loss:  6.3048 (6.8152)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  6.2500 ( 1.1386)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D3/20230510-140206-resnet152-224/checkpoint-3.pth.tar', 0.26647286821705424)

Train: 4 [   0/16 (  0%)]  Loss: 6.879 (6.88)  Time: 1.413s,  181.23/s  (1.413s,  181.23/s)  LR: 8.000e-02  Data: 1.053 (1.053)
Train: 4 [  15/16 (100%)]  Loss: 7.048 (7.00)  Time: 0.359s,  713.35/s  (0.435s,  589.14/s)  LR: 8.000e-02  Data: 0.000 (0.075)
Test: [   0/16]  Time: 1.060 (1.060)  Loss:  6.8300 (6.8300)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.020 (0.249)  Loss:  6.4835 (6.8438)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  0.0000 ( 1.3081)
Train: 5 [   0/16 (  0%)]  Loss: 6.868 (6.87)  Time: 1.510s,  169.51/s  (1.510s,  169.51/s)  LR: 9.993e-02  Data: 1.144 (1.144)
Train: 5 [  15/16 (100%)]  Loss: 7.096 (7.04)  Time: 0.360s,  711.24/s  (0.440s,  581.77/s)  LR: 9.993e-02  Data: 0.000 (0.080)
Test: [   0/16]  Time: 1.062 (1.062)  Loss:  6.8760 (6.8760)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  1.5625 ( 1.5625)
Test: [  16/16]  Time: 0.018 (0.247)  Loss:  6.2184 (6.8704)  Acc@1:  0.0000 ( 0.1453)  Acc@5:  3.1250 ( 1.0417)
Train: 6 [   0/16 (  0%)]  Loss: 6.910 (6.91)  Time: 1.418s,  180.58/s  (1.418s,  180.58/s)  LR: 9.990e-02  Data: 1.059 (1.059)
Train: 6 [  15/16 (100%)]  Loss: 7.142 (7.04)  Time: 0.361s,  710.06/s  (0.434s,  589.35/s)  LR: 9.990e-02  Data: 0.000 (0.075)
Test: [   0/16]  Time: 1.048 (1.048)  Loss:  6.8120 (6.8120)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.018 (0.248)  Loss:  6.4640 (6.8707)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  0.0000 ( 1.1143)
Train: 7 [   0/16 (  0%)]  Loss: 6.866 (6.87)  Time: 1.417s,  180.71/s  (1.417s,  180.71/s)  LR: 9.987e-02  Data: 1.056 (1.056)
Train: 7 [  15/16 (100%)]  Loss: 7.057 (7.01)  Time: 0.362s,  707.42/s  (0.435s,  588.99/s)  LR: 9.987e-02  Data: 0.000 (0.075)
Test: [   0/16]  Time: 1.049 (1.049)  Loss:  6.7949 (6.7949)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.3906 ( 0.3906)
Test: [  16/16]  Time: 0.017 (0.248)  Loss:  6.4786 (6.8464)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  3.1250 ( 0.9932)
Train: 8 [   0/16 (  0%)]  Loss: 6.894 (6.89)  Time: 1.447s,  176.90/s  (1.447s,  176.90/s)  LR: 9.982e-02  Data: 1.087 (1.087)
Train: 8 [  15/16 (100%)]  Loss: 7.043 (6.96)  Time: 0.361s,  710.08/s  (0.439s,  582.96/s)  LR: 9.982e-02  Data: 0.000 (0.079)
Test: [   0/16]  Time: 1.064 (1.064)  Loss:  6.7872 (6.7872)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.018 (0.264)  Loss:  6.5607 (6.8259)  Acc@1:  0.0000 ( 0.1453)  Acc@5:  0.0000 ( 0.9205)
Train: 9 [   0/16 (  0%)]  Loss: 6.900 (6.90)  Time: 1.419s,  180.43/s  (1.419s,  180.43/s)  LR: 9.978e-02  Data: 1.058 (1.058)
Train: 9 [  15/16 (100%)]  Loss: 6.998 (6.93)  Time: 0.360s,  712.03/s  (0.437s,  586.11/s)  LR: 9.978e-02  Data: 0.001 (0.077)
Test: [   0/16]  Time: 1.080 (1.080)  Loss:  6.7893 (6.7893)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.3906 ( 0.3906)
Test: [  16/16]  Time: 0.018 (0.254)  Loss:  6.3837 (6.8087)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  3.1250 ( 1.2112)
Train: 10 [   0/16 (  0%)]  Loss: 6.833 (6.83)  Time: 1.421s,  180.20/s  (1.421s,  180.20/s)  LR: 9.973e-02  Data: 1.060 (1.060)
