Training with a single process on 1 device (cuda:0).
Model resnet152 created, param count:60192808
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.95
	crop_mode: center
Learning rate (0.1) calculated from base learning rate (0.1) and global batch size (256) with linear scaling.
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/16 (  0%)]  Loss: 6.929 (6.93)  Time: 11.399s,   22.46/s  (11.399s,   22.46/s)  LR: 1.000e-05  Data: 1.348 (1.348)
Train: 0 [  15/16 (100%)]  Loss: 6.934 (6.94)  Time: 0.359s,  712.17/s  (1.084s,  236.23/s)  LR: 1.000e-05  Data: 0.000 (0.094)
Test: [   0/16]  Time: 1.503 (1.503)  Loss:  6.9339 (6.9339)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.907 (0.337)  Loss:  6.8981 (6.9128)  Acc@1:  0.0000 ( 0.1453)  Acc@5: 28.1250 ( 0.5329)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D6/20230510-140206-resnet152-224/checkpoint-0.pth.tar', 0.14534883720930233)

Train: 1 [   0/16 (  0%)]  Loss: 6.964 (6.96)  Time: 1.770s,  144.67/s  (1.770s,  144.67/s)  LR: 2.001e-02  Data: 1.090 (1.090)
Train: 1 [  15/16 (100%)]  Loss: 6.978 (6.92)  Time: 0.362s,  707.32/s  (0.460s,  556.41/s)  LR: 2.001e-02  Data: 0.001 (0.078)
Test: [   0/16]  Time: 1.273 (1.273)  Loss:  6.8471 (6.8471)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.018 (0.266)  Loss:  6.5640 (6.8342)  Acc@1: 18.7500 ( 0.2422)  Acc@5: 28.1250 ( 1.2355)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D6/20230510-140206-resnet152-224/checkpoint-1.pth.tar', 0.24224806201550386)

Train: 2 [   0/16 (  0%)]  Loss: 6.832 (6.83)  Time: 1.564s,  163.65/s  (1.564s,  163.65/s)  LR: 4.001e-02  Data: 1.180 (1.180)
Train: 2 [  15/16 (100%)]  Loss: 6.938 (6.92)  Time: 0.366s,  698.64/s  (0.451s,  567.21/s)  LR: 4.001e-02  Data: 0.000 (0.085)
Test: [   0/16]  Time: 1.090 (1.090)  Loss:  6.8031 (6.8031)  Acc@1:  3.1250 ( 3.1250)  Acc@5:  3.1250 ( 3.1250)
Test: [  16/16]  Time: 0.017 (0.252)  Loss:  6.3638 (6.8030)  Acc@1:  0.0000 ( 0.1938)  Acc@5: 28.1250 ( 1.1143)
Train: 3 [   0/16 (  0%)]  Loss: 6.863 (6.86)  Time: 1.492s,  171.58/s  (1.492s,  171.58/s)  LR: 6.000e-02  Data: 1.130 (1.130)
Train: 3 [  15/16 (100%)]  Loss: 7.023 (6.96)  Time: 0.363s,  705.48/s  (0.442s,  579.19/s)  LR: 6.000e-02  Data: 0.001 (0.080)
Test: [   0/16]  Time: 1.099 (1.099)  Loss:  6.8906 (6.8906)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.019 (0.252)  Loss:  6.3048 (6.8152)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  6.2500 ( 1.1386)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D6/20230510-140206-resnet152-224/checkpoint-3.pth.tar', 0.26647286821705424)

Train: 4 [   0/16 (  0%)]  Loss: 6.879 (6.88)  Time: 1.524s,  168.01/s  (1.524s,  168.01/s)  LR: 8.000e-02  Data: 1.142 (1.142)
Train: 4 [  15/16 (100%)]  Loss: 7.048 (7.00)  Time: 0.364s,  704.23/s  (0.444s,  576.20/s)  LR: 8.000e-02  Data: 0.001 (0.081)
Test: [   0/16]  Time: 1.106 (1.106)  Loss:  6.8300 (6.8300)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.020 (0.252)  Loss:  6.4835 (6.8438)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  0.0000 ( 1.3081)
Train: 5 [   0/16 (  0%)]  Loss: 6.868 (6.87)  Time: 1.561s,  164.05/s  (1.561s,  164.05/s)  LR: 9.993e-02  Data: 1.177 (1.177)
Train: 5 [  15/16 (100%)]  Loss: 7.096 (7.04)  Time: 0.362s,  706.32/s  (0.446s,  573.65/s)  LR: 9.993e-02  Data: 0.001 (0.083)
Test: [   0/16]  Time: 1.073 (1.073)  Loss:  6.8760 (6.8760)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  1.5625 ( 1.5625)
Test: [  16/16]  Time: 0.018 (0.248)  Loss:  6.2184 (6.8704)  Acc@1:  0.0000 ( 0.1453)  Acc@5:  3.1250 ( 1.0417)
Train: 6 [   0/16 (  0%)]  Loss: 6.910 (6.91)  Time: 1.478s,  173.20/s  (1.478s,  173.20/s)  LR: 9.990e-02  Data: 1.094 (1.094)
Train: 6 [  15/16 (100%)]  Loss: 7.142 (7.04)  Time: 0.364s,  703.71/s  (0.442s,  579.00/s)  LR: 9.990e-02  Data: 0.000 (0.079)
Test: [   0/16]  Time: 1.127 (1.127)  Loss:  6.8120 (6.8120)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.018 (0.251)  Loss:  6.4640 (6.8707)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  0.0000 ( 1.1143)
Train: 7 [   0/16 (  0%)]  Loss: 6.866 (6.87)  Time: 1.466s,  174.66/s  (1.466s,  174.66/s)  LR: 9.987e-02  Data: 1.104 (1.104)
Train: 7 [  15/16 (100%)]  Loss: 7.057 (7.01)  Time: 0.361s,  708.84/s  (0.442s,  579.03/s)  LR: 9.987e-02  Data: 0.001 (0.080)
Test: [   0/16]  Time: 1.086 (1.086)  Loss:  6.7949 (6.7949)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.3906 ( 0.3906)
Test: [  16/16]  Time: 0.017 (0.251)  Loss:  6.4786 (6.8464)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  3.1250 ( 0.9932)
Train: 8 [   0/16 (  0%)]  Loss: 6.894 (6.89)  Time: 1.449s,  176.67/s  (1.449s,  176.67/s)  LR: 9.982e-02  Data: 1.085 (1.085)
Train: 8 [  15/16 (100%)]  Loss: 7.043 (6.96)  Time: 0.362s,  707.65/s  (0.444s,  576.47/s)  LR: 9.982e-02  Data: 0.000 (0.081)
Test: [   0/16]  Time: 1.086 (1.086)  Loss:  6.7872 (6.7872)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.259)  Loss:  6.5607 (6.8259)  Acc@1:  0.0000 ( 0.1453)  Acc@5:  0.0000 ( 0.9205)
Train: 9 [   0/16 (  0%)]  Loss: 6.900 (6.90)  Time: 1.473s,  173.80/s  (1.473s,  173.80/s)  LR: 9.978e-02  Data: 1.111 (1.111)
Train: 9 [  15/16 (100%)]  Loss: 6.998 (6.93)  Time: 0.363s,  705.28/s  (0.444s,  576.69/s)  LR: 9.978e-02  Data: 0.001 (0.081)
Test: [   0/16]  Time: 1.112 (1.112)  Loss:  6.7893 (6.7893)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.3906 ( 0.3906)
Test: [  16/16]  Time: 0.017 (0.254)  Loss:  6.3837 (6.8087)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  3.1250 ( 1.2112)
Train: 10 [   0/16 (  0%)]  Loss: 6.833 (6.83)  Time: 1.448s,  176.76/s  (1.448s,  176.76/s)  LR: 9.973e-02  Data: 1.087 (1.087)
