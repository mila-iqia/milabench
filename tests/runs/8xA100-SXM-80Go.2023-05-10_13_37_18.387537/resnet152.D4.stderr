Training with a single process on 1 device (cuda:0).
Model resnet152 created, param count:60192808
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.95
	crop_mode: center
Learning rate (0.1) calculated from base learning rate (0.1) and global batch size (256) with linear scaling.
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/16 (  0%)]  Loss: 6.929 (6.93)  Time: 10.970s,   23.34/s  (10.970s,   23.34/s)  LR: 1.000e-05  Data: 1.334 (1.334)
Train: 0 [  15/16 (100%)]  Loss: 6.934 (6.94)  Time: 0.359s,  713.81/s  (1.084s,  236.17/s)  LR: 1.000e-05  Data: 0.000 (0.094)
Test: [   0/16]  Time: 1.229 (1.229)  Loss:  6.9339 (6.9339)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.659 (0.295)  Loss:  6.8981 (6.9128)  Acc@1:  0.0000 ( 0.1453)  Acc@5: 28.1250 ( 0.5329)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D4/20230510-140206-resnet152-224/checkpoint-0.pth.tar', 0.14534883720930233)

Train: 1 [   0/16 (  0%)]  Loss: 6.964 (6.96)  Time: 1.489s,  171.87/s  (1.489s,  171.87/s)  LR: 2.001e-02  Data: 1.032 (1.032)
Train: 1 [  15/16 (100%)]  Loss: 6.978 (6.92)  Time: 0.359s,  713.13/s  (0.440s,  581.61/s)  LR: 2.001e-02  Data: 0.000 (0.074)
Test: [   0/16]  Time: 1.049 (1.049)  Loss:  6.8471 (6.8471)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.016 (0.256)  Loss:  6.5640 (6.8342)  Acc@1: 18.7500 ( 0.2422)  Acc@5: 28.1250 ( 1.2355)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D4/20230510-140206-resnet152-224/checkpoint-1.pth.tar', 0.24224806201550386)

Train: 2 [   0/16 (  0%)]  Loss: 6.832 (6.83)  Time: 1.419s,  180.37/s  (1.419s,  180.37/s)  LR: 4.001e-02  Data: 1.059 (1.059)
Train: 2 [  15/16 (100%)]  Loss: 6.938 (6.92)  Time: 0.361s,  709.30/s  (0.439s,  582.77/s)  LR: 4.001e-02  Data: 0.001 (0.076)
Test: [   0/16]  Time: 1.040 (1.040)  Loss:  6.8031 (6.8031)  Acc@1:  3.1250 ( 3.1250)  Acc@5:  3.1250 ( 3.1250)
Test: [  16/16]  Time: 0.017 (0.245)  Loss:  6.3638 (6.8030)  Acc@1:  0.0000 ( 0.1938)  Acc@5: 28.1250 ( 1.1143)
Train: 3 [   0/16 (  0%)]  Loss: 6.863 (6.86)  Time: 1.409s,  181.72/s  (1.409s,  181.72/s)  LR: 6.000e-02  Data: 1.048 (1.048)
Train: 3 [  15/16 (100%)]  Loss: 7.023 (6.96)  Time: 0.360s,  710.68/s  (0.438s,  584.56/s)  LR: 6.000e-02  Data: 0.000 (0.077)
Test: [   0/16]  Time: 1.040 (1.040)  Loss:  6.8906 (6.8906)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.246)  Loss:  6.3048 (6.8152)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  6.2500 ( 1.1386)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D4/20230510-140206-resnet152-224/checkpoint-3.pth.tar', 0.26647286821705424)

Train: 4 [   0/16 (  0%)]  Loss: 6.879 (6.88)  Time: 1.417s,  180.66/s  (1.417s,  180.66/s)  LR: 8.000e-02  Data: 1.056 (1.056)
Train: 4 [  15/16 (100%)]  Loss: 7.048 (7.00)  Time: 0.361s,  709.12/s  (0.436s,  586.78/s)  LR: 8.000e-02  Data: 0.000 (0.075)
Test: [   0/16]  Time: 1.104 (1.104)  Loss:  6.8300 (6.8300)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.244)  Loss:  6.4835 (6.8438)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  0.0000 ( 1.3081)
Train: 5 [   0/16 (  0%)]  Loss: 6.868 (6.87)  Time: 1.412s,  181.32/s  (1.412s,  181.32/s)  LR: 9.993e-02  Data: 1.049 (1.049)
Train: 5 [  15/16 (100%)]  Loss: 7.096 (7.04)  Time: 0.363s,  704.55/s  (0.440s,  582.38/s)  LR: 9.993e-02  Data: 0.001 (0.077)
Test: [   0/16]  Time: 1.030 (1.030)  Loss:  6.8760 (6.8760)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  1.5625 ( 1.5625)
Test: [  16/16]  Time: 0.018 (0.244)  Loss:  6.2184 (6.8704)  Acc@1:  0.0000 ( 0.1453)  Acc@5:  3.1250 ( 1.0417)
Train: 6 [   0/16 (  0%)]  Loss: 6.910 (6.91)  Time: 1.430s,  179.02/s  (1.430s,  179.02/s)  LR: 9.990e-02  Data: 1.067 (1.067)
Train: 6 [  15/16 (100%)]  Loss: 7.142 (7.04)  Time: 0.364s,  703.48/s  (0.438s,  583.98/s)  LR: 9.990e-02  Data: 0.000 (0.076)
Test: [   0/16]  Time: 1.033 (1.033)  Loss:  6.8120 (6.8120)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.019 (0.244)  Loss:  6.4640 (6.8707)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  0.0000 ( 1.1143)
Train: 7 [   0/16 (  0%)]  Loss: 6.866 (6.87)  Time: 1.416s,  180.80/s  (1.416s,  180.80/s)  LR: 9.987e-02  Data: 1.054 (1.054)
Train: 7 [  15/16 (100%)]  Loss: 7.057 (7.01)  Time: 0.362s,  706.91/s  (0.437s,  585.53/s)  LR: 9.987e-02  Data: 0.000 (0.075)
Test: [   0/16]  Time: 1.046 (1.046)  Loss:  6.7949 (6.7949)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.3906 ( 0.3906)
Test: [  16/16]  Time: 0.020 (0.244)  Loss:  6.4786 (6.8464)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  3.1250 ( 0.9932)
Train: 8 [   0/16 (  0%)]  Loss: 6.894 (6.89)  Time: 1.393s,  183.82/s  (1.393s,  183.82/s)  LR: 9.982e-02  Data: 1.031 (1.031)
Train: 8 [  15/16 (100%)]  Loss: 7.043 (6.96)  Time: 0.362s,  706.23/s  (0.436s,  586.87/s)  LR: 9.982e-02  Data: 0.000 (0.074)
Test: [   0/16]  Time: 1.027 (1.027)  Loss:  6.7872 (6.7872)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.243)  Loss:  6.5607 (6.8259)  Acc@1:  0.0000 ( 0.1453)  Acc@5:  0.0000 ( 0.9205)
Train: 9 [   0/16 (  0%)]  Loss: 6.900 (6.90)  Time: 1.592s,  160.84/s  (1.592s,  160.84/s)  LR: 9.978e-02  Data: 1.211 (1.211)
Train: 9 [  15/16 (100%)]  Loss: 6.998 (6.93)  Time: 0.363s,  705.94/s  (0.448s,  571.69/s)  LR: 9.978e-02  Data: 0.000 (0.085)
Test: [   0/16]  Time: 1.042 (1.042)  Loss:  6.7893 (6.7893)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.3906 ( 0.3906)
Test: [  16/16]  Time: 0.017 (0.244)  Loss:  6.3837 (6.8087)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  3.1250 ( 1.2112)
Train: 10 [   0/16 (  0%)]  Loss: 6.833 (6.83)  Time: 1.436s,  178.31/s  (1.436s,  178.31/s)  LR: 9.973e-02  Data: 1.074 (1.074)
