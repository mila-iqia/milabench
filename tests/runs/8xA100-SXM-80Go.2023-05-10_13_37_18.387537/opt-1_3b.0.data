{"event": "config", "data": {"dirs": {"base": "/Tmp/slurm.3188069.0/milabench_dev/results", "venv": "/Tmp/slurm.3188069.0/milabench_dev/results/venv/torch", "data": "/Tmp/slurm.3188069.0/milabench_dev/results/data", "runs": "/Tmp/slurm.3188069.0/milabench_dev/results/runs", "extra": "/Tmp/slurm.3188069.0/milabench_dev/results/extra/opt", "cache": "/Tmp/slurm.3188069.0/milabench_dev/results/cache"}, "arch": "cuda", "group": "opt", "install_group": "torch", "install_variant": "cuda", "run_name": "8xA100-SXM-80Go.2023-05-10_13:37:18.387537", "enabled": true, "capabilities": {"nodes": 1}, "max_duration": 600, "voir": {"options": {"stop": 60, "interval": "1s"}}, "config_base": "/Tmp/slurm.3188069.0/milabench_dev/milabench/config", "config_file": "/Tmp/slurm.3188069.0/milabench_dev/milabench/config/standard.yaml", "tags": ["huggingface", "language-modeling", "llm", "multigpu", "nlp", "transformer"], "definition": "/Tmp/slurm.3188069.0/milabench_dev/milabench/benchmarks/accelerate_opt", "plan": {"method": "njobs", "n": 1}, "manager_addr": "override-me", "manager_port": 10000, "cpus_per_gpu": 8, "gradient_accumulation_steps": 1, "max_train_steps": 100, "dataset_name": "wikitext", "dataset_config_name": "wikitext-103-v1", "validation_split_percentage": 5, "use_deepspeed": false, "num_machines": 1, "model_name": "facebook/opt-1.3b", "per_gpu_batch_size": 1, "weight": 5.0, "name": "opt-1_3b", "tag": ["opt-1_3b", "0"], "job-number": 0, "devices": ["0", "1", "2", "3", "4", "5", "6", "7"]}, "pipe": null}
{"event": "start", "data": {"command": ["accelerate", "launch", "--mixed_precision=fp16", "--dynamo_backend=no", "--machine_rank=0", "--num_machines=1", "--multi_gpu", "--gradient_accumulation_steps=1", "--num_cpu_threads_per_process=8", "--main_process_ip=override-me", "--main_process_port=10000", "--num_processes=8", "/Tmp/slurm.3188069.0/milabench_dev/milabench/benchmarks/accelerate_opt/main.py"], "time": 1683742631.467951}, "pipe": null}
{"event": "line", "data": "[05/10/23 14:18:22] INFO     [3/8] __main__ - Distributed environment: MULTI_GPU     logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Backend: nccl                                                        \n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 3                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 3                                               \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:3                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:22] INFO     [4/8] __main__ - Distributed environment: MULTI_GPU     logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Backend: nccl                                                        \n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 4                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 4                                               \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:4                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:22] INFO     [1/8] __main__ - Distributed environment: MULTI_GPU     logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Backend: nccl                                                        \n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 1                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 1                                               \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:1                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:22] INFO     [6/8] __main__ - Distributed environment: MULTI_GPU     logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Backend: nccl                                                        \n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 6                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 6                                               \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:6                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:22] INFO     [5/8] __main__ - Distributed environment: MULTI_GPU     logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Backend: nccl                                                        \n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 5                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 5                                               \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:5                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:22] INFO     [2/8] __main__ - Distributed environment: MULTI_GPU     logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Backend: nccl                                                        \n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 2                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 2                                               \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:2                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:22] INFO     [7/8] __main__ - Distributed environment: MULTI_GPU     logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Backend: nccl                                                        \n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 7                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 7                                               \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:7                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [3.0, 81251.1875], "load": 0, "temperature": 28}, "1": {"memory": [15.0, 81251.1875], "load": 0, "temperature": 27}, "2": {"memory": [15.0, 81251.1875], "load": 0, "temperature": 29}, "3": {"memory": [17.0, 81251.1875], "load": 0, "temperature": 28}, "4": {"memory": [18.0, 81251.1875], "load": 0.01, "temperature": 38}, "5": {"memory": [18.0, 81251.1875], "load": 0.01, "temperature": 37}, "6": {"memory": [24.0, 81251.1875], "load": 0.01, "temperature": 38}, "7": {"memory": [74.0, 81251.1875], "load": 0, "temperature": 37}}}, "pipe": "data"}
{"event": "line", "data": "[05/10/23 14:18:23] INFO     [0/8] __main__ - Distributed environment: MULTI_GPU     logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Backend: nccl                                                        \n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 0                                                     \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 0                                               \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:0                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                  \n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [986.0, 81251.1875], "load": 0, "temperature": 29}, "1": {"memory": [988.0, 81251.1875], "load": 0, "temperature": 28}, "2": {"memory": [988.0, 81251.1875], "load": 0, "temperature": 29}, "3": {"memory": [988.0, 81251.1875], "load": 0, "temperature": 28}, "4": {"memory": [988.0, 81251.1875], "load": 0, "temperature": 38}, "5": {"memory": [988.0, 81251.1875], "load": 0, "temperature": 37}, "6": {"memory": [988.0, 81251.1875], "load": 0, "temperature": 38}, "7": {"memory": [988.0, 81251.1875], "load": 0, "temperature": 37}}}, "pipe": "data"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "[05/10/23 14:18:30] WARNING  [0/8] datasets.builder - Found cached dataset wikitext builder.py:817\n", "pipe": "stdout"}
{"event": "line", "data": "                             (/Tmp/slurm.3188069.0/milabench_dev/results/cache/hugg               \n", "pipe": "stdout"}
{"event": "line", "data": "                             ingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db               \n", "pipe": "stdout"}
{"event": "line", "data": "                             52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646               \n", "pipe": "stdout"}
{"event": "line", "data": "                             a126)                                                                \n", "pipe": "stdout"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 97.47it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 104.80it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 161.26it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 160.23it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 130.67it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 150.57it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 149.18it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "loading configuration file config.json from cache at /Tmp/slurm.3188069.0/milabench_dev/results/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/config.json\n", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 156.32it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "Model config OPTConfig {\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_name_or_path\": \"facebook/opt-1.3b\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_remove_final_layer_norm\": false,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_function\": \"relu\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"architectures\": [\n", "pipe": "stderr"}
{"event": "line", "data": "    \"OPTForCausalLM\"\n", "pipe": "stderr"}
{"event": "line", "data": "  ],\n", "pipe": "stderr"}
{"event": "line", "data": "  \"attention_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"bos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"do_layer_norm_before\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"dropout\": 0.1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"enable_bias\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"eos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"ffn_dim\": 8192,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"hidden_size\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"init_std\": 0.02,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layer_norm_elementwise_affine\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layerdrop\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"max_position_embeddings\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"model_type\": \"opt\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_attention_heads\": 32,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_hidden_layers\": 24,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"pad_token_id\": 1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"prefix\": \"</s>\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"torch_dtype\": \"float16\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"transformers_version\": \"4.27.4\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"use_cache\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"vocab_size\": 50272,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"word_embed_proj_dim\": 2048\n", "pipe": "stderr"}
{"event": "line", "data": "}\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "loading configuration file config.json from cache at /Tmp/slurm.3188069.0/milabench_dev/results/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/config.json\n", "pipe": "stderr"}
{"event": "line", "data": "Model config OPTConfig {\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_name_or_path\": \"facebook/opt-1.3b\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_remove_final_layer_norm\": false,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_function\": \"relu\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"architectures\": [\n", "pipe": "stderr"}
{"event": "line", "data": "    \"OPTForCausalLM\"\n", "pipe": "stderr"}
{"event": "line", "data": "  ],\n", "pipe": "stderr"}
{"event": "line", "data": "  \"attention_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"bos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"do_layer_norm_before\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"dropout\": 0.1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"enable_bias\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"eos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"ffn_dim\": 8192,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"hidden_size\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"init_std\": 0.02,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layer_norm_elementwise_affine\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layerdrop\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"max_position_embeddings\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"model_type\": \"opt\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_attention_heads\": 32,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_hidden_layers\": 24,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"pad_token_id\": 1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"prefix\": \"</s>\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"torch_dtype\": \"float16\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"transformers_version\": \"4.27.4\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"use_cache\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"vocab_size\": 50272,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"word_embed_proj_dim\": 2048\n", "pipe": "stderr"}
{"event": "line", "data": "}\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "loading file vocab.json from cache at /Tmp/slurm.3188069.0/milabench_dev/results/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/vocab.json\n", "pipe": "stderr"}
{"event": "line", "data": "loading file merges.txt from cache at /Tmp/slurm.3188069.0/milabench_dev/results/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/merges.txt\n", "pipe": "stderr"}
{"event": "line", "data": "loading file tokenizer.json from cache at None\n", "pipe": "stderr"}
{"event": "line", "data": "loading file added_tokens.json from cache at None\n", "pipe": "stderr"}
{"event": "line", "data": "loading file special_tokens_map.json from cache at /Tmp/slurm.3188069.0/milabench_dev/results/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/special_tokens_map.json\n", "pipe": "stderr"}
{"event": "line", "data": "loading file tokenizer_config.json from cache at /Tmp/slurm.3188069.0/milabench_dev/results/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/tokenizer_config.json\n", "pipe": "stderr"}
{"event": "line", "data": "loading configuration file config.json from cache at /Tmp/slurm.3188069.0/milabench_dev/results/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/config.json\n", "pipe": "stderr"}
{"event": "line", "data": "Model config OPTConfig {\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_name_or_path\": \"facebook/opt-1.3b\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_remove_final_layer_norm\": false,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_function\": \"relu\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"architectures\": [\n", "pipe": "stderr"}
{"event": "line", "data": "    \"OPTForCausalLM\"\n", "pipe": "stderr"}
{"event": "line", "data": "  ],\n", "pipe": "stderr"}
{"event": "line", "data": "  \"attention_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"bos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"do_layer_norm_before\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"dropout\": 0.1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"enable_bias\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"eos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"ffn_dim\": 8192,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"hidden_size\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"init_std\": 0.02,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layer_norm_elementwise_affine\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layerdrop\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"max_position_embeddings\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"model_type\": \"opt\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_attention_heads\": 32,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_hidden_layers\": 24,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"pad_token_id\": 1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"prefix\": \"</s>\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"torch_dtype\": \"float16\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"transformers_version\": \"4.27.4\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"use_cache\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"vocab_size\": 50272,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"word_embed_proj_dim\": 2048\n", "pipe": "stderr"}
{"event": "line", "data": "}\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "loading configuration file config.json from cache at /Tmp/slurm.3188069.0/milabench_dev/results/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/config.json\n", "pipe": "stderr"}
{"event": "line", "data": "Model config OPTConfig {\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_name_or_path\": \"facebook/opt-1.3b\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_remove_final_layer_norm\": false,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_function\": \"relu\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"architectures\": [\n", "pipe": "stderr"}
{"event": "line", "data": "    \"OPTForCausalLM\"\n", "pipe": "stderr"}
{"event": "line", "data": "  ],\n", "pipe": "stderr"}
{"event": "line", "data": "  \"attention_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"bos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"do_layer_norm_before\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"dropout\": 0.1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"enable_bias\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"eos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"ffn_dim\": 8192,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"hidden_size\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"init_std\": 0.02,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layer_norm_elementwise_affine\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layerdrop\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"max_position_embeddings\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"model_type\": \"opt\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_attention_heads\": 32,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_hidden_layers\": 24,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"pad_token_id\": 1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"prefix\": \"</s>\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"torch_dtype\": \"float16\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"transformers_version\": \"4.27.4\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"use_cache\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"vocab_size\": 50272,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"word_embed_proj_dim\": 2048\n", "pipe": "stderr"}
{"event": "line", "data": "}\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "                    WARNING  [0/8] datasets.arrow_dataset - Loading cached   arrow_dataset.py:3110\n", "pipe": "stdout"}
{"event": "line", "data": "                             processed dataset at                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             /Tmp/slurm.3188069.0/milabench_dev/results/cach                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             e/huggingface/datasets/wikitext/wikitext-103-v1                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             /1.0.0/a241db52902eaf2c6aa732210bead40c090019a4                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             99ceb13bcbfa3f8ab646a126/cache-1b4e61c4f1ef8b68                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             _*_of_00008.arrow                                                    \n", "pipe": "stdout"}
{"event": "line", "data": "                    WARNING  [0/8] datasets.arrow_dataset - Loading cached   arrow_dataset.py:3110\n", "pipe": "stdout"}
{"event": "line", "data": "                             processed dataset at                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             /Tmp/slurm.3188069.0/milabench_dev/results/cach                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             e/huggingface/datasets/wikitext/wikitext-103-v1                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             /1.0.0/a241db52902eaf2c6aa732210bead40c090019a4                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             99ceb13bcbfa3f8ab646a126/cache-329331b01bd0468e                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             _*_of_00008.arrow                                                    \n", "pipe": "stdout"}
{"event": "line", "data": "                    WARNING  [0/8] datasets.arrow_dataset - Loading cached   arrow_dataset.py:3110\n", "pipe": "stdout"}
{"event": "line", "data": "                             processed dataset at                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             /Tmp/slurm.3188069.0/milabench_dev/results/cach                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             e/huggingface/datasets/wikitext/wikitext-103-v1                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             /1.0.0/a241db52902eaf2c6aa732210bead40c090019a4                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             99ceb13bcbfa3f8ab646a126/cache-c60b625823abbe78                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             _*_of_00008.arrow                                                    \n", "pipe": "stdout"}
{"event": "line", "data": "                    WARNING  [0/8] __main__ - The tokenizer picked seems to have a   logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             very large `model_max_length`                                        \n", "pipe": "stdout"}
{"event": "line", "data": "                             (1000000000000000019884624838656). Picking 1024                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             instead. You can change that default value by passing                \n", "pipe": "stdout"}
{"event": "line", "data": "                             --block_size xxx.                                                    \n", "pipe": "stdout"}
{"event": "line", "data": "                    WARNING  [0/8] datasets.arrow_dataset - Loading cached   arrow_dataset.py:3110\n", "pipe": "stdout"}
{"event": "line", "data": "                             processed dataset at                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             /Tmp/slurm.3188069.0/milabench_dev/results/cach                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             e/huggingface/datasets/wikitext/wikitext-103-v1                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             /1.0.0/a241db52902eaf2c6aa732210bead40c090019a4                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             99ceb13bcbfa3f8ab646a126/cache-87a845baeb5292f0                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             _*_of_00008.arrow                                                    \n", "pipe": "stdout"}
{"event": "line", "data": "                    WARNING  [0/8] datasets.arrow_dataset - Loading cached   arrow_dataset.py:3110\n", "pipe": "stdout"}
{"event": "line", "data": "                             processed dataset at                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             /Tmp/slurm.3188069.0/milabench_dev/results/cach                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             e/huggingface/datasets/wikitext/wikitext-103-v1                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             /1.0.0/a241db52902eaf2c6aa732210bead40c090019a4                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             99ceb13bcbfa3f8ab646a126/cache-23b43495f74434f7                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             _*_of_00008.arrow                                                    \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:31] WARNING  [0/8] datasets.arrow_dataset - Loading cached   arrow_dataset.py:3110\n", "pipe": "stdout"}
{"event": "line", "data": "                             processed dataset at                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             /Tmp/slurm.3188069.0/milabench_dev/results/cach                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             e/huggingface/datasets/wikitext/wikitext-103-v1                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             /1.0.0/a241db52902eaf2c6aa732210bead40c090019a4                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             99ceb13bcbfa3f8ab646a126/cache-7649aa6a833efa01                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             _*_of_00008.arrow                                                    \n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [1486.0, 81251.1875], "load": 0, "temperature": 29}, "1": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 28}, "2": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 29}, "3": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 28}, "4": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 38}, "5": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 37}, "6": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 38}, "7": {"memory": [1486.0, 81251.1875], "load": 0, "temperature": 37}}}, "pipe": "data"}
{"event": "line", "data": "Generate config GenerationConfig {\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_from_model_config\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"bos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"eos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"pad_token_id\": 1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"transformers_version\": \"4.27.4\"\n", "pipe": "stderr"}
{"event": "line", "data": "}\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [1486.0, 81251.1875], "load": 0, "temperature": 29}, "1": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 28}, "2": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 29}, "3": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 28}, "4": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 37}, "5": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 37}, "6": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 38}, "7": {"memory": [1486.0, 81251.1875], "load": 0, "temperature": 36}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [1486.0, 81251.1875], "load": 0, "temperature": 29}, "1": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 28}, "2": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 29}, "3": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 28}, "4": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 37}, "5": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 37}, "6": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 37}, "7": {"memory": [1486.0, 81251.1875], "load": 0, "temperature": 36}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [1486.0, 81251.1875], "load": 0, "temperature": 28}, "1": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 28}, "2": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 29}, "3": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 28}, "4": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 37}, "5": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 36}, "6": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 37}, "7": {"memory": [1486.0, 81251.1875], "load": 0, "temperature": 36}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [1486.0, 81251.1875], "load": 0, "temperature": 28}, "1": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 28}, "2": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 29}, "3": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 28}, "4": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 37}, "5": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 36}, "6": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 37}, "7": {"memory": [1486.0, 81251.1875], "load": 0, "temperature": 36}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [1486.0, 81251.1875], "load": 0, "temperature": 28}, "1": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 28}, "2": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 29}, "3": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 28}, "4": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 37}, "5": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 36}, "6": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 37}, "7": {"memory": [1486.0, 81251.1875], "load": 0, "temperature": 36}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [6508.0, 81251.1875], "load": 1.0, "temperature": 29}, "1": {"memory": [6652.0, 81251.1875], "load": 0.23, "temperature": 28}, "2": {"memory": [1630.0, 81251.1875], "load": 0, "temperature": 29}, "3": {"memory": [4346.0, 81251.1875], "load": 0.16, "temperature": 28}, "4": {"memory": [6092.0, 81251.1875], "load": 0.24, "temperature": 37}, "5": {"memory": [6652.0, 81251.1875], "load": 0.38, "temperature": 36}, "6": {"memory": [3578.0, 81251.1875], "load": 0.11, "temperature": 37}, "7": {"memory": [6508.0, 81251.1875], "load": 0.4, "temperature": 36}}}, "pipe": "data"}
{"event": "line", "data": "[05/10/23 14:18:53] INFO     [0/8] __main__ - ***** Running training *****           logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                    INFO     [0/8] __main__ -   Num examples = 115910                logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                    INFO     [0/8] __main__ -   Num Epochs = 1                       logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                    INFO     [0/8] __main__ -   Instantaneous batch size per device  logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             = 1                                                                  \n", "pipe": "stdout"}
{"event": "line", "data": "                    INFO     [0/8] __main__ -   Total train batch size (w. parallel, logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             distributed & accumulation) = 8                                      \n", "pipe": "stdout"}
{"event": "line", "data": "                    INFO     [0/8] __main__ -   Gradient Accumulation steps = 1      logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                    INFO     [0/8] __main__ -   Total optimization steps = 100       logging.py:47\n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [13454.0, 81251.1875], "load": 0.02, "temperature": 29}, "1": {"memory": [13610.0, 81251.1875], "load": 0.02, "temperature": 28}, "2": {"memory": [13618.0, 81251.1875], "load": 0.01, "temperature": 29}, "3": {"memory": [13576.0, 81251.1875], "load": 0.01, "temperature": 29}, "4": {"memory": [13626.0, 81251.1875], "load": 0.01, "temperature": 38}, "5": {"memory": [13638.0, 81251.1875], "load": 0.01, "temperature": 37}, "6": {"memory": [13646.0, 81251.1875], "load": 0.02, "temperature": 38}, "7": {"memory": [13508.0, 81251.1875], "load": 0.01, "temperature": 37}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 11.122532844543457}, "pipe": "data"}
{"event": "line", "data": "[05/10/23 14:18:57] INFO     [0/8] torch.nn.parallel.distributed - Reducer     distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "                             buckets have been rebuilt in this iteration.                         \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:57] INFO     [6/8] torch.nn.parallel.distributed - Reducer     distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "                             buckets have been rebuilt in this iteration.                         \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:57] INFO     [5/8] torch.nn.parallel.distributed - Reducer     distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "                             buckets have been rebuilt in this iteration.                         \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:57] INFO     [2/8] torch.nn.parallel.distributed - Reducer     distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "                             buckets have been rebuilt in this iteration.                         \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:57] INFO     [7/8] torch.nn.parallel.distributed - Reducer     distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "                             buckets have been rebuilt in this iteration.                         \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:57] INFO     [1/8] torch.nn.parallel.distributed - Reducer     distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "                             buckets have been rebuilt in this iteration.                         \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:57] INFO     [4/8] torch.nn.parallel.distributed - Reducer     distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "                             buckets have been rebuilt in this iteration.                         \n", "pipe": "stdout"}
{"event": "line", "data": "[05/10/23 14:18:57] INFO     [3/8] torch.nn.parallel.distributed - Reducer     distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "                             buckets have been rebuilt in this iteration.                         \n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [37848.0, 81251.1875], "load": 0, "temperature": 29}, "1": {"memory": [38154.0, 81251.1875], "load": 0, "temperature": 28}, "2": {"memory": [38160.0, 81251.1875], "load": 0, "temperature": 30}, "3": {"memory": [38160.0, 81251.1875], "load": 0, "temperature": 29}, "4": {"memory": [38160.0, 81251.1875], "load": 0, "temperature": 37}, "5": {"memory": [38160.0, 81251.1875], "load": 0, "temperature": 37}, "6": {"memory": [39056.0, 81251.1875], "load": 0.1, "temperature": 38}, "7": {"memory": [39424.0, 81251.1875], "load": 0.2, "temperature": 37}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.92843246459961}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.960206031799316}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.74958324432373}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.897795677185059}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 4.008304157012071, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.636249542236328}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.169405937194824}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.052301406860352}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.714323374745, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.787303924560547}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.711798667907715}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.587363243103027}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.58654353535179, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.40591812133789}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [43860.0, 81251.1875], "load": 0.92, "temperature": 38}, "1": {"memory": [44004.0, 81251.1875], "load": 0.96, "temperature": 36}, "2": {"memory": [44004.0, 81251.1875], "load": 0.97, "temperature": 39}, "3": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 37}, "4": {"memory": [44004.0, 81251.1875], "load": 0.9, "temperature": 46}, "5": {"memory": [44004.0, 81251.1875], "load": 0.96, "temperature": 45}, "6": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 46}, "7": {"memory": [43860.0, 81251.1875], "load": 0.98, "temperature": 46}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.528517723083496}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.529739379882812}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.796814072206164, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.536813735961914}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.233687400817871}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.004950523376465}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.7089053437068, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.138412475585938}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.372623443603516}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.392293930053711}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.48580464881706, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.11568832397461}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.140449523925781}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [43860.0, 81251.1875], "load": 0.98, "temperature": 39}, "1": {"memory": [44004.0, 81251.1875], "load": 0.99, "temperature": 37}, "2": {"memory": [44004.0, 81251.1875], "load": 0.96, "temperature": 40}, "3": {"memory": [44004.0, 81251.1875], "load": 0.89, "temperature": 38}, "4": {"memory": [44004.0, 81251.1875], "load": 0.86, "temperature": 47}, "5": {"memory": [44004.0, 81251.1875], "load": 0.82, "temperature": 47}, "6": {"memory": [44004.0, 81251.1875], "load": 0.83, "temperature": 48}, "7": {"memory": [43860.0, 81251.1875], "load": 0.98, "temperature": 46}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.442456245422363}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 24.830267761471475, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.140869140625}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.393256187438965}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.119144439697266}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.328222228875994, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.381292343139648}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 8.876993179321289}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.372840881347656}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.436602998065155, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 8.903997421264648}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.184161186218262}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.26639461517334}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.799081812396636, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.207894325256348}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [43860.0, 81251.1875], "load": 0.98, "temperature": 41}, "1": {"memory": [44004.0, 81251.1875], "load": 0.99, "temperature": 39}, "2": {"memory": [44004.0, 81251.1875], "load": 0.96, "temperature": 42}, "3": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 39}, "4": {"memory": [44004.0, 81251.1875], "load": 0.96, "temperature": 49}, "5": {"memory": [44004.0, 81251.1875], "load": 0.97, "temperature": 49}, "6": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 49}, "7": {"memory": [43860.0, 81251.1875], "load": 0.87, "temperature": 48}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.58532428741455}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.363105773925781}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.46580481426079, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.193947792053223}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.551831245422363}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.011130332946777}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.528365076635843, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.23448371887207}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 8.872147560119629}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.358460426330566}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.286313282792506, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.368824005126953}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.297222137451172}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [43860.0, 81251.1875], "load": 0.9, "temperature": 40}, "1": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 39}, "2": {"memory": [44004.0, 81251.1875], "load": 0.99, "temperature": 43}, "3": {"memory": [44004.0, 81251.1875], "load": 0.96, "temperature": 40}, "4": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 50}, "5": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 50}, "6": {"memory": [44004.0, 81251.1875], "load": 0.91, "temperature": 50}, "7": {"memory": [43860.0, 81251.1875], "load": 0.99, "temperature": 49}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.241148948669434}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.277461910527848, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.432785987854004}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.385108947753906}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.467279434204102}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.975258511934268, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.350247383117676}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.329327583312988}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.29102897644043}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.22926930498471, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.778212547302246}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.134719848632812}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.056169509887695}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [43860.0, 81251.1875], "load": 0.99, "temperature": 43}, "1": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 41}, "2": {"memory": [44004.0, 81251.1875], "load": 0.97, "temperature": 44}, "3": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 42}, "4": {"memory": [44004.0, 81251.1875], "load": 0.97, "temperature": 51}, "5": {"memory": [44004.0, 81251.1875], "load": 0.93, "temperature": 51}, "6": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 52}, "7": {"memory": [43860.0, 81251.1875], "load": 0.94, "temperature": 51}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 26.069166230943082, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.198077201843262}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.275959968566895}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.36447811126709}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 26.126542696396207, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.055032730102539}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.601694107055664}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.604958534240723}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 26.088083402421557, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.618302345275879}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 8.93289852142334}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.30557918548584}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 24.788572906085513, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.657130241394043}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [43860.0, 81251.1875], "load": 0.94, "temperature": 43}, "1": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 41}, "2": {"memory": [44004.0, 81251.1875], "load": 0.99, "temperature": 44}, "3": {"memory": [44004.0, 81251.1875], "load": 0.96, "temperature": 42}, "4": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 52}, "5": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 52}, "6": {"memory": [44004.0, 81251.1875], "load": 0.96, "temperature": 53}, "7": {"memory": [43860.0, 81251.1875], "load": 0.96, "temperature": 52}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.586573600769043}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 8.717949867248535}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 26.032322883333187, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.56655502319336}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.250471115112305}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.407920837402344}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.708655840917004, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.556682586669922}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.07265853881836}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.397906303405762}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.459917876369413, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.335489273071289}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.316095352172852}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [43860.0, 81251.1875], "load": 0.98, "temperature": 44}, "1": {"memory": [44004.0, 81251.1875], "load": 0.96, "temperature": 42}, "2": {"memory": [44004.0, 81251.1875], "load": 0.96, "temperature": 45}, "3": {"memory": [44004.0, 81251.1875], "load": 0.99, "temperature": 43}, "4": {"memory": [44004.0, 81251.1875], "load": 0.92, "temperature": 53}, "5": {"memory": [44004.0, 81251.1875], "load": 0.89, "temperature": 53}, "6": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 54}, "7": {"memory": [43860.0, 81251.1875], "load": 0.93, "temperature": 53}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.417357444763184}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.41503108732678, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.534281730651855}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.19356918334961}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.523662567138672}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.705274899031068, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.368199348449707}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.152313232421875}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.339032173156738}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.831786838537628, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.560941696166992}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.367607116699219}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.42013931274414}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.746734701707272, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.031045913696289}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [43860.0, 81251.1875], "load": 0.97, "temperature": 44}, "1": {"memory": [44004.0, 81251.1875], "load": 1.0, "temperature": 41}, "2": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 45}, "3": {"memory": [44004.0, 81251.1875], "load": 0.99, "temperature": 42}, "4": {"memory": [44004.0, 81251.1875], "load": 0.96, "temperature": 55}, "5": {"memory": [44004.0, 81251.1875], "load": 1.0, "temperature": 55}, "6": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 55}, "7": {"memory": [43860.0, 81251.1875], "load": 0.93, "temperature": 54}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.389043807983398}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.82315731048584}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.865093262628477, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.338522911071777}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 8.951515197753906}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.45188045501709}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.785752160568304, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.25078296661377}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.505645751953125}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.312030792236328}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.767046495888568, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.204952239990234}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 8.389557838439941}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.521608352661133}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [43860.0, 81251.1875], "load": 0.96, "temperature": 45}, "1": {"memory": [44004.0, 81251.1875], "load": 1.0, "temperature": 41}, "2": {"memory": [44004.0, 81251.1875], "load": 0.91, "temperature": 45}, "3": {"memory": [44004.0, 81251.1875], "load": 0.99, "temperature": 43}, "4": {"memory": [44004.0, 81251.1875], "load": 0.97, "temperature": 55}, "5": {"memory": [44004.0, 81251.1875], "load": 0.94, "temperature": 55}, "6": {"memory": [44004.0, 81251.1875], "load": 0.98, "temperature": 56}, "7": {"memory": [43860.0, 81251.1875], "load": 0.93, "temperature": 55}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.19292528938005, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.37336540222168}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.058425903320312}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.032485008239746}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.93618711369783, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.338104248046875}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.294700622558594}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.494272232055664}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 25.43050469284311, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.572979927062988}, "pipe": "data"}
{"event": "end", "data": {"command": ["accelerate", "launch", "--mixed_precision=fp16", "--dynamo_backend=no", "--machine_rank=0", "--num_machines=1", "--multi_gpu", "--gradient_accumulation_steps=1", "--num_cpu_threads_per_process=8", "--main_process_ip=override-me", "--main_process_port=10000", "--num_processes=8", "/Tmp/slurm.3188069.0/milabench_dev/milabench/benchmarks/accelerate_opt/main.py"], "time": 1683742778.935893, "return_code": 0}, "pipe": null}
