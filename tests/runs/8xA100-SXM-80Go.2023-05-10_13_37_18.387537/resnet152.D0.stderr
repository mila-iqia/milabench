Training with a single process on 1 device (cuda:0).
Model resnet152 created, param count:60192808
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.95
	crop_mode: center
Learning rate (0.1) calculated from base learning rate (0.1) and global batch size (256) with linear scaling.
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/16 (  0%)]  Loss: 6.929 (6.93)  Time: 11.159s,   22.94/s  (11.159s,   22.94/s)  LR: 1.000e-05  Data: 1.470 (1.470)
Train: 0 [  15/16 (100%)]  Loss: 6.934 (6.94)  Time: 0.360s,  711.43/s  (1.096s,  233.61/s)  LR: 1.000e-05  Data: 0.000 (0.103)
Test: [   0/16]  Time: 1.401 (1.401)  Loss:  6.9339 (6.9339)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.685 (0.302)  Loss:  6.8981 (6.9128)  Acc@1:  0.0000 ( 0.1453)  Acc@5: 28.1250 ( 0.5329)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D0/20230510-140205-resnet152-224/checkpoint-0.pth.tar', 0.14534883720930233)

Train: 1 [   0/16 (  0%)]  Loss: 6.964 (6.96)  Time: 1.490s,  171.85/s  (1.490s,  171.85/s)  LR: 2.001e-02  Data: 1.038 (1.038)
Train: 1 [  15/16 (100%)]  Loss: 6.978 (6.92)  Time: 0.360s,  711.30/s  (0.441s,  580.45/s)  LR: 2.001e-02  Data: 0.000 (0.075)
Test: [   0/16]  Time: 1.019 (1.019)  Loss:  6.8474 (6.8474)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.022 (0.248)  Loss:  6.5629 (6.8342)  Acc@1: 18.7500 ( 0.2422)  Acc@5: 28.1250 ( 1.1870)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D0/20230510-140205-resnet152-224/checkpoint-1.pth.tar', 0.24224806201550386)

Train: 2 [   0/16 (  0%)]  Loss: 6.833 (6.83)  Time: 1.416s,  180.74/s  (1.416s,  180.74/s)  LR: 4.001e-02  Data: 1.055 (1.055)
Train: 2 [  15/16 (100%)]  Loss: 6.952 (6.92)  Time: 0.359s,  712.74/s  (0.440s,  581.51/s)  LR: 4.001e-02  Data: 0.001 (0.076)
Test: [   0/16]  Time: 1.004 (1.004)  Loss:  6.7801 (6.7801)  Acc@1:  0.3906 ( 0.3906)  Acc@5:  3.1250 ( 3.1250)
Test: [  16/16]  Time: 0.017 (0.237)  Loss:  6.3678 (6.8023)  Acc@1:  0.0000 ( 0.1938)  Acc@5: 12.5000 ( 1.0417)
Train: 3 [   0/16 (  0%)]  Loss: 6.850 (6.85)  Time: 1.450s,  176.61/s  (1.450s,  176.61/s)  LR: 6.000e-02  Data: 1.089 (1.089)
Train: 3 [  15/16 (100%)]  Loss: 7.031 (6.96)  Time: 0.360s,  711.01/s  (0.438s,  584.32/s)  LR: 6.000e-02  Data: 0.001 (0.078)
Test: [   0/16]  Time: 1.000 (1.000)  Loss:  6.9445 (6.9445)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.018 (0.236)  Loss:  6.3876 (6.8262)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  0.0000 ( 1.1628)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D0/20230510-140205-resnet152-224/checkpoint-3.pth.tar', 0.26647286821705424)

Train: 4 [   0/16 (  0%)]  Loss: 6.895 (6.89)  Time: 1.430s,  179.06/s  (1.430s,  179.06/s)  LR: 8.000e-02  Data: 1.068 (1.068)
Train: 4 [  15/16 (100%)]  Loss: 7.045 (7.00)  Time: 0.361s,  709.58/s  (0.437s,  585.44/s)  LR: 8.000e-02  Data: 0.000 (0.076)
Test: [   0/16]  Time: 1.003 (1.003)  Loss:  6.8099 (6.8099)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.236)  Loss:  6.4447 (6.8513)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  0.0000 ( 1.0901)
Train: 5 [   0/16 (  0%)]  Loss: 6.862 (6.86)  Time: 1.418s,  180.48/s  (1.418s,  180.48/s)  LR: 9.993e-02  Data: 1.058 (1.058)
Train: 5 [  15/16 (100%)]  Loss: 7.093 (7.04)  Time: 0.361s,  709.94/s  (0.437s,  585.35/s)  LR: 9.993e-02  Data: 0.001 (0.076)
Test: [   0/16]  Time: 0.996 (0.996)  Loss:  6.9076 (6.9076)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.235)  Loss:  6.2764 (6.8779)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  0.0000 ( 1.0417)
Train: 6 [   0/16 (  0%)]  Loss: 6.900 (6.90)  Time: 1.479s,  173.06/s  (1.479s,  173.06/s)  LR: 9.990e-02  Data: 1.095 (1.095)
Train: 6 [  15/16 (100%)]  Loss: 7.166 (7.04)  Time: 0.361s,  708.85/s  (0.441s,  580.32/s)  LR: 9.990e-02  Data: 0.000 (0.078)
Test: [   0/16]  Time: 1.009 (1.009)  Loss:  6.8035 (6.8035)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.235)  Loss:  6.4521 (6.8709)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 1.2112)
Train: 7 [   0/16 (  0%)]  Loss: 6.869 (6.87)  Time: 1.479s,  173.03/s  (1.479s,  173.03/s)  LR: 9.987e-02  Data: 1.117 (1.117)
Train: 7 [  15/16 (100%)]  Loss: 7.121 (7.03)  Time: 0.362s,  708.14/s  (0.441s,  580.50/s)  LR: 9.987e-02  Data: 0.000 (0.080)
Test: [   0/16]  Time: 1.007 (1.007)  Loss:  6.8728 (6.8728)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.235)  Loss:  6.3739 (6.8668)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  0.0000 ( 1.0659)
Train: 8 [   0/16 (  0%)]  Loss: 6.890 (6.89)  Time: 1.474s,  173.63/s  (1.474s,  173.63/s)  LR: 9.982e-02  Data: 1.114 (1.114)
Train: 8 [  15/16 (100%)]  Loss: 7.140 (7.02)  Time: 0.362s,  706.88/s  (0.441s,  580.82/s)  LR: 9.982e-02  Data: 0.001 (0.080)
Test: [   0/16]  Time: 1.004 (1.004)  Loss:  6.8641 (6.8641)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.3906 ( 0.3906)
Test: [  16/16]  Time: 0.018 (0.235)  Loss:  6.7118 (6.8790)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  3.1250 ( 1.0417)
Train: 9 [   0/16 (  0%)]  Loss: 6.945 (6.94)  Time: 1.492s,  171.61/s  (1.492s,  171.61/s)  LR: 9.978e-02  Data: 1.119 (1.119)
Train: 9 [  15/16 (100%)]  Loss: 7.062 (7.01)  Time: 0.363s,  704.48/s  (0.443s,  578.40/s)  LR: 9.978e-02  Data: 0.001 (0.081)
Test: [   0/16]  Time: 1.003 (1.003)  Loss:  6.7967 (6.7967)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  3.9062 ( 3.9062)
Test: [  16/16]  Time: 0.018 (0.234)  Loss:  6.5441 (6.8406)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  0.0000 ( 1.1143)
Train: 10 [   0/16 (  0%)]  Loss: 6.842 (6.84)  Time: 1.437s,  178.11/s  (1.437s,  178.11/s)  LR: 9.973e-02  Data: 1.077 (1.077)
