Training with a single process on 1 device (cuda:0).
Model resnet152 created, param count:60192808
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.95
	crop_mode: center
Learning rate (0.1) calculated from base learning rate (0.1) and global batch size (256) with linear scaling.
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/16 (  0%)]  Loss: 6.929 (6.93)  Time: 10.786s,   23.74/s  (10.786s,   23.74/s)  LR: 1.000e-05  Data: 1.298 (1.298)
Train: 0 [  15/16 (100%)]  Loss: 6.934 (6.94)  Time: 0.360s,  711.65/s  (1.095s,  233.89/s)  LR: 1.000e-05  Data: 0.001 (0.093)
Test: [   0/16]  Time: 1.187 (1.187)  Loss:  6.9339 (6.9339)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.631 (0.301)  Loss:  6.8981 (6.9128)  Acc@1:  0.0000 ( 0.1453)  Acc@5: 28.1250 ( 0.5329)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D1/20230510-140204-resnet152-224/checkpoint-0.pth.tar', 0.14534883720930233)

Train: 1 [   0/16 (  0%)]  Loss: 6.964 (6.96)  Time: 1.887s,  135.68/s  (1.887s,  135.68/s)  LR: 2.001e-02  Data: 1.071 (1.071)
Train: 1 [  15/16 (100%)]  Loss: 6.978 (6.92)  Time: 0.361s,  709.60/s  (0.468s,  546.90/s)  LR: 2.001e-02  Data: 0.001 (0.078)
Test: [   0/16]  Time: 1.012 (1.012)  Loss:  6.8471 (6.8471)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.018 (0.250)  Loss:  6.5640 (6.8342)  Acc@1: 18.7500 ( 0.2422)  Acc@5: 28.1250 ( 1.2355)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D1/20230510-140204-resnet152-224/checkpoint-1.pth.tar', 0.24224806201550386)

Train: 2 [   0/16 (  0%)]  Loss: 6.832 (6.83)  Time: 1.461s,  175.25/s  (1.461s,  175.25/s)  LR: 4.001e-02  Data: 1.101 (1.101)
Train: 2 [  15/16 (100%)]  Loss: 6.938 (6.92)  Time: 0.360s,  711.45/s  (0.444s,  575.98/s)  LR: 4.001e-02  Data: 0.001 (0.080)
Test: [   0/16]  Time: 1.038 (1.038)  Loss:  6.8027 (6.8027)  Acc@1:  3.1250 ( 3.1250)  Acc@5:  3.1250 ( 3.1250)
Test: [  16/16]  Time: 0.017 (0.239)  Loss:  6.3640 (6.8029)  Acc@1:  0.0000 ( 0.1938)  Acc@5: 28.1250 ( 1.1143)
Train: 3 [   0/16 (  0%)]  Loss: 6.863 (6.86)  Time: 1.427s,  179.34/s  (1.427s,  179.34/s)  LR: 6.000e-02  Data: 1.067 (1.067)
Train: 3 [  15/16 (100%)]  Loss: 7.026 (6.96)  Time: 0.362s,  707.28/s  (0.438s,  584.73/s)  LR: 6.000e-02  Data: 0.001 (0.077)
Test: [   0/16]  Time: 1.013 (1.013)  Loss:  6.9035 (6.9035)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.237)  Loss:  6.3678 (6.8186)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  0.0000 ( 1.0901)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D1/20230510-140204-resnet152-224/checkpoint-3.pth.tar', 0.26647286821705424)

Train: 4 [   0/16 (  0%)]  Loss: 6.874 (6.87)  Time: 1.431s,  178.90/s  (1.431s,  178.90/s)  LR: 8.000e-02  Data: 1.071 (1.071)
Train: 4 [  15/16 (100%)]  Loss: 7.046 (7.00)  Time: 0.360s,  710.96/s  (0.437s,  585.49/s)  LR: 8.000e-02  Data: 0.001 (0.077)
Test: [   0/16]  Time: 1.019 (1.019)  Loss:  6.8266 (6.8266)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.238)  Loss:  6.6335 (6.8511)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 1.1628)
Train: 5 [   0/16 (  0%)]  Loss: 6.880 (6.88)  Time: 1.425s,  179.69/s  (1.425s,  179.69/s)  LR: 9.993e-02  Data: 1.065 (1.065)
Train: 5 [  15/16 (100%)]  Loss: 7.087 (7.04)  Time: 0.360s,  710.59/s  (0.440s,  581.35/s)  LR: 9.993e-02  Data: 0.001 (0.079)
Test: [   0/16]  Time: 1.010 (1.010)  Loss:  6.9131 (6.9131)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.3906 ( 0.3906)
Test: [  16/16]  Time: 0.017 (0.237)  Loss:  6.3840 (6.8865)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  3.1250 ( 0.9690)
Train: 6 [   0/16 (  0%)]  Loss: 6.898 (6.90)  Time: 1.459s,  175.41/s  (1.459s,  175.41/s)  LR: 9.990e-02  Data: 1.098 (1.098)
Train: 6 [  15/16 (100%)]  Loss: 7.154 (7.05)  Time: 0.359s,  712.13/s  (0.439s,  582.78/s)  LR: 9.990e-02  Data: 0.001 (0.079)
Test: [   0/16]  Time: 1.006 (1.006)  Loss:  6.8055 (6.8055)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.237)  Loss:  6.5659 (6.8740)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 1.1143)
Train: 7 [   0/16 (  0%)]  Loss: 6.865 (6.86)  Time: 1.446s,  177.05/s  (1.446s,  177.05/s)  LR: 9.987e-02  Data: 1.086 (1.086)
Train: 7 [  15/16 (100%)]  Loss: 7.067 (7.01)  Time: 0.360s,  710.45/s  (0.438s,  584.22/s)  LR: 9.987e-02  Data: 0.001 (0.078)
Test: [   0/16]  Time: 1.040 (1.040)  Loss:  6.8030 (6.8030)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.016 (0.237)  Loss:  6.5713 (6.8475)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 0.9448)
Train: 8 [   0/16 (  0%)]  Loss: 6.889 (6.89)  Time: 1.443s,  177.38/s  (1.443s,  177.38/s)  LR: 9.982e-02  Data: 1.083 (1.083)
Train: 8 [  15/16 (100%)]  Loss: 7.028 (6.96)  Time: 0.360s,  710.59/s  (0.437s,  585.57/s)  LR: 9.982e-02  Data: 0.001 (0.077)
Test: [   0/16]  Time: 1.006 (1.006)  Loss:  6.7971 (6.7971)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.016 (0.237)  Loss:  6.6769 (6.8256)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 1.0659)
Train: 9 [   0/16 (  0%)]  Loss: 6.905 (6.91)  Time: 1.429s,  179.15/s  (1.429s,  179.15/s)  LR: 9.978e-02  Data: 1.069 (1.069)
Train: 9 [  15/16 (100%)]  Loss: 6.993 (6.92)  Time: 0.360s,  711.05/s  (0.438s,  584.31/s)  LR: 9.978e-02  Data: 0.001 (0.077)
Test: [   0/16]  Time: 1.005 (1.005)  Loss:  6.7832 (6.7832)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.237)  Loss:  6.4143 (6.8103)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  0.0000 ( 1.2597)
Train: 10 [   0/16 (  0%)]  Loss: 6.825 (6.83)  Time: 1.420s,  180.24/s  (1.420s,  180.24/s)  LR: 9.973e-02  Data: 1.061 (1.061)
