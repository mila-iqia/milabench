Training with a single process on 1 device (cuda:0).
Model resnet152 created, param count:60192808
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.95
	crop_mode: center
Learning rate (0.1) calculated from base learning rate (0.1) and global batch size (256) with linear scaling.
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/16 (  0%)]  Loss: 6.929 (6.93)  Time: 11.386s,   22.48/s  (11.386s,   22.48/s)  LR: 1.000e-05  Data: 1.419 (1.419)
Train: 0 [  15/16 (100%)]  Loss: 6.934 (6.94)  Time: 0.371s,  690.85/s  (1.085s,  235.97/s)  LR: 1.000e-05  Data: 0.012 (0.100)
Test: [   0/16]  Time: 1.484 (1.484)  Loss:  6.9339 (6.9339)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.908 (0.328)  Loss:  6.8981 (6.9128)  Acc@1:  0.0000 ( 0.1453)  Acc@5: 28.1250 ( 0.5329)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D7/20230510-140206-resnet152-224/checkpoint-0.pth.tar', 0.14534883720930233)

Train: 1 [   0/16 (  0%)]  Loss: 6.964 (6.96)  Time: 1.735s,  147.58/s  (1.735s,  147.58/s)  LR: 2.001e-02  Data: 1.113 (1.113)
Train: 1 [  15/16 (100%)]  Loss: 6.978 (6.92)  Time: 0.360s,  710.67/s  (0.458s,  558.55/s)  LR: 2.001e-02  Data: 0.001 (0.080)
Test: [   0/16]  Time: 1.203 (1.203)  Loss:  6.8471 (6.8471)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.019 (0.259)  Loss:  6.5640 (6.8342)  Acc@1: 18.7500 ( 0.2422)  Acc@5: 28.1250 ( 1.2355)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D7/20230510-140206-resnet152-224/checkpoint-1.pth.tar', 0.24224806201550386)

Train: 2 [   0/16 (  0%)]  Loss: 6.832 (6.83)  Time: 1.475s,  173.51/s  (1.475s,  173.51/s)  LR: 4.001e-02  Data: 1.115 (1.115)
Train: 2 [  15/16 (100%)]  Loss: 6.938 (6.92)  Time: 0.361s,  708.62/s  (0.445s,  575.86/s)  LR: 4.001e-02  Data: 0.000 (0.080)
Test: [   0/16]  Time: 1.067 (1.067)  Loss:  6.8027 (6.8027)  Acc@1:  3.1250 ( 3.1250)  Acc@5:  3.1250 ( 3.1250)
Test: [  16/16]  Time: 0.021 (0.250)  Loss:  6.3640 (6.8029)  Acc@1:  0.0000 ( 0.1938)  Acc@5: 28.1250 ( 1.1143)
Train: 3 [   0/16 (  0%)]  Loss: 6.863 (6.86)  Time: 1.468s,  174.33/s  (1.468s,  174.33/s)  LR: 6.000e-02  Data: 1.107 (1.107)
Train: 3 [  15/16 (100%)]  Loss: 7.026 (6.96)  Time: 0.364s,  703.41/s  (0.441s,  580.33/s)  LR: 6.000e-02  Data: 0.000 (0.080)
Test: [   0/16]  Time: 1.123 (1.123)  Loss:  6.9035 (6.9035)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.254)  Loss:  6.3678 (6.8186)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  0.0000 ( 1.0901)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D7/20230510-140206-resnet152-224/checkpoint-3.pth.tar', 0.26647286821705424)

Train: 4 [   0/16 (  0%)]  Loss: 6.874 (6.87)  Time: 1.483s,  172.65/s  (1.483s,  172.65/s)  LR: 8.000e-02  Data: 1.099 (1.099)
Train: 4 [  15/16 (100%)]  Loss: 7.046 (7.00)  Time: 0.364s,  703.57/s  (0.442s,  578.67/s)  LR: 8.000e-02  Data: 0.001 (0.080)
Test: [   0/16]  Time: 1.122 (1.122)  Loss:  6.8266 (6.8266)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.255)  Loss:  6.6335 (6.8511)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 1.1628)
Train: 5 [   0/16 (  0%)]  Loss: 6.880 (6.88)  Time: 1.610s,  159.02/s  (1.610s,  159.02/s)  LR: 9.993e-02  Data: 1.226 (1.226)
Train: 5 [  15/16 (100%)]  Loss: 7.087 (7.04)  Time: 0.364s,  703.46/s  (0.450s,  569.38/s)  LR: 9.993e-02  Data: 0.000 (0.087)
Test: [   0/16]  Time: 1.117 (1.117)  Loss:  6.9131 (6.9131)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.3906 ( 0.3906)
Test: [  16/16]  Time: 0.019 (0.258)  Loss:  6.3840 (6.8865)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  3.1250 ( 0.9690)
Train: 6 [   0/16 (  0%)]  Loss: 6.898 (6.90)  Time: 1.500s,  170.67/s  (1.500s,  170.67/s)  LR: 9.990e-02  Data: 1.132 (1.132)
Train: 6 [  15/16 (100%)]  Loss: 7.154 (7.05)  Time: 0.361s,  708.28/s  (0.442s,  578.63/s)  LR: 9.990e-02  Data: 0.000 (0.081)
Test: [   0/16]  Time: 1.112 (1.112)  Loss:  6.8055 (6.8055)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.018 (0.249)  Loss:  6.5659 (6.8740)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 1.1143)
Train: 7 [   0/16 (  0%)]  Loss: 6.865 (6.86)  Time: 1.430s,  178.99/s  (1.430s,  178.99/s)  LR: 9.987e-02  Data: 1.069 (1.069)
Train: 7 [  15/16 (100%)]  Loss: 7.067 (7.01)  Time: 0.360s,  711.56/s  (0.438s,  584.26/s)  LR: 9.987e-02  Data: 0.000 (0.077)
Test: [   0/16]  Time: 1.115 (1.115)  Loss:  6.8030 (6.8030)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.018 (0.250)  Loss:  6.5713 (6.8475)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 0.9448)
Train: 8 [   0/16 (  0%)]  Loss: 6.889 (6.89)  Time: 1.455s,  175.98/s  (1.455s,  175.98/s)  LR: 9.982e-02  Data: 1.093 (1.093)
Train: 8 [  15/16 (100%)]  Loss: 7.028 (6.96)  Time: 0.361s,  708.51/s  (0.443s,  578.35/s)  LR: 9.982e-02  Data: 0.000 (0.081)
Test: [   0/16]  Time: 1.087 (1.087)  Loss:  6.7971 (6.7971)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.019 (0.257)  Loss:  6.6769 (6.8256)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 1.0659)
Train: 9 [   0/16 (  0%)]  Loss: 6.905 (6.91)  Time: 1.452s,  176.30/s  (1.452s,  176.30/s)  LR: 9.978e-02  Data: 1.091 (1.091)
Train: 9 [  15/16 (100%)]  Loss: 6.993 (6.92)  Time: 0.362s,  706.30/s  (0.439s,  582.98/s)  LR: 9.978e-02  Data: 0.001 (0.078)
Test: [   0/16]  Time: 1.069 (1.069)  Loss:  6.7832 (6.7832)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.257)  Loss:  6.4143 (6.8103)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  0.0000 ( 1.2597)
Train: 10 [   0/16 (  0%)]  Loss: 6.825 (6.83)  Time: 1.462s,  175.05/s  (1.462s,  175.05/s)  LR: 9.973e-02  Data: 1.101 (1.101)
