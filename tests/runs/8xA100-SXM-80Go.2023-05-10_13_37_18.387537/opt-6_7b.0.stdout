[05/10/23 14:20:53] INFO     [6/8] __main__ - Distributed environment: DEEPSPEED     logging.py:47
                             Num processes: 8                                                     
                             Process index: 6                                                     
                             Local process index: 6                                               
                             Device: cuda:6                                                       
                                                                                                  
                             Mixed precision type: fp16                                           
                             ds_config: {'train_batch_size': 'auto',                              
                             'train_micro_batch_size_per_gpu': 'auto',                            
                             'gradient_accumulation_steps': 1, 'zero_optimization':               
                             {'stage': 2, 'offload_optimizer': {'device': 'none'},                
                             'offload_param': {'device': 'none'},                                 
                             'stage3_gather_16bit_weights_on_model_save': False},                 
                             'steps_per_print': inf, 'fp16': {'enabled': True,                    
                             'auto_cast': True}, 'bf16': {'enabled': False}}                      
                                                                                                  
[05/10/23 14:20:53] INFO     [5/8] __main__ - Distributed environment: DEEPSPEED     logging.py:47
                             Num processes: 8                                                     
                             Process index: 5                                                     
                             Local process index: 5                                               
                             Device: cuda:5                                                       
                                                                                                  
                             Mixed precision type: fp16                                           
                             ds_config: {'train_batch_size': 'auto',                              
                             'train_micro_batch_size_per_gpu': 'auto',                            
                             'gradient_accumulation_steps': 1, 'zero_optimization':               
                             {'stage': 2, 'offload_optimizer': {'device': 'none'},                
                             'offload_param': {'device': 'none'},                                 
                             'stage3_gather_16bit_weights_on_model_save': False},                 
                             'steps_per_print': inf, 'fp16': {'enabled': True,                    
                             'auto_cast': True}, 'bf16': {'enabled': False}}                      
                                                                                                  
[05/10/23 14:20:53] INFO     [2/8] __main__ - Distributed environment: DEEPSPEED     logging.py:47
                             Num processes: 8                                                     
                             Process index: 2                                                     
                             Local process index: 2                                               
                             Device: cuda:2                                                       
                                                                                                  
                             Mixed precision type: fp16                                           
                             ds_config: {'train_batch_size': 'auto',                              
                             'train_micro_batch_size_per_gpu': 'auto',                            
                             'gradient_accumulation_steps': 1, 'zero_optimization':               
                             {'stage': 2, 'offload_optimizer': {'device': 'none'},                
                             'offload_param': {'device': 'none'},                                 
                             'stage3_gather_16bit_weights_on_model_save': False},                 
                             'steps_per_print': inf, 'fp16': {'enabled': True,                    
                             'auto_cast': True}, 'bf16': {'enabled': False}}                      
                                                                                                  
[05/10/23 14:20:53] INFO     [4/8] __main__ - Distributed environment: DEEPSPEED     logging.py:47
                             Num processes: 8                                                     
                             Process index: 4                                                     
                             Local process index: 4                                               
                             Device: cuda:4                                                       
                                                                                                  
                             Mixed precision type: fp16                                           
                             ds_config: {'train_batch_size': 'auto',                              
                             'train_micro_batch_size_per_gpu': 'auto',                            
                             'gradient_accumulation_steps': 1, 'zero_optimization':               
                             {'stage': 2, 'offload_optimizer': {'device': 'none'},                
                             'offload_param': {'device': 'none'},                                 
                             'stage3_gather_16bit_weights_on_model_save': False},                 
                             'steps_per_print': inf, 'fp16': {'enabled': True,                    
                             'auto_cast': True}, 'bf16': {'enabled': False}}                      
                                                                                                  
[05/10/23 14:20:53] INFO     [3/8] __main__ - Distributed environment: DEEPSPEED     logging.py:47
                             Num processes: 8                                                     
                             Process index: 3                                                     
                             Local process index: 3                                               
                             Device: cuda:3                                                       
                                                                                                  
                             Mixed precision type: fp16                                           
                             ds_config: {'train_batch_size': 'auto',                              
                             'train_micro_batch_size_per_gpu': 'auto',                            
                             'gradient_accumulation_steps': 1, 'zero_optimization':               
                             {'stage': 2, 'offload_optimizer': {'device': 'none'},                
                             'offload_param': {'device': 'none'},                                 
                             'stage3_gather_16bit_weights_on_model_save': False},                 
                             'steps_per_print': inf, 'fp16': {'enabled': True,                    
                             'auto_cast': True}, 'bf16': {'enabled': False}}                      
                                                                                                  
[05/10/23 14:20:53] INFO     [7/8] __main__ - Distributed environment: DEEPSPEED     logging.py:47
                             Num processes: 8                                                     
                             Process index: 7                                                     
                             Local process index: 7                                               
                             Device: cuda:7                                                       
                                                                                                  
                             Mixed precision type: fp16                                           
                             ds_config: {'train_batch_size': 'auto',                              
                             'train_micro_batch_size_per_gpu': 'auto',                            
                             'gradient_accumulation_steps': 1, 'zero_optimization':               
                             {'stage': 2, 'offload_optimizer': {'device': 'none'},                
                             'offload_param': {'device': 'none'},                                 
                             'stage3_gather_16bit_weights_on_model_save': False},                 
                             'steps_per_print': inf, 'fp16': {'enabled': True,                    
                             'auto_cast': True}, 'bf16': {'enabled': False}}                      
                                                                                                  
[05/10/23 14:20:53] INFO     [1/8] __main__ - Distributed environment: DEEPSPEED     logging.py:47
                             Num processes: 8                                                     
                             Process index: 1                                                     
                             Local process index: 1                                               
                             Device: cuda:1                                                       
                                                                                                  
                             Mixed precision type: fp16                                           
                             ds_config: {'train_batch_size': 'auto',                              
                             'train_micro_batch_size_per_gpu': 'auto',                            
                             'gradient_accumulation_steps': 1, 'zero_optimization':               
                             {'stage': 2, 'offload_optimizer': {'device': 'none'},                
                             'offload_param': {'device': 'none'},                                 
                             'stage3_gather_16bit_weights_on_model_save': False},                 
                             'steps_per_print': inf, 'fp16': {'enabled': True,                    
                             'auto_cast': True}, 'bf16': {'enabled': False}}                      
                                                                                                  
[05/10/23 14:20:54] INFO     [0/8] __main__ - Distributed environment: DEEPSPEED     logging.py:47
                             Num processes: 8                                                     
                             Process index: 0                                                     
                             Local process index: 0                                               
                             Device: cuda:0                                                       
                                                                                                  
                             Mixed precision type: fp16                                           
                             ds_config: {'train_batch_size': 'auto',                              
                             'train_micro_batch_size_per_gpu': 'auto',                            
                             'gradient_accumulation_steps': 1, 'zero_optimization':               
                             {'stage': 2, 'offload_optimizer': {'device': 'none'},                
                             'offload_param': {'device': 'none'},                                 
                             'stage3_gather_16bit_weights_on_model_save': False},                 
                             'steps_per_print': inf, 'fp16': {'enabled': True,                    
                             'auto_cast': True}, 'bf16': {'enabled': False}}                      
                                                                                                  
[05/10/23 14:21:00] WARNING  [0/8] datasets.builder - Found cached dataset wikitext builder.py:817
                             (/Tmp/slurm.3188069.0/milabench_dev/results/cache/hugg               
                             ingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db               
                             52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646               
                             a126)                                                                
[05/10/23 14:21:01] WARNING  [0/8] datasets.arrow_dataset - Loading cached   arrow_dataset.py:3110
                             processed dataset at                                                 
                             /Tmp/slurm.3188069.0/milabench_dev/results/cach                      
                             e/huggingface/datasets/wikitext/wikitext-103-v1                      
                             /1.0.0/a241db52902eaf2c6aa732210bead40c090019a4                      
                             99ceb13bcbfa3f8ab646a126/cache-a9f98f4245980a05                      
                             _*_of_00008.arrow                                                    
                    WARNING  [0/8] datasets.arrow_dataset - Loading cached   arrow_dataset.py:3110
                             processed dataset at                                                 
                             /Tmp/slurm.3188069.0/milabench_dev/results/cach                      
                             e/huggingface/datasets/wikitext/wikitext-103-v1                      
                             /1.0.0/a241db52902eaf2c6aa732210bead40c090019a4                      
                             99ceb13bcbfa3f8ab646a126/cache-85db34bbdde76966                      
                             _*_of_00008.arrow                                                    
                    WARNING  [0/8] datasets.arrow_dataset - Loading cached   arrow_dataset.py:3110
                             processed dataset at                                                 
                             /Tmp/slurm.3188069.0/milabench_dev/results/cach                      
                             e/huggingface/datasets/wikitext/wikitext-103-v1                      
                             /1.0.0/a241db52902eaf2c6aa732210bead40c090019a4                      
                             99ceb13bcbfa3f8ab646a126/cache-911038f3ecefb91d                      
                             _*_of_00008.arrow                                                    
                    WARNING  [0/8] __main__ - The tokenizer picked seems to have a   logging.py:47
                             very large `model_max_length`                                        
                             (1000000000000000019884624838656). Picking 1024                      
                             instead. You can change that default value by passing                
                             --block_size xxx.                                                    
                    WARNING  [0/8] datasets.arrow_dataset - Loading cached   arrow_dataset.py:3110
                             processed dataset at                                                 
                             /Tmp/slurm.3188069.0/milabench_dev/results/cach                      
                             e/huggingface/datasets/wikitext/wikitext-103-v1                      
                             /1.0.0/a241db52902eaf2c6aa732210bead40c090019a4                      
                             99ceb13bcbfa3f8ab646a126/cache-4b0b79af86b40fe7                      
                             _*_of_00008.arrow                                                    
                    WARNING  [0/8] datasets.arrow_dataset - Loading cached   arrow_dataset.py:3110
                             processed dataset at                                                 
                             /Tmp/slurm.3188069.0/milabench_dev/results/cach                      
                             e/huggingface/datasets/wikitext/wikitext-103-v1                      
                             /1.0.0/a241db52902eaf2c6aa732210bead40c090019a4                      
                             99ceb13bcbfa3f8ab646a126/cache-16a17d1415aa7b1e                      
                             _*_of_00008.arrow                                                    
                    WARNING  [0/8] datasets.arrow_dataset - Loading cached   arrow_dataset.py:3110
                             processed dataset at                                                 
                             /Tmp/slurm.3188069.0/milabench_dev/results/cach                      
                             e/huggingface/datasets/wikitext/wikitext-103-v1                      
                             /1.0.0/a241db52902eaf2c6aa732210bead40c090019a4                      
                             99ceb13bcbfa3f8ab646a126/cache-3b448ee369e6697b                      
                             _*_of_00008.arrow                                                    
[2023-05-10 14:22:15,643] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[05/10/23 14:22:16] INFO     [0/8] accelerate.accelerator - Since you passed both    logging.py:47
                             train and evaluation dataloader, `is_train_batch_min`                
                             (here True will decide the `train_batch_size` (1).                   
[2023-05-10 14:22:16,600] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[2023-05-10 14:22:16,931] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[2023-05-10 14:22:17,075] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[2023-05-10 14:22:17,317] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[2023-05-10 14:22:17,644] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[2023-05-10 14:22:18,231] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[2023-05-10 14:22:19,896] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[05/10/23 14:22:21] INFO     [6/8] torch.distributed.distributed_c10d -    distributed_c10d.py:432
                             Added key: store_based_barrier_key:2 to store                        
                             for rank: 6                                                          
[05/10/23 14:22:22] INFO     [0/8] torch.distributed.distributed_c10d -    distributed_c10d.py:432
                             Added key: store_based_barrier_key:2 to store                        
                             for rank: 0                                                          
[05/10/23 14:22:24] INFO     [7/8] torch.distributed.distributed_c10d -    distributed_c10d.py:432
                             Added key: store_based_barrier_key:2 to store                        
                             for rank: 7                                                          
[05/10/23 14:22:24] INFO     [5/8] torch.distributed.distributed_c10d -    distributed_c10d.py:432
                             Added key: store_based_barrier_key:2 to store                        
                             for rank: 5                                                          
[05/10/23 14:22:28] INFO     [3/8] torch.distributed.distributed_c10d -    distributed_c10d.py:432
                             Added key: store_based_barrier_key:2 to store                        
                             for rank: 3                                                          
[05/10/23 14:22:29] INFO     [2/8] torch.distributed.distributed_c10d -    distributed_c10d.py:432
                             Added key: store_based_barrier_key:2 to store                        
                             for rank: 2                                                          
[05/10/23 14:22:29] INFO     [1/8] torch.distributed.distributed_c10d -    distributed_c10d.py:432
                             Added key: store_based_barrier_key:2 to store                        
                             for rank: 1                                                          
                    INFO     [1/8] torch.distributed.distributed_c10d -    distributed_c10d.py:466
                             Rank 1: Completed store-based barrier for                            
                             key:store_based_barrier_key:2 with 8 nodes.                          
[05/10/23 14:22:29] INFO     [6/8] torch.distributed.distributed_c10d -    distributed_c10d.py:466
                             Rank 6: Completed store-based barrier for                            
                             key:store_based_barrier_key:2 with 8 nodes.                          
[05/10/23 14:22:29] INFO     [4/8] torch.distributed.distributed_c10d -    distributed_c10d.py:432
                             Added key: store_based_barrier_key:2 to store                        
                             for rank: 4                                                          
[05/10/23 14:22:29] INFO     [0/8] torch.distributed.distributed_c10d -    distributed_c10d.py:466
                             Rank 0: Completed store-based barrier for                            
                             key:store_based_barrier_key:2 with 8 nodes.                          
                    INFO     [4/8] torch.distributed.distributed_c10d -    distributed_c10d.py:466
                             Rank 4: Completed store-based barrier for                            
                             key:store_based_barrier_key:2 with 8 nodes.                          
                    INFO     [2/8] torch.distributed.distributed_c10d -    distributed_c10d.py:466
                             Rank 2: Completed store-based barrier for                            
                             key:store_based_barrier_key:2 with 8 nodes.                          
[05/10/23 14:22:29] INFO     [5/8] torch.distributed.distributed_c10d -    distributed_c10d.py:466
                             Rank 5: Completed store-based barrier for                            
                             key:store_based_barrier_key:2 with 8 nodes.                          
[05/10/23 14:22:29] INFO     [7/8] torch.distributed.distributed_c10d -    distributed_c10d.py:466
                             Rank 7: Completed store-based barrier for                            
                             key:store_based_barrier_key:2 with 8 nodes.                          
[05/10/23 14:22:29] INFO     [3/8] torch.distributed.distributed_c10d -    distributed_c10d.py:466
                             Rank 3: Completed store-based barrier for                            
                             key:store_based_barrier_key:2 with 8 nodes.                          
[2023-05-10 14:22:33,566] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-05-10 14:22:33,568] [INFO] [logging.py:93:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-05-10 14:22:33,568] [INFO] [logging.py:93:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-05-10 14:22:33,592] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-05-10 14:22:33,592] [INFO] [utils.py:55:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2023-05-10 14:22:33,592] [INFO] [logging.py:93:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[2023-05-10 14:22:33,592] [INFO] [stage_1_and_2.py:144:__init__] Reduce bucket size 500,000,000
[2023-05-10 14:22:33,592] [INFO] [stage_1_and_2.py:145:__init__] Allgather bucket size 500,000,000
[2023-05-10 14:22:33,592] [INFO] [stage_1_and_2.py:146:__init__] CPU Offload: False
[2023-05-10 14:22:33,592] [INFO] [stage_1_and_2.py:147:__init__] Round robin gradient partitioning: False
[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /home/mila/d/delaunap/scratch/milabench/conda/lib/python3.9/site-packages/torch/include -isystem /home/mila/d/delaunap/scratch/milabench/conda/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /home/mila/d/delaunap/scratch/milabench/conda/lib/python3.9/site-packages/torch/include/TH -isystem /home/mila/d/delaunap/scratch/milabench/conda/lib/python3.9/site-packages/torch/include/THC -isystem /home/mila/d/delaunap/scratch/milabench/conda/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /home/mila/d/delaunap/scratch/milabench/conda/lib/python3.9/site-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o 
[2/2] c++ flatten_unflatten.o -shared -L/home/mila/d/delaunap/scratch/milabench/conda/lib/python3.9/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so
Time to load utils op: 29.773117542266846 seconds
Time to load utils op: 29.738744258880615 seconds
Time to load utils op: 29.73954463005066 seconds
Time to load utils op: 29.736891984939575 seconds
Time to load utils op: 29.7374210357666 seconds
Time to load utils op: 29.737247705459595 seconds
Time to load utils op: 29.63775610923767 seconds
Time to load utils op: 29.838988304138184 seconds
Rank: 0 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 6 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 7 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 5 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 3 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 1 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 2 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 4 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
[2023-05-10 14:23:17,942] [INFO] [utils.py:829:see_memory_usage] Before initializing optimizer states
[2023-05-10 14:23:17,944] [INFO] [utils.py:830:see_memory_usage] MA 15.5 GB         Max_MA 17.05 GB         CA 15.52 GB         Max_CA 17 GB 
[2023-05-10 14:23:17,944] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 38.65 GB, percent = 1.9%
Time to load utils op: 0.004669189453125 secondsTime to load utils op: 0.0046923160552978516 seconds

Time to load utils op: 0.0044291019439697266 seconds
Time to load utils op: 0.00548243522644043 seconds
Time to load utils op: 0.005692958831787109 secondsTime to load utils op: 0.005034446716308594 seconds

Time to load utils op: 0.002580404281616211 seconds
[2023-05-10 14:23:18,297] [INFO] [utils.py:829:see_memory_usage] After initializing optimizer states
[2023-05-10 14:23:18,298] [INFO] [utils.py:830:see_memory_usage] MA 21.7 GB         Max_MA 31.0 GB         CA 31.04 GB         Max_CA 31 GB 
[2023-05-10 14:23:18,298] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 38.65 GB, percent = 1.9%
[2023-05-10 14:23:18,298] [INFO] [stage_1_and_2.py:520:__init__] optimizer state initialized
[2023-05-10 14:23:18,395] [INFO] [utils.py:829:see_memory_usage] After initializing ZeRO optimizer
[2023-05-10 14:23:18,395] [INFO] [utils.py:830:see_memory_usage] MA 21.7 GB         Max_MA 21.7 GB         CA 31.04 GB         Max_CA 31 GB 
[2023-05-10 14:23:18,396] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 38.65 GB, percent = 1.9%
[2023-05-10 14:23:18,398] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2023-05-10 14:23:18,398] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-05-10 14:23:18,398] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2023-05-10 14:23:18,398] [INFO] [logging.py:93:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05, 5e-05], mom=[(0.9, 0.999), (0.9, 0.999)]
[2023-05-10 14:23:18,399] [INFO] [config.py:1018:print] DeepSpeedEngine configuration:
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   amp_enabled .................. False
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   amp_params ................... False
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   bfloat16_enabled ............. False
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   checkpoint_parallel_write_pipeline  False
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   checkpoint_tag_validation_enabled  True
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   checkpoint_tag_validation_fail  False
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7bd4a3d850>
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   communication_data_type ...... None
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   curriculum_enabled_legacy .... False
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   curriculum_params_legacy ..... False
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   data_efficiency_enabled ...... False
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   dataloader_drop_last ......... False
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   disable_allgather ............ False
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   dump_state ................... False
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   dynamic_loss_scale_args ...... None
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   eigenvalue_enabled ........... False
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   eigenvalue_gas_boundary_resolution  1
[2023-05-10 14:23:18,400] [INFO] [config.py:1022:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   eigenvalue_layer_num ......... 0
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   eigenvalue_max_iter .......... 100
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   eigenvalue_stability ......... 1e-06
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   eigenvalue_tol ............... 0.01
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   eigenvalue_verbose ........... False
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   elasticity_enabled ........... False
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   fp16_auto_cast ............... True
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   fp16_enabled ................. True
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   fp16_master_weights_and_gradients  False
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   global_rank .................. 0
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   grad_accum_dtype ............. None
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   gradient_accumulation_steps .. 1
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   gradient_clipping ............ 0.0
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   gradient_predivide_factor .... 1.0
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   initial_dynamic_scale ........ 65536
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   load_universal_checkpoint .... False
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   loss_scale ................... 0
[2023-05-10 14:23:18,401] [INFO] [config.py:1022:print]   memory_breakdown ............. False
[2023-05-10 14:23:18,402] [INFO] [config.py:1022:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-05-10 14:23:18,402] [INFO] [config.py:1022:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-05-10 14:23:18,402] [INFO] [config.py:1022:print]   optimizer_legacy_fusion ...... False
[2023-05-10 14:23:18,402] [INFO] [config.py:1022:print]   optimizer_name ............... None
[2023-05-10 14:23:18,402] [INFO] [config.py:1022:print]   optimizer_params ............. None
[2023-05-10 14:23:18,402] [INFO] [config.py:1022:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-05-10 14:23:18,402] [INFO] [config.py:1022:print]   pld_enabled .................. False
[2023-05-10 14:23:18,402] [INFO] [config.py:1022:print]   pld_params ................... False
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   prescale_gradients ........... False
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   scheduler_name ............... None
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   scheduler_params ............. None
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   sparse_attention ............. None
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   sparse_gradients_enabled ..... False
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   steps_per_print .............. inf
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   train_batch_size ............. 8
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   train_micro_batch_size_per_gpu  1
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   use_node_local_storage ....... False
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   wall_clock_breakdown ......... False
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   world_size ................... 8
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   zero_allow_untested_optimizer  True
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   zero_enabled ................. True
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   zero_force_ds_cpu_optimizer .. True
[2023-05-10 14:23:18,403] [INFO] [config.py:1022:print]   zero_optimization_stage ...... 2
[2023-05-10 14:23:18,403] [INFO] [config.py:1007:print_user_config]   json = {
    "train_batch_size": 8, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "none"
        }, 
        "offload_param": {
            "device": "none"
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "steps_per_print": inf, 
    "fp16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "bf16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
Time to load utils op: 0.0013644695281982422 seconds
[05/10/23 14:23:18] INFO     [0/8] __main__ - ***** Running training *****           logging.py:47
                    INFO     [0/8] __main__ -   Num examples = 115910                logging.py:47
                    INFO     [0/8] __main__ -   Num Epochs = 1                       logging.py:47
                    INFO     [0/8] __main__ -   Instantaneous batch size per device  logging.py:47
                             = 1                                                                  
                    INFO     [0/8] __main__ -   Total train batch size (w. parallel, logging.py:47
                             distributed & accumulation) = 8                                      
                    INFO     [0/8] __main__ -   Gradient Accumulation steps = 1      logging.py:47
                    INFO     [0/8] __main__ -   Total optimization steps = 100       logging.py:47
[2023-05-10 14:23:20,349] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648
[2023-05-10 14:23:20,747] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824
[2023-05-10 14:23:21,151] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912
[2023-05-10 14:23:21,550] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456
[2023-05-10 14:23:21,952] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728
[2023-05-10 14:23:22,351] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864
[2023-05-10 14:23:22,754] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432
[2023-05-10 14:23:23,151] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216
[2023-05-10 14:23:23,551] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608
[2023-05-10 14:23:23,959] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304
[2023-05-10 14:23:24,358] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152
[2023-05-10 14:23:24,759] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576
[2023-05-10 14:23:25,162] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576, reducing to 524288
[2023-05-10 14:23:25,568] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288, reducing to 262144
[2023-05-10 14:23:25,966] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072
[2023-05-10 14:23:26,370] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072, reducing to 65536
[2023-05-10 14:23:26,774] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768
[2023-05-10 14:23:27,832] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384
