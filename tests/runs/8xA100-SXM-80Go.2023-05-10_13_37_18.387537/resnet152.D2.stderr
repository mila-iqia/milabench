Training with a single process on 1 device (cuda:0).
Model resnet152 created, param count:60192808
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.95
	crop_mode: center
Learning rate (0.1) calculated from base learning rate (0.1) and global batch size (256) with linear scaling.
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/16 (  0%)]  Loss: 6.929 (6.93)  Time: 10.854s,   23.59/s  (10.854s,   23.59/s)  LR: 1.000e-05  Data: 1.280 (1.280)
Train: 0 [  15/16 (100%)]  Loss: 6.934 (6.94)  Time: 0.358s,  714.18/s  (1.082s,  236.70/s)  LR: 1.000e-05  Data: 0.000 (0.091)
Test: [   0/16]  Time: 1.224 (1.224)  Loss:  6.9339 (6.9339)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.667 (0.298)  Loss:  6.8981 (6.9128)  Acc@1:  0.0000 ( 0.1453)  Acc@5: 28.1250 ( 0.5329)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D2/20230510-140205-resnet152-224/checkpoint-0.pth.tar', 0.14534883720930233)

Train: 1 [   0/16 (  0%)]  Loss: 6.964 (6.96)  Time: 1.477s,  173.34/s  (1.477s,  173.34/s)  LR: 2.001e-02  Data: 1.047 (1.047)
Train: 1 [  15/16 (100%)]  Loss: 6.978 (6.92)  Time: 0.359s,  713.29/s  (0.440s,  582.35/s)  LR: 2.001e-02  Data: 0.000 (0.075)
Test: [   0/16]  Time: 1.052 (1.052)  Loss:  6.8471 (6.8471)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.257)  Loss:  6.5640 (6.8342)  Acc@1: 18.7500 ( 0.2422)  Acc@5: 28.1250 ( 1.2355)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D2/20230510-140205-resnet152-224/checkpoint-1.pth.tar', 0.24224806201550386)

Train: 2 [   0/16 (  0%)]  Loss: 6.832 (6.83)  Time: 1.415s,  180.91/s  (1.415s,  180.91/s)  LR: 4.001e-02  Data: 1.055 (1.055)
Train: 2 [  15/16 (100%)]  Loss: 6.938 (6.92)  Time: 0.360s,  711.91/s  (0.437s,  585.73/s)  LR: 4.001e-02  Data: 0.000 (0.075)
Test: [   0/16]  Time: 1.037 (1.037)  Loss:  6.8027 (6.8027)  Acc@1:  3.1250 ( 3.1250)  Acc@5:  3.1250 ( 3.1250)
Test: [  16/16]  Time: 0.016 (0.246)  Loss:  6.3640 (6.8029)  Acc@1:  0.0000 ( 0.1938)  Acc@5: 28.1250 ( 1.1143)
Train: 3 [   0/16 (  0%)]  Loss: 6.863 (6.86)  Time: 1.405s,  182.22/s  (1.405s,  182.22/s)  LR: 6.000e-02  Data: 1.045 (1.045)
Train: 3 [  15/16 (100%)]  Loss: 7.026 (6.96)  Time: 0.359s,  713.08/s  (0.434s,  589.19/s)  LR: 6.000e-02  Data: 0.001 (0.075)
Test: [   0/16]  Time: 1.030 (1.030)  Loss:  6.9035 (6.9035)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.245)  Loss:  6.3678 (6.8186)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  0.0000 ( 1.0901)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D2/20230510-140205-resnet152-224/checkpoint-3.pth.tar', 0.26647286821705424)

Train: 4 [   0/16 (  0%)]  Loss: 6.874 (6.87)  Time: 1.394s,  183.65/s  (1.394s,  183.65/s)  LR: 8.000e-02  Data: 1.034 (1.034)
Train: 4 [  15/16 (100%)]  Loss: 7.046 (7.00)  Time: 0.360s,  710.52/s  (0.435s,  589.12/s)  LR: 8.000e-02  Data: 0.000 (0.074)
Test: [   0/16]  Time: 1.040 (1.040)  Loss:  6.8266 (6.8266)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.016 (0.245)  Loss:  6.6335 (6.8511)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 1.1628)
Train: 5 [   0/16 (  0%)]  Loss: 6.880 (6.88)  Time: 1.397s,  183.21/s  (1.397s,  183.21/s)  LR: 9.993e-02  Data: 1.037 (1.037)
Train: 5 [  15/16 (100%)]  Loss: 7.087 (7.04)  Time: 0.361s,  710.02/s  (0.435s,  587.96/s)  LR: 9.993e-02  Data: 0.000 (0.074)
Test: [   0/16]  Time: 1.029 (1.029)  Loss:  6.9131 (6.9131)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.3906 ( 0.3906)
Test: [  16/16]  Time: 0.018 (0.244)  Loss:  6.3840 (6.8865)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  3.1250 ( 0.9690)
Train: 6 [   0/16 (  0%)]  Loss: 6.898 (6.90)  Time: 1.431s,  178.86/s  (1.431s,  178.86/s)  LR: 9.990e-02  Data: 1.070 (1.070)
Train: 6 [  15/16 (100%)]  Loss: 7.154 (7.05)  Time: 0.360s,  711.94/s  (0.437s,  585.83/s)  LR: 9.990e-02  Data: 0.000 (0.077)
Test: [   0/16]  Time: 1.045 (1.045)  Loss:  6.8055 (6.8055)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.019 (0.245)  Loss:  6.5659 (6.8740)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 1.1143)
Train: 7 [   0/16 (  0%)]  Loss: 6.865 (6.86)  Time: 1.407s,  182.00/s  (1.407s,  182.00/s)  LR: 9.987e-02  Data: 1.046 (1.046)
Train: 7 [  15/16 (100%)]  Loss: 7.067 (7.01)  Time: 0.362s,  707.50/s  (0.436s,  587.74/s)  LR: 9.987e-02  Data: 0.001 (0.075)
Test: [   0/16]  Time: 1.038 (1.038)  Loss:  6.8030 (6.8030)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.020 (0.245)  Loss:  6.5713 (6.8475)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 0.9448)
Train: 8 [   0/16 (  0%)]  Loss: 6.889 (6.89)  Time: 1.433s,  178.68/s  (1.433s,  178.68/s)  LR: 9.982e-02  Data: 1.070 (1.070)
Train: 8 [  15/16 (100%)]  Loss: 7.028 (6.96)  Time: 0.363s,  705.07/s  (0.438s,  584.97/s)  LR: 9.982e-02  Data: 0.000 (0.077)
Test: [   0/16]  Time: 1.046 (1.046)  Loss:  6.7971 (6.7971)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.020 (0.245)  Loss:  6.6769 (6.8256)  Acc@1:  0.0000 ( 0.1938)  Acc@5:  0.0000 ( 1.0659)
Train: 9 [   0/16 (  0%)]  Loss: 6.905 (6.91)  Time: 1.531s,  167.19/s  (1.531s,  167.19/s)  LR: 9.978e-02  Data: 1.170 (1.170)
Train: 9 [  15/16 (100%)]  Loss: 6.993 (6.92)  Time: 0.360s,  710.81/s  (0.444s,  576.25/s)  LR: 9.978e-02  Data: 0.000 (0.084)
Test: [   0/16]  Time: 1.042 (1.042)  Loss:  6.7832 (6.7832)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.018 (0.244)  Loss:  6.4143 (6.8103)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  0.0000 ( 1.2597)
Train: 10 [   0/16 (  0%)]  Loss: 6.825 (6.83)  Time: 1.404s,  182.33/s  (1.404s,  182.33/s)  LR: 9.973e-02  Data: 1.044 (1.044)
