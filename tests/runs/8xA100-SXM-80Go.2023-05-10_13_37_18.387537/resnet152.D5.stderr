Training with a single process on 1 device (cuda:0).
Model resnet152 created, param count:60192808
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.95
	crop_mode: center
Learning rate (0.1) calculated from base learning rate (0.1) and global batch size (256) with linear scaling.
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 300. LR stepped per epoch.
Train: 0 [   0/16 (  0%)]  Loss: 6.929 (6.93)  Time: 11.280s,   22.69/s  (11.280s,   22.69/s)  LR: 1.000e-05  Data: 1.276 (1.276)
Train: 0 [  15/16 (100%)]  Loss: 6.934 (6.94)  Time: 0.359s,  714.07/s  (1.058s,  241.94/s)  LR: 1.000e-05  Data: 0.000 (0.089)
Test: [   0/16]  Time: 1.182 (1.182)  Loss:  6.9339 (6.9339)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.747 (0.298)  Loss:  6.8981 (6.9128)  Acc@1:  0.0000 ( 0.1453)  Acc@5: 28.1250 ( 0.5329)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D5/20230510-140207-resnet152-224/checkpoint-0.pth.tar', 0.14534883720930233)

Train: 1 [   0/16 (  0%)]  Loss: 6.964 (6.96)  Time: 1.506s,  170.02/s  (1.506s,  170.02/s)  LR: 2.001e-02  Data: 1.052 (1.052)
Train: 1 [  15/16 (100%)]  Loss: 6.978 (6.92)  Time: 0.359s,  713.86/s  (0.440s,  581.16/s)  LR: 2.001e-02  Data: 0.000 (0.074)
Test: [   0/16]  Time: 1.212 (1.212)  Loss:  6.8471 (6.8471)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.019 (0.256)  Loss:  6.5640 (6.8342)  Acc@1: 18.7500 ( 0.2422)  Acc@5: 28.1250 ( 1.2355)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D5/20230510-140207-resnet152-224/checkpoint-1.pth.tar', 0.24224806201550386)

Train: 2 [   0/16 (  0%)]  Loss: 6.832 (6.83)  Time: 1.425s,  179.71/s  (1.425s,  179.71/s)  LR: 4.001e-02  Data: 1.063 (1.063)
Train: 2 [  15/16 (100%)]  Loss: 6.938 (6.92)  Time: 0.361s,  708.23/s  (0.439s,  582.78/s)  LR: 4.001e-02  Data: 0.000 (0.076)
Test: [   0/16]  Time: 1.064 (1.064)  Loss:  6.8031 (6.8031)  Acc@1:  3.1250 ( 3.1250)  Acc@5:  3.1250 ( 3.1250)
Test: [  16/16]  Time: 0.017 (0.245)  Loss:  6.3638 (6.8030)  Acc@1:  0.0000 ( 0.1938)  Acc@5: 28.1250 ( 1.1143)
Train: 3 [   0/16 (  0%)]  Loss: 6.863 (6.86)  Time: 1.442s,  177.49/s  (1.442s,  177.49/s)  LR: 6.000e-02  Data: 1.078 (1.078)
Train: 3 [  15/16 (100%)]  Loss: 7.023 (6.96)  Time: 0.360s,  711.33/s  (0.437s,  585.96/s)  LR: 6.000e-02  Data: 0.001 (0.076)
Test: [   0/16]  Time: 1.047 (1.047)  Loss:  6.8906 (6.8906)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.020 (0.245)  Loss:  6.3048 (6.8152)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  6.2500 ( 1.1386)
Current checkpoints:
 ('/Tmp/slurm.3188069.0/milabench_dev/results/extra/timm/8xA100-SXM-80Go.2023-05-10_13:37:18.387537/resnet152.D5/20230510-140207-resnet152-224/checkpoint-3.pth.tar', 0.26647286821705424)

Train: 4 [   0/16 (  0%)]  Loss: 6.879 (6.88)  Time: 1.403s,  182.48/s  (1.403s,  182.48/s)  LR: 8.000e-02  Data: 1.042 (1.042)
Train: 4 [  15/16 (100%)]  Loss: 7.048 (7.00)  Time: 0.362s,  707.25/s  (0.436s,  587.04/s)  LR: 8.000e-02  Data: 0.000 (0.075)
Test: [   0/16]  Time: 1.045 (1.045)  Loss:  6.8300 (6.8300)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.019 (0.245)  Loss:  6.4835 (6.8438)  Acc@1:  0.0000 ( 0.2665)  Acc@5:  0.0000 ( 1.3081)
Train: 5 [   0/16 (  0%)]  Loss: 6.868 (6.87)  Time: 1.437s,  178.15/s  (1.437s,  178.15/s)  LR: 9.993e-02  Data: 1.075 (1.075)
Train: 5 [  15/16 (100%)]  Loss: 7.096 (7.04)  Time: 0.363s,  704.73/s  (0.439s,  583.34/s)  LR: 9.993e-02  Data: 0.000 (0.077)
Test: [   0/16]  Time: 1.040 (1.040)  Loss:  6.8760 (6.8760)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  1.5625 ( 1.5625)
Test: [  16/16]  Time: 0.019 (0.246)  Loss:  6.2185 (6.8704)  Acc@1:  0.0000 ( 0.1453)  Acc@5:  3.1250 ( 1.0417)
Train: 6 [   0/16 (  0%)]  Loss: 6.910 (6.91)  Time: 1.431s,  178.89/s  (1.431s,  178.89/s)  LR: 9.990e-02  Data: 1.065 (1.065)
Train: 6 [  15/16 (100%)]  Loss: 7.142 (7.04)  Time: 0.363s,  704.66/s  (0.438s,  584.26/s)  LR: 9.990e-02  Data: 0.000 (0.076)
Test: [   0/16]  Time: 1.036 (1.036)  Loss:  6.8120 (6.8120)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.018 (0.245)  Loss:  6.4639 (6.8707)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  0.0000 ( 1.1143)
Train: 7 [   0/16 (  0%)]  Loss: 6.866 (6.87)  Time: 1.416s,  180.76/s  (1.416s,  180.76/s)  LR: 9.987e-02  Data: 1.054 (1.054)
Train: 7 [  15/16 (100%)]  Loss: 7.057 (7.01)  Time: 0.363s,  704.47/s  (0.437s,  585.96/s)  LR: 9.987e-02  Data: 0.000 (0.075)
Test: [   0/16]  Time: 1.038 (1.038)  Loss:  6.7949 (6.7949)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.3906 ( 0.3906)
Test: [  16/16]  Time: 0.018 (0.245)  Loss:  6.4786 (6.8464)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  3.1250 ( 0.9932)
Train: 8 [   0/16 (  0%)]  Loss: 6.894 (6.89)  Time: 1.448s,  176.82/s  (1.448s,  176.82/s)  LR: 9.982e-02  Data: 1.085 (1.085)
Train: 8 [  15/16 (100%)]  Loss: 7.043 (6.96)  Time: 0.363s,  705.44/s  (0.439s,  583.23/s)  LR: 9.982e-02  Data: 0.000 (0.077)
Test: [   0/16]  Time: 1.054 (1.054)  Loss:  6.7872 (6.7872)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.0000 ( 0.0000)
Test: [  16/16]  Time: 0.017 (0.244)  Loss:  6.5608 (6.8259)  Acc@1:  0.0000 ( 0.1453)  Acc@5:  0.0000 ( 0.9205)
Train: 9 [   0/16 (  0%)]  Loss: 6.900 (6.90)  Time: 1.508s,  169.81/s  (1.508s,  169.81/s)  LR: 9.978e-02  Data: 1.134 (1.134)
Train: 9 [  15/16 (100%)]  Loss: 6.998 (6.93)  Time: 0.363s,  706.17/s  (0.445s,  575.56/s)  LR: 9.978e-02  Data: 0.000 (0.082)
Test: [   0/16]  Time: 1.037 (1.037)  Loss:  6.7893 (6.7893)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.3906 ( 0.3906)
Test: [  16/16]  Time: 0.020 (0.246)  Loss:  6.3837 (6.8087)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  3.1250 ( 1.2112)
Train: 10 [   0/16 (  0%)]  Loss: 6.833 (6.83)  Time: 1.436s,  178.30/s  (1.436s,  178.30/s)  LR: 9.973e-02  Data: 1.073 (1.073)
