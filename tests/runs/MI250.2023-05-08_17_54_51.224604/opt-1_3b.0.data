{"event": "config", "data": {"dirs": {"base": "/milabench/envs", "venv": "/milabench/envs/venv/torch", "data": "/milabench/envs/data", "runs": "/milabench/envs/runs", "extra": "/milabench/envs/extra/opt", "cache": "/milabench/envs/cache"}, "arch": "rocm", "group": "opt", "install_group": "torch", "install_variant": "rocm", "run_name": "redizilo.2023-05-08_17:54:51.224604", "enabled": true, "capabilities": {"nodes": 1}, "max_duration": 600, "voir": {"options": {"stop": 60, "interval": "1s"}}, "config_base": "/milabench/milabench/config", "config_file": "/milabench/milabench/config/standard.yaml", "tags": ["huggingface", "language-modeling", "llm", "multigpu", "nlp", "transformer"], "definition": "/milabench/milabench/benchmarks/accelerate_opt", "plan": {"method": "njobs", "n": 1}, "manager_addr": "override-me", "manager_port": 10000, "cpus_per_gpu": 8, "gradient_accumulation_steps": 1, "max_train_steps": 100, "dataset_name": "wikitext", "dataset_config_name": "wikitext-103-v1", "validation_split_percentage": 5, "use_deepspeed": false, "num_machines": 1, "model_name": "facebook/opt-1.3b", "per_gpu_batch_size": 1, "weight": 5.0, "name": "opt-1_3b", "tag": ["opt-1_3b", "0"], "job-number": 0, "devices": [0, 1, 2, 3, 4, 5, 6, 7]}, "pipe": null}
{"event": "start", "data": {"command": ["accelerate", "launch", "--mixed_precision=fp16", "--dynamo_backend=no", "--machine_rank=0", "--num_machines=1", "--multi_gpu", "--gradient_accumulation_steps=1", "--num_cpu_threads_per_process=8", "--main_process_ip=override-me", "--main_process_port=10000", "--num_processes=8", "/milabench/milabench/benchmarks/accelerate_opt/main.py"], "time": 1683571195.9718585}, "pipe": null}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory\n", "pipe": "stderr"}
{"event": "line", "data": "[05/08/23 18:40:05] INFO     [5/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 5                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 5                                                                                                                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:5                                                                                                                                                   \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                                                                                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:05] INFO     [2/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 2                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 2                                                                                                                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:2                                                                                                                                                   \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                                                                                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:05] INFO     [4/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 4                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 4                                                                                                                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:4                                                                                                                                                   \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                                                                                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:05] INFO     [3/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 3                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 3                                                                                                                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:3                                                                                                                                                   \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                                                                                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:05] INFO     [6/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 6                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 6                                                                                                                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:6                                                                                                                                                   \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                                                                                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:05] INFO     [1/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 1                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 1                                                                                                                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:1                                                                                                                                                   \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                                                                                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:05] INFO     [7/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 7                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 7                                                                                                                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:7                                                                                                                                                   \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                                                                                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:05] INFO     [0/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             Num processes: 8                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Process index: 0                                                                                                                                                 \n", "pipe": "stdout"}
{"event": "line", "data": "                             Local process index: 0                                                                                                                                           \n", "pipe": "stdout"}
{"event": "line", "data": "                             Device: cuda:0                                                                                                                                                   \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "line", "data": "                             Mixed precision type: fp16                                                                                                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                                                                                                                                                                                              \n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [12, 65520], "load": 0.0, "temperature": 33.0}, "1": {"memory": [14, 65520], "load": 0.0, "temperature": 39.0}, "2": {"memory": [14, 65520], "load": 0.0, "temperature": 46.0}, "3": {"memory": [14, 65520], "load": 0.0, "temperature": 38.0}, "4": {"memory": [14, 65520], "load": 0.0, "temperature": 41.0}, "5": {"memory": [14, 65520], "load": 0.0, "temperature": 35.0}, "6": {"memory": [14, 65520], "load": 0.0, "temperature": 42.0}, "7": {"memory": [14, 65520], "load": 0.0, "temperature": 41.0}}}, "pipe": "data"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "[05/08/23 18:40:07] WARNING  [0/8] datasets.builder - Found cached dataset wikitext                                                                                             builder.py:817\n", "pipe": "stdout"}
{"event": "line", "data": "                             (/milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)                     \n", "pipe": "stdout"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "\r  0%|          | 0/3 [00:00<?, ?it/s]", "pipe": "stderr"}
{"event": "line", "data": "\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 2/3 [00:00<00:00,  2.26it/s]", "pipe": "stderr"}
{"event": "line", "data": "\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 2/3 [00:00<00:00,  2.26it/s]\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 2/3 [00:00<00:00,  2.06it/s]\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 2/3 [00:00<00:00,  2.06it/s]\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 2/3 [00:00<00:00,  2.10it/s]\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 2/3 [00:00<00:00,  2.08it/s]\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 2/3 [00:00<00:00,  2.12it/s]\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 2/3 [00:00<00:00,  2.13it/s]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00,  3.38it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00,  3.09it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00,  3.15it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00,  3.11it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00,  3.17it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00,  3.38it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00,  3.09it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00,  3.19it/s]\n", "pipe": "stderr"}
{"event": "line", "data": "loading configuration file config.json from cache at /milabench/envs/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/config.json\n", "pipe": "stderr"}
{"event": "line", "data": "Model config OPTConfig {\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_name_or_path\": \"facebook/opt-1.3b\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_remove_final_layer_norm\": false,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_function\": \"relu\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"architectures\": [\n", "pipe": "stderr"}
{"event": "line", "data": "    \"OPTForCausalLM\"\n", "pipe": "stderr"}
{"event": "line", "data": "  ],\n", "pipe": "stderr"}
{"event": "line", "data": "  \"attention_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"bos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"do_layer_norm_before\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"dropout\": 0.1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"enable_bias\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"eos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"ffn_dim\": 8192,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"hidden_size\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"init_std\": 0.02,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layer_norm_elementwise_affine\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layerdrop\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"max_position_embeddings\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"model_type\": \"opt\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_attention_heads\": 32,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_hidden_layers\": 24,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"pad_token_id\": 1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"prefix\": \"</s>\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"torch_dtype\": \"float16\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"transformers_version\": \"4.27.4\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"use_cache\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"vocab_size\": 50272,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"word_embed_proj_dim\": 2048\n", "pipe": "stderr"}
{"event": "line", "data": "}\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "[05/08/23 18:40:08] WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110\n", "pipe": "stdout"}
{"event": "line", "data": "                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             cache-1b4e61c4f1ef8b68_*_of_00008.arrow                                                                                                                          \n", "pipe": "stdout"}
{"event": "line", "data": "loading configuration file config.json from cache at /milabench/envs/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/config.json\n", "pipe": "stderr"}
{"event": "line", "data": "Model config OPTConfig {\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_name_or_path\": \"facebook/opt-1.3b\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_remove_final_layer_norm\": false,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_function\": \"relu\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"architectures\": [\n", "pipe": "stderr"}
{"event": "line", "data": "    \"OPTForCausalLM\"\n", "pipe": "stderr"}
{"event": "line", "data": "  ],\n", "pipe": "stderr"}
{"event": "line", "data": "  \"attention_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"bos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"do_layer_norm_before\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"dropout\": 0.1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"enable_bias\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"eos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"ffn_dim\": 8192,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"hidden_size\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"init_std\": 0.02,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layer_norm_elementwise_affine\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layerdrop\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"max_position_embeddings\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"model_type\": \"opt\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_attention_heads\": 32,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_hidden_layers\": 24,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"pad_token_id\": 1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"prefix\": \"</s>\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"torch_dtype\": \"float16\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"transformers_version\": \"4.27.4\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"use_cache\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"vocab_size\": 50272,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"word_embed_proj_dim\": 2048\n", "pipe": "stderr"}
{"event": "line", "data": "}\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "loading file vocab.json from cache at /milabench/envs/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/vocab.json\n", "pipe": "stderr"}
{"event": "line", "data": "loading file merges.txt from cache at /milabench/envs/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/merges.txt\n", "pipe": "stderr"}
{"event": "line", "data": "loading file tokenizer.json from cache at None\n", "pipe": "stderr"}
{"event": "line", "data": "loading file added_tokens.json from cache at None\n", "pipe": "stderr"}
{"event": "line", "data": "loading file special_tokens_map.json from cache at /milabench/envs/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/special_tokens_map.json\n", "pipe": "stderr"}
{"event": "line", "data": "loading file tokenizer_config.json from cache at /milabench/envs/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/tokenizer_config.json\n", "pipe": "stderr"}
{"event": "line", "data": "loading configuration file config.json from cache at /milabench/envs/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/config.json\n", "pipe": "stderr"}
{"event": "line", "data": "Model config OPTConfig {\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_name_or_path\": \"facebook/opt-1.3b\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_remove_final_layer_norm\": false,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_function\": \"relu\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"architectures\": [\n", "pipe": "stderr"}
{"event": "line", "data": "    \"OPTForCausalLM\"\n", "pipe": "stderr"}
{"event": "line", "data": "  ],\n", "pipe": "stderr"}
{"event": "line", "data": "  \"attention_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"bos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"do_layer_norm_before\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"dropout\": 0.1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"enable_bias\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"eos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"ffn_dim\": 8192,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"hidden_size\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"init_std\": 0.02,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layer_norm_elementwise_affine\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layerdrop\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"max_position_embeddings\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"model_type\": \"opt\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_attention_heads\": 32,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_hidden_layers\": 24,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"pad_token_id\": 1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"prefix\": \"</s>\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"torch_dtype\": \"float16\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"transformers_version\": \"4.27.4\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"use_cache\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"vocab_size\": 50272,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"word_embed_proj_dim\": 2048\n", "pipe": "stderr"}
{"event": "line", "data": "}\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "loading configuration file config.json from cache at /milabench/envs/cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/8c7b10754972749675d22364c25c428b29face51/config.json\n", "pipe": "stderr"}
{"event": "line", "data": "Model config OPTConfig {\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_name_or_path\": \"facebook/opt-1.3b\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_remove_final_layer_norm\": false,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"activation_function\": \"relu\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"architectures\": [\n", "pipe": "stderr"}
{"event": "line", "data": "    \"OPTForCausalLM\"\n", "pipe": "stderr"}
{"event": "line", "data": "  ],\n", "pipe": "stderr"}
{"event": "line", "data": "  \"attention_dropout\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"bos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"do_layer_norm_before\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"dropout\": 0.1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"enable_bias\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"eos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"ffn_dim\": 8192,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"hidden_size\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"init_std\": 0.02,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layer_norm_elementwise_affine\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"layerdrop\": 0.0,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"max_position_embeddings\": 2048,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"model_type\": \"opt\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_attention_heads\": 32,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"num_hidden_layers\": 24,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"pad_token_id\": 1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"prefix\": \"</s>\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"torch_dtype\": \"float16\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"transformers_version\": \"4.27.4\",\n", "pipe": "stderr"}
{"event": "line", "data": "  \"use_cache\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"vocab_size\": 50272,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"word_embed_proj_dim\": 2048\n", "pipe": "stderr"}
{"event": "line", "data": "}\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "line", "data": "[05/08/23 18:40:09] WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110\n", "pipe": "stdout"}
{"event": "line", "data": "                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             cache-329331b01bd0468e_*_of_00008.arrow                                                                                                                          \n", "pipe": "stdout"}
{"event": "line", "data": "                    WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110\n", "pipe": "stdout"}
{"event": "line", "data": "                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             cache-c60b625823abbe78_*_of_00008.arrow                                                                                                                          \n", "pipe": "stdout"}
{"event": "line", "data": "                    WARNING  [0/8] __main__ - The tokenizer picked seems to have a very large `model_max_length` (1000000000000000019884624838656). Picking 1024 instead. You    logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                             can change that default value by passing --block_size xxx.                                                                                                       \n", "pipe": "stdout"}
{"event": "line", "data": "                    WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110\n", "pipe": "stdout"}
{"event": "line", "data": "                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             cache-87a845baeb5292f0_*_of_00008.arrow                                                                                                                          \n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [267, 65520], "load": 0.0, "temperature": 32.0}, "1": {"memory": [331, 65520], "load": 0.0, "temperature": 38.0}, "2": {"memory": [331, 65520], "load": 0.0, "temperature": 45.0}, "3": {"memory": [331, 65520], "load": 0.0, "temperature": 38.0}, "4": {"memory": [331, 65520], "load": 0.0, "temperature": 40.0}, "5": {"memory": [331, 65520], "load": 0.0, "temperature": 34.0}, "6": {"memory": [267, 65520], "load": 0.0, "temperature": 41.0}, "7": {"memory": [331, 65520], "load": 0.0, "temperature": 40.0}}}, "pipe": "data"}
{"event": "line", "data": "[05/08/23 18:40:10] WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110\n", "pipe": "stdout"}
{"event": "line", "data": "                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             cache-23b43495f74434f7_*_of_00008.arrow                                                                                                                          \n", "pipe": "stdout"}
{"event": "line", "data": "                    WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110\n", "pipe": "stdout"}
{"event": "line", "data": "                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      \n", "pipe": "stdout"}
{"event": "line", "data": "                             cache-7649aa6a833efa01_*_of_00008.arrow                                                                                                                          \n", "pipe": "stdout"}
{"event": "line", "data": "Generate config GenerationConfig {\n", "pipe": "stderr"}
{"event": "line", "data": "  \"_from_model_config\": true,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"bos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"eos_token_id\": 2,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"pad_token_id\": 1,\n", "pipe": "stderr"}
{"event": "line", "data": "  \"transformers_version\": \"4.27.4\"\n", "pipe": "stderr"}
{"event": "line", "data": "}\n", "pipe": "stderr"}
{"event": "line", "data": "\n", "pipe": "stderr"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [267, 65520], "load": 0.0, "temperature": 32.0}, "1": {"memory": [331, 65520], "load": 0.0, "temperature": 39.0}, "2": {"memory": [331, 65520], "load": 0.0, "temperature": 45.0}, "3": {"memory": [331, 65520], "load": 0.0, "temperature": 38.0}, "4": {"memory": [331, 65520], "load": 0.0, "temperature": 40.0}, "5": {"memory": [331, 65520], "load": 0.0, "temperature": 33.0}, "6": {"memory": [267, 65520], "load": 0.0, "temperature": 41.0}, "7": {"memory": [331, 65520], "load": 0.0, "temperature": 39.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [267, 65520], "load": 0.0, "temperature": 32.0}, "1": {"memory": [331, 65520], "load": 0.0, "temperature": 38.0}, "2": {"memory": [331, 65520], "load": 0.0, "temperature": 44.0}, "3": {"memory": [331, 65520], "load": 0.0, "temperature": 37.0}, "4": {"memory": [331, 65520], "load": 0.0, "temperature": 39.0}, "5": {"memory": [331, 65520], "load": 0.0, "temperature": 33.0}, "6": {"memory": [267, 65520], "load": 0.0, "temperature": 41.0}, "7": {"memory": [331, 65520], "load": 0.0, "temperature": 39.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [267, 65520], "load": 0.0, "temperature": 31.0}, "1": {"memory": [331, 65520], "load": 0.0, "temperature": 38.0}, "2": {"memory": [331, 65520], "load": 0.0, "temperature": 44.0}, "3": {"memory": [331, 65520], "load": 0.0, "temperature": 37.0}, "4": {"memory": [331, 65520], "load": 0.0, "temperature": 39.0}, "5": {"memory": [331, 65520], "load": 0.0, "temperature": 32.0}, "6": {"memory": [267, 65520], "load": 0.0, "temperature": 40.0}, "7": {"memory": [331, 65520], "load": 0.0, "temperature": 39.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [267, 65520], "load": 0.0, "temperature": 31.0}, "1": {"memory": [331, 65520], "load": 0.0, "temperature": 37.0}, "2": {"memory": [331, 65520], "load": 0.0, "temperature": 43.0}, "3": {"memory": [331, 65520], "load": 0.0, "temperature": 37.0}, "4": {"memory": [331, 65520], "load": 0.0, "temperature": 39.0}, "5": {"memory": [331, 65520], "load": 0.0, "temperature": 32.0}, "6": {"memory": [267, 65520], "load": 0.0, "temperature": 40.0}, "7": {"memory": [331, 65520], "load": 0.0, "temperature": 39.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [268, 65520], "load": 0.0, "temperature": 31.0}, "1": {"memory": [2856, 65520], "load": 0.0, "temperature": 37.0}, "2": {"memory": [2680, 65520], "load": 0.03, "temperature": 43.0}, "3": {"memory": [4392, 65520], "load": 0.0, "temperature": 37.0}, "4": {"memory": [332, 65520], "load": 0.0, "temperature": 39.0}, "5": {"memory": [332, 65520], "load": 0.0, "temperature": 32.0}, "6": {"memory": [268, 65520], "load": 0.0, "temperature": 40.0}, "7": {"memory": [332, 65520], "load": 0.0, "temperature": 38.0}}}, "pipe": "data"}
{"event": "line", "data": "[05/08/23 18:40:27] INFO     [0/8] __main__ - ***** Running training *****                                                                                                       logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                    INFO     [0/8] __main__ -   Num examples = 115910                                                                                                            logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                    INFO     [0/8] __main__ -   Num Epochs = 1                                                                                                                   logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                    INFO     [0/8] __main__ -   Instantaneous batch size per device = 1                                                                                          logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                    INFO     [0/8] __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8                                                             logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                    INFO     [0/8] __main__ -   Gradient Accumulation steps = 1                                                                                                  logging.py:47\n", "pipe": "stdout"}
{"event": "line", "data": "                    INFO     [0/8] __main__ -   Total optimization steps = 100                                                                                                   logging.py:47\n", "pipe": "stdout"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [14974, 65520], "load": 0.0, "temperature": 31.0}, "1": {"memory": [15043, 65520], "load": 0.0, "temperature": 37.0}, "2": {"memory": [15043, 65520], "load": 0.01, "temperature": 44.0}, "3": {"memory": [15043, 65520], "load": 0.0, "temperature": 37.0}, "4": {"memory": [15043, 65520], "load": 0.13, "temperature": 39.0}, "5": {"memory": [15043, 65520], "load": 0.01, "temperature": 32.0}, "6": {"memory": [14979, 65520], "load": 0.0, "temperature": 40.0}, "7": {"memory": [15043, 65520], "load": 0.0, "temperature": 38.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 11.244769096374512}, "pipe": "data"}
{"event": "line", "data": "[05/08/23 18:40:28] INFO     [0/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:28] INFO     [3/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:28] INFO     [2/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:28] INFO     [5/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:28] INFO     [7/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:28] INFO     [6/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:28] INFO     [4/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140\n", "pipe": "stdout"}
{"event": "line", "data": "[05/08/23 18:40:28] INFO     [1/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140\n", "pipe": "stdout"}
{"event": "data", "data": {"task": "train", "loss": 12.267850875854492}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 12.49117660522461}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 12.15821361541748}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.405855178833008}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 7.7597895721278345, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.86361312866211}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 36.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 42.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 48.0}, "3": {"memory": [42543, 65520], "load": 1.0, "temperature": 42.0}, "4": {"memory": [42543, 65520], "load": 1.0, "temperature": 44.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 37.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 44.0}, "7": {"memory": [42543, 65520], "load": 1.0, "temperature": 43.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.296810150146484}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.535013198852539}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.780399426843958, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.246511459350586}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.04898452758789}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.89249038696289}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 37.0}, "1": {"memory": [42543, 65520], "load": 0.46, "temperature": 44.0}, "2": {"memory": [42543, 65520], "load": 0.99, "temperature": 51.0}, "3": {"memory": [42543, 65520], "load": 1.0, "temperature": 44.0}, "4": {"memory": [42543, 65520], "load": 0.99, "temperature": 46.0}, "5": {"memory": [42543, 65520], "load": 0.18, "temperature": 39.0}, "6": {"memory": [42479, 65520], "load": 0.99, "temperature": 47.0}, "7": {"memory": [42543, 65520], "load": 0.94, "temperature": 44.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 12.800393892329145, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.792084693908691}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.784997940063477}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.983820915222168}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.779639356893846, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.83812141418457}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.679388046264648}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.665876388549805}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 38.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 45.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 52.0}, "3": {"memory": [42543, 65520], "load": 1.0, "temperature": 44.0}, "4": {"memory": [42543, 65520], "load": 1.0, "temperature": 47.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 40.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 48.0}, "7": {"memory": [42543, 65520], "load": 1.0, "temperature": 46.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.794046527689279, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.576091766357422}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.709940910339355}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.645634651184082}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.601832552665183, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.480047225952148}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.647114753723145}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 39.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 45.0}, "2": {"memory": [42543, 65520], "load": 0.89, "temperature": 53.0}, "3": {"memory": [42543, 65520], "load": 0.99, "temperature": 45.0}, "4": {"memory": [42543, 65520], "load": 0.85, "temperature": 48.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 41.0}, "6": {"memory": [42479, 65520], "load": 0.91, "temperature": 49.0}, "7": {"memory": [42543, 65520], "load": 0.99, "temperature": 47.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.74467945098877}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.03396371922193, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.487750053405762}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.774653434753418}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.513618469238281}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.655316665895054, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.801486015319824}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.115788459777832}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 41.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 46.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 54.0}, "3": {"memory": [42543, 65520], "load": 1.0, "temperature": 46.0}, "4": {"memory": [42543, 65520], "load": 1.0, "temperature": 49.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 42.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 49.0}, "7": {"memory": [42543, 65520], "load": 1.0, "temperature": 47.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.904106140136719}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.73548205310488, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.38658332824707}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.663514137268066}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.691375732421875}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.61407475436644, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.585005760192871}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 40.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 47.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 55.0}, "3": {"memory": [42543, 65520], "load": 0.05, "temperature": 47.0}, "4": {"memory": [42543, 65520], "load": 0.65, "temperature": 49.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 42.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 51.0}, "7": {"memory": [42543, 65520], "load": 0.99, "temperature": 49.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.884039878845215}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.762312889099121}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.026884507625512, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.447751998901367}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.851224899291992}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.089624404907227}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.610778470925997, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.650735855102539}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 41.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 47.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 55.0}, "3": {"memory": [42543, 65520], "load": 1.0, "temperature": 48.0}, "4": {"memory": [42543, 65520], "load": 1.0, "temperature": 50.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 43.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 51.0}, "7": {"memory": [42543, 65520], "load": 1.0, "temperature": 48.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.300397872924805}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.81367015838623}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.766950635486852, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.732902526855469}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.692922592163086}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.698410987854004}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 41.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 47.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 56.0}, "3": {"memory": [42543, 65520], "load": 0.99, "temperature": 48.0}, "4": {"memory": [42543, 65520], "load": 0.08, "temperature": 50.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 44.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 52.0}, "7": {"memory": [42543, 65520], "load": 0.99, "temperature": 49.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 12.682864066348888, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.740583419799805}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.831542015075684}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.832673072814941}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.772984843584073, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.736977577209473}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.781484603881836}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.61855411529541}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 43.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 48.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 57.0}, "3": {"memory": [42543, 65520], "load": 1.0, "temperature": 49.0}, "4": {"memory": [42543, 65520], "load": 1.0, "temperature": 50.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 44.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 52.0}, "7": {"memory": [42543, 65520], "load": 1.0, "temperature": 51.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.867333937363195, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.145726203918457}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.516352653503418}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.281543731689453}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.659168881755816, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.550651550292969}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.686450004577637}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 43.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 48.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 58.0}, "3": {"memory": [42543, 65520], "load": 0.98, "temperature": 50.0}, "4": {"memory": [42543, 65520], "load": 0.22, "temperature": 51.0}, "5": {"memory": [42543, 65520], "load": 0.91, "temperature": 44.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 53.0}, "7": {"memory": [42543, 65520], "load": 0.99, "temperature": 51.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.67166519165039}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.034476784409485, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.282825469970703}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.948747634887695}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.072555541992188}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.595777338890935, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.024239540100098}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.413820266723633}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 43.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 49.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 59.0}, "3": {"memory": [42543, 65520], "load": 1.0, "temperature": 50.0}, "4": {"memory": [42543, 65520], "load": 1.0, "temperature": 51.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 45.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 54.0}, "7": {"memory": [42543, 65520], "load": 1.0, "temperature": 51.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.847414016723633}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.80485570517107, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.87613582611084}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.783452987670898}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.009074211120605}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.639008291288404, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.758140563964844}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 43.0}, "1": {"memory": [42543, 65520], "load": 0.31, "temperature": 49.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 59.0}, "3": {"memory": [42543, 65520], "load": 0.99, "temperature": 51.0}, "4": {"memory": [42543, 65520], "load": 0.99, "temperature": 52.0}, "5": {"memory": [42543, 65520], "load": 0.98, "temperature": 45.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 54.0}, "7": {"memory": [42543, 65520], "load": 0.99, "temperature": 51.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.540507316589355}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.749835968017578}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.036355555279279, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.974737167358398}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.312299728393555}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.606141090393066}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.597898209314476, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.646730422973633}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 44.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 49.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 59.0}, "3": {"memory": [42543, 65520], "load": 1.0, "temperature": 51.0}, "4": {"memory": [42543, 65520], "load": 1.0, "temperature": 52.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 45.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 55.0}, "7": {"memory": [42543, 65520], "load": 1.0, "temperature": 52.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.761210441589355}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.720009803771973}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.734910444930488, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.869464874267578}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.370746612548828}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.858521461486816}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 43.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 49.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 59.0}, "3": {"memory": [42543, 65520], "load": 0.27, "temperature": 51.0}, "4": {"memory": [42543, 65520], "load": 0.08, "temperature": 52.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 46.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 55.0}, "7": {"memory": [42543, 65520], "load": 1.0, "temperature": 52.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 12.882660923367059, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.95586109161377}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.518830299377441}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.7466402053833}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.84934967996613, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.849822998046875}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.72934627532959}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.823227882385254}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 44.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 49.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 60.0}, "3": {"memory": [42543, 65520], "load": 1.0, "temperature": 52.0}, "4": {"memory": [42543, 65520], "load": 1.0, "temperature": 52.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 46.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 56.0}, "7": {"memory": [42543, 65520], "load": 1.0, "temperature": 52.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.830434477954602, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.45942497253418}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.88857650756836}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 10.002543449401855}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.699678577358359, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.768073081970215}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.339152336120605}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 44.0}, "1": {"memory": [42543, 65520], "load": 0.9, "temperature": 49.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 60.0}, "3": {"memory": [42543, 65520], "load": 0.32, "temperature": 52.0}, "4": {"memory": [42543, 65520], "load": 0.99, "temperature": 52.0}, "5": {"memory": [42543, 65520], "load": 0.74, "temperature": 46.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 55.0}, "7": {"memory": [42543, 65520], "load": 0.99, "temperature": 53.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.744702339172363}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.005419048632938, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.858338356018066}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.861623764038086}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.690442085266113}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.556218480152655, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.622380256652832}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 8.749312400817871}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 44.0}, "1": {"memory": [42543, 65520], "load": 1.0, "temperature": 49.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 60.0}, "3": {"memory": [42543, 65520], "load": 1.0, "temperature": 52.0}, "4": {"memory": [42543, 65520], "load": 1.0, "temperature": 52.0}, "5": {"memory": [42543, 65520], "load": 1.0, "temperature": 46.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 56.0}, "7": {"memory": [42543, 65520], "load": 1.0, "temperature": 53.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.984437942504883}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 13.78416209731497, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.804292678833008}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.287416458129883}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.365129470825195}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 14.557353095360845, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.63882064819336}, "pipe": "data"}
{"event": "data", "data": {"task": "main", "gpudata": {"0": {"memory": [42479, 65520], "load": 0.0, "temperature": 43.0}, "1": {"memory": [42543, 65520], "load": 0.8, "temperature": 49.0}, "2": {"memory": [42543, 65520], "load": 1.0, "temperature": 61.0}, "3": {"memory": [42543, 65520], "load": 0.99, "temperature": 52.0}, "4": {"memory": [42543, 65520], "load": 0.99, "temperature": 53.0}, "5": {"memory": [42543, 65520], "load": 0.22, "temperature": 46.0}, "6": {"memory": [42479, 65520], "load": 1.0, "temperature": 56.0}, "7": {"memory": [42543, 65520], "load": 0.94, "temperature": 53.0}}}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.620251655578613}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.947088241577148}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "rate": 12.988007968538723, "units": "items/s"}, "pipe": "data"}
{"event": "data", "data": {"task": "train", "loss": 9.93880558013916}, "pipe": "data"}
{"event": "end", "data": {"command": ["accelerate", "launch", "--mixed_precision=fp16", "--dynamo_backend=no", "--machine_rank=0", "--num_machines=1", "--multi_gpu", "--gradient_accumulation_steps=1", "--num_cpu_threads_per_process=8", "--main_process_ip=override-me", "--main_process_port=10000", "--num_processes=8", "/milabench/milabench/benchmarks/accelerate_opt/main.py"], "time": 1683571289.2968082, "return_code": 0}, "pipe": null}
