/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
Added key: store_based_barrier_key:1 to store for rank: 1
Added key: store_based_barrier_key:1 to store for rank: 2
Added key: store_based_barrier_key:1 to store for rank: 3
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
Added key: store_based_barrier_key:1 to store for rank: 6
Added key: store_based_barrier_key:1 to store for rank: 7
Added key: store_based_barrier_key:1 to store for rank: 0
Added key: store_based_barrier_key:1 to store for rank: 4
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
/opt/amdgpu/share/libdrm/amdgpu.ids: No such file or directory
Added key: store_based_barrier_key:1 to store for rank: 5
Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
Training in distributed mode with multiple processes, 1 device per process.Process 5, total 8, device cuda:5.
Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
Training in distributed mode with multiple processes, 1 device per process.Process 2, total 8, device cuda:2.
Training in distributed mode with multiple processes, 1 device per process.Process 3, total 8, device cuda:3.
Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
Training in distributed mode with multiple processes, 1 device per process.Process 4, total 8, device cuda:4.
Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
Training in distributed mode with multiple processes, 1 device per process.Process 7, total 8, device cuda:7.
Training in distributed mode with multiple processes, 1 device per process.Process 6, total 8, device cuda:6.
Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
Training in distributed mode with multiple processes, 1 device per process.Process 1, total 8, device cuda:1.
Training in distributed mode with multiple processes, 1 device per process.Process 0, total 8, device cuda:0.
Model davit_large created, param count:196811752
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.95
	crop_mode: center
Learning rate (0.04) calculated from base learning rate (0.01) and global batch size (1024) with linear scaling.
Using native Torch AMP. Training in mixed precision.
Using native Torch DistributedDataParallel.
Scheduled epochs: 300. LR stepped per epoch.
/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1536, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1536, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1536, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1536, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1536, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1536, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1536, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1536, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1536, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1536, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1536, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1536, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1536, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1536, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1536, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1536, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Train: 0 [   0/4 (  0%)]  Loss: 7.221 (7.22)  Time: 4.106s,  249.40/s  (4.106s,  249.40/s)  LR: 1.000e-05  Data: 0.702 (0.702)
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Train: 0 [   3/4 (100%)]  Loss: 7.247 (7.23)  Time: 2.829s,  361.93/s  (3.158s,  324.26/s)  LR: 1.000e-05  Data: 0.001 (0.181)
Distributing BatchNorm running means and vars
Test: [   0/4]  Time: 1.323 (1.323)  Loss:  7.2865 (7.2865)  Acc@1:  0.2930 ( 0.2930)  Acc@5:  0.4883 ( 0.4883)
Test: [   4/4]  Time: 0.231 (0.679)  Loss:  7.0638 (7.2443)  Acc@1:  0.0000 ( 0.0969)  Acc@5:  0.0000 ( 0.5087)
Current checkpoints:
 ('/milabench/envs/extra/timm/redizilo.2023-05-08_17:54:51.224604/davit_large-multi.0/20230508-183715-davit_large-224/checkpoint-0.pth.tar', 0.09689922480620156)

Train: 1 [   0/4 (  0%)]  Loss: 7.233 (7.23)  Time: 3.452s,  296.62/s  (3.452s,  296.62/s)  LR: 8.008e-03  Data: 0.600 (0.600)
Train: 1 [   3/4 (100%)]  Loss: 7.003 (7.12)  Time: 2.868s,  357.09/s  (3.018s,  339.30/s)  LR: 8.008e-03  Data: 0.001 (0.157)
Distributing BatchNorm running means and vars
Test: [   0/4]  Time: 1.140 (1.140)  Loss:  6.9700 (6.9700)  Acc@1:  0.1953 ( 0.1953)  Acc@5:  1.0742 ( 1.0742)
Test: [   4/4]  Time: 0.027 (0.603)  Loss:  6.7299 (6.9363)  Acc@1:  0.0000 ( 0.0969)  Acc@5:  0.0000 ( 0.6541)
Train: 2 [   0/4 (  0%)]  Loss: 6.937 (6.94)  Time: 3.401s,  301.11/s  (3.401s,  301.11/s)  LR: 1.601e-02  Data: 0.551 (0.551)
Train: 2 [   3/4 (100%)]  Loss: 6.957 (6.95)  Time: 2.854s,  358.83/s  (2.993s,  342.08/s)  LR: 1.601e-02  Data: 0.001 (0.143)
Distributing BatchNorm running means and vars
Test: [   0/4]  Time: 1.110 (1.110)  Loss:  6.8539 (6.8539)  Acc@1:  0.1953 ( 0.1953)  Acc@5:  1.3672 ( 1.3672)
Test: [   4/4]  Time: 0.024 (0.597)  Loss:  6.4858 (6.8479)  Acc@1:  0.0000 ( 0.2422)  Acc@5:  0.0000 ( 1.4535)
Current checkpoints:
 ('/milabench/envs/extra/timm/redizilo.2023-05-08_17:54:51.224604/davit_large-multi.0/20230508-183715-davit_large-224/checkpoint-2.pth.tar', 0.24224806201550386)

Train: 3 [   0/4 (  0%)]  Loss: 6.872 (6.87)  Time: 3.400s,  301.13/s  (3.400s,  301.13/s)  LR: 2.400e-02  Data: 0.544 (0.544)
Train: 3 [   3/4 (100%)]  Loss: 6.967 (6.92)  Time: 2.843s,  360.20/s  (2.995s,  341.89/s)  LR: 2.400e-02  Data: 0.001 (0.144)
Distributing BatchNorm running means and vars
Test: [   0/4]  Time: 1.141 (1.141)  Loss:  6.8028 (6.8028)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  1.3672 ( 1.3672)
Test: [   4/4]  Time: 0.024 (0.603)  Loss:  6.2546 (6.8256)  Acc@1:  0.0000 ( 0.2907)  Acc@5:  0.0000 ( 1.1870)
Current checkpoints:
 ('/milabench/envs/extra/timm/redizilo.2023-05-08_17:54:51.224604/davit_large-multi.0/20230508-183715-davit_large-224/checkpoint-3.pth.tar', 0.29069767441860467)

Train: 4 [   0/4 (  0%)]  Loss: 6.843 (6.84)  Time: 3.399s,  301.31/s  (3.399s,  301.31/s)  LR: 3.200e-02  Data: 0.543 (0.543)
Train: 4 [   3/4 (100%)]  Loss: 6.985 (6.91)  Time: 2.853s,  358.89/s  (2.999s,  341.40/s)  LR: 3.200e-02  Data: 0.001 (0.144)
Distributing BatchNorm running means and vars
Test: [   0/4]  Time: 1.119 (1.119)  Loss:  6.7876 (6.7876)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  0.8789 ( 0.8789)
Test: [   4/4]  Time: 0.029 (0.599)  Loss:  6.3145 (6.8137)  Acc@1:  0.0000 ( 0.1696)  Acc@5:  3.1250 ( 0.9932)
Train: 5 [   0/4 (  0%)]  Loss: 6.848 (6.85)  Time: 3.349s,  305.72/s  (3.349s,  305.72/s)  LR: 3.997e-02  Data: 0.492 (0.492)
Memory access fault by GPU node-9 (Agent handle: 0x7e76370) on address 0x7fc0d4600000. Reason: Unknown.
Memory access fault by GPU node-7 (Agent handle: 0x7af02a0) on address 0x7fe7a4600000. Reason: Unknown.
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 171385 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 171386 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 171387 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 171388 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 171389 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 171390 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 171391 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -6) local_rank: 7 (pid: 171392) of binary: /milabench/envs/venv/torch/bin/python
Traceback (most recent call last):
  File "/milabench/envs/venv/torch/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
voir FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-05-08_18:38:50
  host      : 43d4ac7988e0
  rank      : 7 (local_rank: 7)
  exitcode  : -6 (pid: 171392)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 171392
=======================================================
