[05/08/23 18:41:38] INFO     [7/8] __main__ - Distributed environment: DEEPSPEED                                                                                                 logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 7                                                                                                                                                 
                             Local process index: 7                                                                                                                                           
                             Device: cuda:7                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                             ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage':               
                             2, 'offload_optimizer': {'device': 'none'}, 'offload_param': {'device': 'none'}, 'stage3_gather_16bit_weights_on_model_save': False},                            
                             'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}                                                                
                                                                                                                                                                                              
[05/08/23 18:41:38] INFO     [1/8] __main__ - Distributed environment: DEEPSPEED                                                                                                 logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 1                                                                                                                                                 
                             Local process index: 1                                                                                                                                           
                             Device: cuda:1                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                             ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage':               
                             2, 'offload_optimizer': {'device': 'none'}, 'offload_param': {'device': 'none'}, 'stage3_gather_16bit_weights_on_model_save': False},                            
                             'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}                                                                
                                                                                                                                                                                              
[05/08/23 18:41:38] INFO     [4/8] __main__ - Distributed environment: DEEPSPEED                                                                                                 logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 4                                                                                                                                                 
                             Local process index: 4                                                                                                                                           
                             Device: cuda:4                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                             ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage':               
                             2, 'offload_optimizer': {'device': 'none'}, 'offload_param': {'device': 'none'}, 'stage3_gather_16bit_weights_on_model_save': False},                            
                             'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}                                                                
                                                                                                                                                                                              
[05/08/23 18:41:38] INFO     [2/8] __main__ - Distributed environment: DEEPSPEED                                                                                                 logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 2                                                                                                                                                 
                             Local process index: 2                                                                                                                                           
                             Device: cuda:2                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                             ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage':               
                             2, 'offload_optimizer': {'device': 'none'}, 'offload_param': {'device': 'none'}, 'stage3_gather_16bit_weights_on_model_save': False},                            
                             'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}                                                                
                                                                                                                                                                                              
[05/08/23 18:41:38] INFO     [5/8] __main__ - Distributed environment: DEEPSPEED                                                                                                 logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 5                                                                                                                                                 
                             Local process index: 5                                                                                                                                           
                             Device: cuda:5                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                             ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage':               
                             2, 'offload_optimizer': {'device': 'none'}, 'offload_param': {'device': 'none'}, 'stage3_gather_16bit_weights_on_model_save': False},                            
                             'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}                                                                
                                                                                                                                                                                              
[05/08/23 18:41:38] INFO     [6/8] __main__ - Distributed environment: DEEPSPEED                                                                                                 logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 6                                                                                                                                                 
                             Local process index: 6                                                                                                                                           
                             Device: cuda:6                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                             ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage':               
                             2, 'offload_optimizer': {'device': 'none'}, 'offload_param': {'device': 'none'}, 'stage3_gather_16bit_weights_on_model_save': False},                            
                             'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}                                                                
                                                                                                                                                                                              
[05/08/23 18:41:38] INFO     [3/8] __main__ - Distributed environment: DEEPSPEED                                                                                                 logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 3                                                                                                                                                 
                             Local process index: 3                                                                                                                                           
                             Device: cuda:3                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                             ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage':               
                             2, 'offload_optimizer': {'device': 'none'}, 'offload_param': {'device': 'none'}, 'stage3_gather_16bit_weights_on_model_save': False},                            
                             'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}                                                                
                                                                                                                                                                                              
[05/08/23 18:41:38] INFO     [0/8] __main__ - Distributed environment: DEEPSPEED                                                                                                 logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 0                                                                                                                                                 
                             Local process index: 0                                                                                                                                           
                             Device: cuda:0                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                             ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage':               
                             2, 'offload_optimizer': {'device': 'none'}, 'offload_param': {'device': 'none'}, 'stage3_gather_16bit_weights_on_model_save': False},                            
                             'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}                                                                
                                                                                                                                                                                              
[05/08/23 18:41:39] WARNING  [0/8] datasets.builder - Found cached dataset wikitext                                                                                             builder.py:817
                             (/milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)                     
[05/08/23 18:41:40] WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110
                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      
                             cache-a9f98f4245980a05_*_of_00008.arrow                                                                                                                          
                    WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110
                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      
                             cache-85db34bbdde76966_*_of_00008.arrow                                                                                                                          
                    WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110
                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      
                             cache-911038f3ecefb91d_*_of_00008.arrow                                                                                                                          
                    WARNING  [0/8] __main__ - The tokenizer picked seems to have a very large `model_max_length` (1000000000000000019884624838656). Picking 1024 instead. You    logging.py:47
                             can change that default value by passing --block_size xxx.                                                                                                       
                    WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110
                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      
                             cache-4b0b79af86b40fe7_*_of_00008.arrow                                                                                                                          
[05/08/23 18:41:41] WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110
                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      
                             cache-16a17d1415aa7b1e_*_of_00008.arrow                                                                                                                          
                    WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110
                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      
                             cache-3b448ee369e6697b_*_of_00008.arrow                                                                                                                          
[2023-05-08 18:42:44,771] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[2023-05-08 18:42:45,245] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[2023-05-08 18:42:45,256] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[2023-05-08 18:42:45,277] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[2023-05-08 18:42:45,295] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[2023-05-08 18:42:47,761] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[05/08/23 18:42:51] INFO     [3/8] torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 3                                      distributed_c10d.py:432
[05/08/23 18:42:51] INFO     [4/8] torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 4                                      distributed_c10d.py:432
[05/08/23 18:42:52] INFO     [7/8] torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 7                                      distributed_c10d.py:432
[05/08/23 18:42:52] INFO     [1/8] torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1                                      distributed_c10d.py:432
[05/08/23 18:42:52] INFO     [6/8] torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 6                                      distributed_c10d.py:432
[05/08/23 18:42:55] INFO     [5/8] torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 5                                      distributed_c10d.py:432
[2023-05-08 18:42:55,347] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[05/08/23 18:42:56] INFO     [0/8] accelerate.accelerator - Since you passed both train and evaluation dataloader, `is_train_batch_min` (here True will decide the               logging.py:47
                             `train_batch_size` (1).                                                                                                                                          
[2023-05-08 18:42:56,493] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown
[05/08/23 18:43:01] INFO     [3/8] torch.distributed.distributed_c10d - Waiting in store based barrier to initialize process group for rank: 3, key:                   distributed_c10d.py:450
                             store_based_barrier_key:2 (world_size=8, worker_count=6, timeout=0:30:00)                                                                                        
[05/08/23 18:43:01] INFO     [4/8] torch.distributed.distributed_c10d - Waiting in store based barrier to initialize process group for rank: 4, key:                   distributed_c10d.py:450
                             store_based_barrier_key:2 (world_size=8, worker_count=6, timeout=0:30:00)                                                                                        
[05/08/23 18:43:02] INFO     [7/8] torch.distributed.distributed_c10d - Waiting in store based barrier to initialize process group for rank: 7, key:                   distributed_c10d.py:450
                             store_based_barrier_key:2 (world_size=8, worker_count=6, timeout=0:30:00)                                                                                        
[05/08/23 18:43:02] INFO     [1/8] torch.distributed.distributed_c10d - Waiting in store based barrier to initialize process group for rank: 1, key:                   distributed_c10d.py:450
                             store_based_barrier_key:2 (world_size=8, worker_count=6, timeout=0:30:00)                                                                                        
[05/08/23 18:43:02] INFO     [6/8] torch.distributed.distributed_c10d - Waiting in store based barrier to initialize process group for rank: 6, key:                   distributed_c10d.py:450
                             store_based_barrier_key:2 (world_size=8, worker_count=6, timeout=0:30:00)                                                                                        
[05/08/23 18:43:02] INFO     [2/8] torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 2                                      distributed_c10d.py:432
[05/08/23 18:43:04] INFO     [0/8] torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0                                      distributed_c10d.py:432
                    INFO     [0/8] torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.          distributed_c10d.py:466
[05/08/23 18:43:04] INFO     [3/8] torch.distributed.distributed_c10d - Rank 3: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.          distributed_c10d.py:466
[05/08/23 18:43:04] INFO     [7/8] torch.distributed.distributed_c10d - Rank 7: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.          distributed_c10d.py:466
[05/08/23 18:43:04] INFO     [6/8] torch.distributed.distributed_c10d - Rank 6: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.          distributed_c10d.py:466
[05/08/23 18:43:04] INFO     [4/8] torch.distributed.distributed_c10d - Rank 4: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.          distributed_c10d.py:466
[05/08/23 18:43:04] INFO     [1/8] torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.          distributed_c10d.py:466
[05/08/23 18:43:04] INFO     [5/8] torch.distributed.distributed_c10d - Rank 5: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.          distributed_c10d.py:466
[05/08/23 18:43:04] INFO     [2/8] torch.distributed.distributed_c10d - Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.          distributed_c10d.py:466
[2023-05-08 18:43:04,252] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-05-08 18:43:04,254] [INFO] [logging.py:93:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-05-08 18:43:04,254] [INFO] [logging.py:93:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-05-08 18:43:04,278] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-05-08 18:43:04,278] [INFO] [utils.py:55:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2023-05-08 18:43:04,279] [INFO] [logging.py:93:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[2023-05-08 18:43:04,279] [INFO] [stage_1_and_2.py:144:__init__] Reduce bucket size 500,000,000
[2023-05-08 18:43:04,279] [INFO] [stage_1_and_2.py:145:__init__] Allgather bucket size 500,000,000
[2023-05-08 18:43:04,279] [INFO] [stage_1_and_2.py:146:__init__] CPU Offload: False
[2023-05-08 18:43:04,279] [INFO] [stage_1_and_2.py:147:__init__] Round robin gradient partitioning: False
[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /milabench/envs/venv/torch/lib/python3.9/site-packages/torch/include -isystem /milabench/envs/venv/torch/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /milabench/envs/venv/torch/lib/python3.9/site-packages/torch/include/TH -isystem /milabench/envs/venv/torch/lib/python3.9/site-packages/torch/include/THC -isystem /opt/anaconda/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /milabench/envs/venv/torch/lib/python3.9/site-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o -fPIC -D__HIP_PLATFORM_HCC__=1 -DUSE_ROCM=1
[2/2] c++ flatten_unflatten.o -shared -L/milabench/envs/venv/torch/lib/python3.9/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so
Time to load utils op: 10.766638278961182 seconds
Time to load utils op: 10.623243570327759 seconds
Time to load utils op: 10.821872472763062 secondsTime to load utils op: 10.82172966003418 seconds

Time to load utils op: 10.822834491729736 seconds
Time to load utils op: 10.822640419006348 seconds
Time to load utils op: 10.822596788406372 seconds
Time to load utils op: 10.827074766159058 seconds
Rank: 2 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 4 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 5 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 6 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 7 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 1 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 3 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Rank: 0 partition count [8, 8] and sizes[(832124928, False), (180736, False)] 
Time to load utils op: 0.0005650520324707031 seconds
Time to load utils op: 0.00054168701171875 seconds
Time to load utils op: 0.0005297660827636719 seconds
Time to load utils op: 0.0005233287811279297 seconds
Time to load utils op: 0.0009570121765136719 seconds
Time to load utils op: 0.0006494522094726562 seconds
Time to load utils op: 0.0005614757537841797 seconds
[2023-05-08 18:43:26,877] [INFO] [utils.py:829:see_memory_usage] Before initializing optimizer states
[2023-05-08 18:43:26,878] [INFO] [utils.py:830:see_memory_usage] MA 15.5 GB         Max_MA 17.05 GB         CA 15.52 GB         Max_CA 17 GB 
[2023-05-08 18:43:26,878] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 27.31 GB, percent = 1.4%
[2023-05-08 18:43:27,005] [INFO] [utils.py:829:see_memory_usage] After initializing optimizer states
[2023-05-08 18:43:27,005] [INFO] [utils.py:830:see_memory_usage] MA 21.7 GB         Max_MA 31.0 GB         CA 31.04 GB         Max_CA 31 GB 
[2023-05-08 18:43:27,005] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 27.32 GB, percent = 1.4%
[2023-05-08 18:43:27,005] [INFO] [stage_1_and_2.py:520:__init__] optimizer state initialized
[2023-05-08 18:43:27,096] [INFO] [utils.py:829:see_memory_usage] After initializing ZeRO optimizer
[2023-05-08 18:43:27,096] [INFO] [utils.py:830:see_memory_usage] MA 21.7 GB         Max_MA 21.7 GB         CA 31.04 GB         Max_CA 31 GB 
[2023-05-08 18:43:27,097] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 27.32 GB, percent = 1.4%
[2023-05-08 18:43:27,099] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2023-05-08 18:43:27,099] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-05-08 18:43:27,099] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2023-05-08 18:43:27,099] [INFO] [logging.py:93:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05, 5e-05], mom=[(0.9, 0.999), (0.9, 0.999)]
[2023-05-08 18:43:27,099] [INFO] [config.py:1018:print] DeepSpeedEngine configuration:
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   amp_enabled .................. False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   amp_params ................... False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   bfloat16_enabled ............. False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   checkpoint_parallel_write_pipeline  False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   checkpoint_tag_validation_enabled  True
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   checkpoint_tag_validation_fail  False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc9151f0af0>
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   communication_data_type ...... None
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   curriculum_enabled_legacy .... False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   curriculum_params_legacy ..... False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   data_efficiency_enabled ...... False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   dataloader_drop_last ......... False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   disable_allgather ............ False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   dump_state ................... False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   dynamic_loss_scale_args ...... None
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   eigenvalue_enabled ........... False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   eigenvalue_gas_boundary_resolution  1
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   eigenvalue_layer_num ......... 0
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   eigenvalue_max_iter .......... 100
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   eigenvalue_stability ......... 1e-06
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   eigenvalue_tol ............... 0.01
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   eigenvalue_verbose ........... False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   elasticity_enabled ........... False
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-05-08 18:43:27,100] [INFO] [config.py:1022:print]   fp16_auto_cast ............... True
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   fp16_enabled ................. True
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   fp16_master_weights_and_gradients  False
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   global_rank .................. 0
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   grad_accum_dtype ............. None
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   gradient_accumulation_steps .. 1
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   gradient_clipping ............ 0.0
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   gradient_predivide_factor .... 1.0
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   initial_dynamic_scale ........ 65536
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   load_universal_checkpoint .... False
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   loss_scale ................... 0
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   memory_breakdown ............. False
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   optimizer_legacy_fusion ...... False
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   optimizer_name ............... None
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   optimizer_params ............. None
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   pld_enabled .................. False
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   pld_params ................... False
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   prescale_gradients ........... False
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   scheduler_name ............... None
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   scheduler_params ............. None
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   sparse_attention ............. None
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   sparse_gradients_enabled ..... False
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   steps_per_print .............. inf
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   train_batch_size ............. 8
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   train_micro_batch_size_per_gpu  1
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   use_node_local_storage ....... False
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   wall_clock_breakdown ......... False
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   world_size ................... 8
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   zero_allow_untested_optimizer  True
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   zero_enabled ................. True
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   zero_force_ds_cpu_optimizer .. True
[2023-05-08 18:43:27,101] [INFO] [config.py:1022:print]   zero_optimization_stage ...... 2
[2023-05-08 18:43:27,101] [INFO] [config.py:1007:print_user_config]   json = {
    "train_batch_size": 8, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "none"
        }, 
        "offload_param": {
            "device": "none"
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "steps_per_print": inf, 
    "fp16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "bf16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
Time to load utils op: 0.0004360675811767578 seconds
[05/08/23 18:43:27] INFO     [0/8] __main__ - ***** Running training *****                                                                                                       logging.py:47
                    INFO     [0/8] __main__ -   Num examples = 115910                                                                                                            logging.py:47
                    INFO     [0/8] __main__ -   Num Epochs = 1                                                                                                                   logging.py:47
                    INFO     [0/8] __main__ -   Instantaneous batch size per device = 1                                                                                          logging.py:47
                    INFO     [0/8] __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8                                                             logging.py:47
                    INFO     [0/8] __main__ -   Gradient Accumulation steps = 1                                                                                                  logging.py:47
                    INFO     [0/8] __main__ -   Total optimization steps = 100                                                                                                   logging.py:47
[2023-05-08 18:43:30,878] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648
[2023-05-08 18:43:34,179] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824
[2023-05-08 18:43:37,464] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912
[2023-05-08 18:43:40,751] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456
[2023-05-08 18:43:44,028] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728
[2023-05-08 18:43:47,306] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864
[2023-05-08 18:43:50,609] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432
[2023-05-08 18:43:53,904] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216
[2023-05-08 18:43:57,177] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608
[2023-05-08 18:44:00,455] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304
[2023-05-08 18:44:03,964] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152
[2023-05-08 18:44:07,240] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576
[2023-05-08 18:44:10,512] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576, reducing to 524288
[2023-05-08 18:44:13,774] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288, reducing to 262144
[2023-05-08 18:44:17,044] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072
[2023-05-08 18:44:20,342] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072, reducing to 65536
[2023-05-08 18:44:23,657] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768
[2023-05-08 18:44:34,192] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384
