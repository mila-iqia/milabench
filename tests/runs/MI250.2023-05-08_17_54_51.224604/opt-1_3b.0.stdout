[05/08/23 18:40:05] INFO     [5/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 5                                                                                                                                                 
                             Local process index: 5                                                                                                                                           
                             Device: cuda:5                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                                                                                                                                                                                              
[05/08/23 18:40:05] INFO     [2/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 2                                                                                                                                                 
                             Local process index: 2                                                                                                                                           
                             Device: cuda:2                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                                                                                                                                                                                              
[05/08/23 18:40:05] INFO     [4/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 4                                                                                                                                                 
                             Local process index: 4                                                                                                                                           
                             Device: cuda:4                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                                                                                                                                                                                              
[05/08/23 18:40:05] INFO     [3/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 3                                                                                                                                                 
                             Local process index: 3                                                                                                                                           
                             Device: cuda:3                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                                                                                                                                                                                              
[05/08/23 18:40:05] INFO     [6/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 6                                                                                                                                                 
                             Local process index: 6                                                                                                                                           
                             Device: cuda:6                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                                                                                                                                                                                              
[05/08/23 18:40:05] INFO     [1/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 1                                                                                                                                                 
                             Local process index: 1                                                                                                                                           
                             Device: cuda:1                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                                                                                                                                                                                              
[05/08/23 18:40:05] INFO     [7/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 7                                                                                                                                                 
                             Local process index: 7                                                                                                                                           
                             Device: cuda:7                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                                                                                                                                                                                              
[05/08/23 18:40:05] INFO     [0/8] __main__ - Distributed environment: MULTI_GPU  Backend: nccl                                                                                  logging.py:47
                             Num processes: 8                                                                                                                                                 
                             Process index: 0                                                                                                                                                 
                             Local process index: 0                                                                                                                                           
                             Device: cuda:0                                                                                                                                                   
                                                                                                                                                                                              
                             Mixed precision type: fp16                                                                                                                                       
                                                                                                                                                                                              
[05/08/23 18:40:07] WARNING  [0/8] datasets.builder - Found cached dataset wikitext                                                                                             builder.py:817
                             (/milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)                     
[05/08/23 18:40:08] WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110
                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      
                             cache-1b4e61c4f1ef8b68_*_of_00008.arrow                                                                                                                          
[05/08/23 18:40:09] WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110
                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      
                             cache-329331b01bd0468e_*_of_00008.arrow                                                                                                                          
                    WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110
                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      
                             cache-c60b625823abbe78_*_of_00008.arrow                                                                                                                          
                    WARNING  [0/8] __main__ - The tokenizer picked seems to have a very large `model_max_length` (1000000000000000019884624838656). Picking 1024 instead. You    logging.py:47
                             can change that default value by passing --block_size xxx.                                                                                                       
                    WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110
                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      
                             cache-87a845baeb5292f0_*_of_00008.arrow                                                                                                                          
[05/08/23 18:40:10] WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110
                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      
                             cache-23b43495f74434f7_*_of_00008.arrow                                                                                                                          
                    WARNING  [0/8] datasets.arrow_dataset - Loading cached processed dataset at                                                                          arrow_dataset.py:3110
                             /milabench/envs/cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/                      
                             cache-7649aa6a833efa01_*_of_00008.arrow                                                                                                                          
[05/08/23 18:40:27] INFO     [0/8] __main__ - ***** Running training *****                                                                                                       logging.py:47
                    INFO     [0/8] __main__ -   Num examples = 115910                                                                                                            logging.py:47
                    INFO     [0/8] __main__ -   Num Epochs = 1                                                                                                                   logging.py:47
                    INFO     [0/8] __main__ -   Instantaneous batch size per device = 1                                                                                          logging.py:47
                    INFO     [0/8] __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8                                                             logging.py:47
                    INFO     [0/8] __main__ -   Gradient Accumulation steps = 1                                                                                                  logging.py:47
                    INFO     [0/8] __main__ -   Total optimization steps = 100                                                                                                   logging.py:47
[05/08/23 18:40:28] INFO     [0/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140
[05/08/23 18:40:28] INFO     [3/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140
[05/08/23 18:40:28] INFO     [2/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140
[05/08/23 18:40:28] INFO     [5/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140
[05/08/23 18:40:28] INFO     [7/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140
[05/08/23 18:40:28] INFO     [6/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140
[05/08/23 18:40:28] INFO     [4/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140
[05/08/23 18:40:28] INFO     [1/8] torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.                                                    distributed.py:1140
