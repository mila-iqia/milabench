defaults: &defaults
  dirs:
    code: code/{name}
    venv: venv/{name}
    data: data
    runs: runs

  venv:
    type: virtualenv

  voir:
    --forward:
      - "#stdout"
      - "#stderr"
      - "#end"
      - loss
      - compute_rate
      - train_rate
      - loading_rate
      - gpudata
      - gpu_time
      - cpu_dispatch_time
      - cpu_walltime
      - tflops
    # --loading-rate: true
    --poll-gpu: 10

#
# Environments
#
torchvision: &torchvision
  <<<: *defaults

  group: torchvision
  install_group: torchvision

  dirs:
    code: code/torchvision
    venv: venv/torchvision

  plan:
    method: per_gpu

  voir:
    --stop: 120
    --metric: step
    --metric-interval: 1s
    --metric-skip: 10s

  argv:
    --with-amp: true
    --lr: 0.01

  definition: ../benchmarks/torchvision


torchbench: &torchbench
  <<<: *defaults

  group: torchbench

  dirs:
    code: code/torchbench
    venv: venv/torchbench

  plan:
    method: per_gpu

  definition: ../benchmarks/torchbench

  pip:
    constraints:
      - gym < 0.26.0

  voir:
    --stop: 120
    --metric: step
    --metric-interval: 1s
    --metric-skip: 10s

  argv:
    -d: cuda
    -m: eager
    -t: train


lightning: &lightning
  <<<: *defaults

  group: lightning
  install_group: lightning

  dirs:
    code: code/lightning
    venv: venv/lightning

  plan:
    method: njobs
    n: 1

  voir:
    --metric: wrap
    --metric-interval: 1
    --metric-skip: 1

  definition: ../benchmarks/pytorch-lightning

  argv:
    --max_epochs: 1
    --max_steps: 100
    --limit_val_batches: 100
    --devices: -1
    --enable_progress_bar: "False"
    --accelerator: "auto"
    --enable_checkpointing: "False"


sb3: &sb3
    <<<: *defaults

    group: sb3
    install_group: sb3

    dirs:
      code: code/sb3
      venv: venv/sb3

    definition: ../benchmarks/stable_baselines3
    
    plan:
      method: per_gpu

    voir:
      --stop: 20
      --metric: wrap
      --metric-interval: 100
      --metric-skip: 100


#
# Benchmarks
#
benchmarks:
  resnet50-fp16:
    <<<: *torchvision

    mem:
      slope: 82
      intercept: 2728
      multiple: 32

    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: resnet50
      --batch-size: $(bs(gpu, mem, default=512))
      --with-amp: True

  resnet50-fp32:
    <<<: *torchvision

    mem:
      slope: 90
      intercept: 2985
      multiple: 32

    tags:
      - vision
      - classification
      - cnn
      - fp32
      - e2e

    argv:
      --model: resnet50
      --batch-size: $(bs(gpu, mem, default=256))
      --with-amp: null

  squeezenet1_1:
    <<<: *torchvision
    
    mem:
      slope: 19
      intercept: 3166
      multiple: 32

    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e
    
    # Memory capped at 22810.75
    argv:
      --model: squeezenet1_1
      --batch-size: $(bs(gpu, mem, default=256))

  efficientnet_b0:
    <<<: *torchvision
      
    mem:
      slope: 47
      intercept: 2570
      multiple: 32
      
    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: efficientnet_b0
      --batch-size: $(bs(gpu, mem, default=256))

  efficientnet_b4:
    <<<: *torchvision
    
    mem:
      slope: 115
      intercept: 2765
      multiple: 32

    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: efficientnet_b4
      --batch-size: $(bs(gpu, mem, default=256))

  efficientnet_b7:
    <<<: *torchvision
    
    mem:
      slope: 264
      intercept: 3236
      multiple: 32
      
    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: efficientnet_b7
      --batch-size: $(bs(gpu, mem, default=64))

  convnext_large:
    <<<: *torchvision
    mem:
      slope: 190
      intercept: 4090
      multiple: 32
    
    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: convnext_large
      --batch-size: $(bs(gpu, mem, default=256))

  regnet_y_128gf:
    <<<: *torchvision

    mem:
      slope: 826
      intercept: 5290
      multiple: 32
    
    tags:
      - vision
      - classification
      - cnn
      - fp32
      - lstm
      - e2e

    argv:
      --model: regnet_y_128gf
      --batch-size: $(bs(gpu, mem, default=32))
      --with-amp: null

  bert:
    <<<: *torchbench
    tags:
      - nlp
      - language-modeling
      - transformer
      - no-io

    mem:
      slope: 178
      intercept: 3774
      multiple: 8
    
    model: BERT_pytorch
    argv:
      -d: cuda
      -m: eager
      -t: train
      --bs: $(bs(gpu, mem, default=16))

  hf_reformer:
    <<<: *torchbench
    tags:
      - nlp
      - language-modeling
      - transformer
      - huggingface
      - no-io

    mem:
      slope: 385
      intercept: 1464
      multiple: 8
  
    model: hf_Reformer
    argv:
      -d: cuda
      -m: eager
      -t: train
      --bs: $(bs(gpu, mem, default=16))

  hf_t5:
    <<<: *torchbench

    tags:
      - nlp
      - language_modeling
      - transformer
      - huggingface
      - no-io

    mem:
      slope: 2683
      intercept: 1916
      multiple: 8
    
    model: hf_T5
    argv:
      -d: cuda
      -m: eager
      -t: train
      --bs: $(bs(gpu, mem, default=16))

  dlrm:
    <<<: *torchbench

    tags:
      - recommendation
      - mlp
    
    model: dlrm
    # argv:
    #   Batch size here has no impact
    #   --bs: 4096
  
  soft_actor_critic:
    <<<: *torchbench
    tags:
      - rl
      - mlp

    model: soft_actor_critic

  speech_transformer:
    <<<: *torchbench
    tags:
      - speech
      - recognition
      - transformer
    
    model: speech_transformer
    argv:
      -d: cuda
      -m: eager
      -t: train
      #   Batch size here has no impact
      # --bs: 1

  super_slomo:
    <<<: *torchbench

    tags:
      - vision
      - video_interpolation
      - unetcnn

    mem:
      slope: 251
      intercept: 7738
      multiple: 32

    # memory usage is capped to 11762.75
    model: Super_SloMo
    argv:
      -d: cuda
      -m: eager
      -t: train
      --bs: $(bs(gpu, mem, default=12))

  stargan:
    <<<: *torchbench
    tags:
      - vision
      - gan
      - resnet

    model: pytorch_stargan

  # cyclegan:
  #   <<<: *torchbench

  #   plan:
  #     method: njobs
  #     n: 1

  #   model: pytorch_CycleGAN_and_pix2pix

  learning_to_paint:
    <<<: *torchbench
    tags:
      - rl
      - resnet
    
    model: LearningToPaint

  ppo:
    <<<: *sb3
    tags:
      - rl

    plan:
      method: njobs
      n: 1

    argv:
      --algo: ppo
      --env: HalfCheetahBulletEnv-v0
      -n: '-1'
      --num-threads: '-1'
      --seed: '0'
      --vec-env: subproc
      --device: auto
      --: [-params, n_envs:16, n_steps:512, n_epochs:20, n_timesteps:50000]

  td3:
    <<<: *sb3
    tags:
      - rl

    argv:
      --algo: td3
      --env: HalfCheetahBulletEnv-v0 # Default: CartPole-v1
        -n: '-1'
      --num-threads: '-1'
      --n-eval-envs: '1'
      --n-timesteps: '50000' # Default: '-1'
      --num-threads: '-1'
      --log-interval: '-1'
      --eval-episodes: '5'
      --save-freq: '-1'
      --seed: '0' # Default: -1
      --vec-env: subproc # Default: dummy
      --device: auto
      --n-trials: '10' # Default: 500
      --n-jobs: '1'

  resnet152:
    <<<: *lightning
    tags:
      - vision
      - classification
      - cnn

    mem:
      slope: 4.23
      intercept: 3323
      multiple: 32
    
    argv:
      --devices: -1
      --backbone: "resnet152"
      --strategy: "dp"
      --precision: 32
      --max_epochs: 100
      --max_steps: 1000
      --batch_size: $(bs(gpu, mem, default=12, multi_gpu=True))

  vit_l_32:
    <<<: *lightning
    tags:
      - vision
      - classification
      - transformer

    argv:
      --backbone: "vit_l_32"  # (larger model)
      --strategy: "fsdp"  # Fully-Sharded Data-Parallel
      --precision: 32
      # This benchmark is hanging with 8 GPUs
