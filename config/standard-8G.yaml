defaults: &defaults
  dirs:
    code: code/{name}
    venv: venv/{name}
    data: data
    runs: runs

  venv:
    type: virtualenv

  voir:
    --forward:
      - "#stdout"
      - "#stderr"
      - "#end"
      - loss
      - compute_rate
      - train_rate
      - loading_rate
      - gpudata
      - gpu_time
      - cpu_dispatch_time
      - cpu_walltime
      - tflops
    # --loading-rate: true
    --poll-gpu: 10


torchvision: &torchvision
  <<<: *defaults

  group: torchvision
  install_group: torchvision

  dirs:
    code: code/torchvision
    venv: venv/torchvision

  plan:
    method: per_gpu

  voir:
    --stop: 30
    --metric: step
    --metric-interval: 1s
    --metric-skip: 5s

  argv:
    --with-amp: true
    --lr: 0.01

  definition: ../benchmarks/torchvision


torchbench: &torchbench
  <<<: *defaults

  group: torchbench

  dirs:
    code: code/torchbench
    venv: venv/torchbench

  plan:
    method: per_gpu

  definition: ../benchmarks/torchbench

  voir:
    --metric: step
    --metric-interval: 1
    --metric-skip: 9

  argv:
    -d: cuda
    -m: eager
    -t: train


lightning: &lightning
  <<<: *defaults

  group: lightning
  install_group: lightning

  dirs:
    code: code/lightning
    venv: venv/lightning

  plan:
    method: njobs
    n: 1

  voir:
    --metric: wrap
    --metric-interval: 1
    --metric-skip: 1

  definition: ../benchmarks/pytorch-lightning

  argv:
    --gpus: -1
    --max_epochs: 1
    --max_steps: 100
    --limit_val_batches: 100
    --devices: -1
    --enable_progress_bar: "False"
    --accelerator: "auto"
    --enable_checkpointing: "False"


benchmarks:
  resnet50:
    <<<: *torchvision
    argv:
      --model: resnet50
      --batch-size: 32

  squeezenet1_1:
    <<<: *torchvision
    argv:
      --model: squeezenet1_1

  efficientnet_b0:
    <<<: *torchvision
    argv:
      --model: efficientnet_b0
      --batch-size: 32

  efficientnet_b4:
    <<<: *torchvision
    argv:
      --model: efficientnet_b4
      --batch-size: 16

  efficientnet_b7:
    <<<: *torchvision
    argv:
      --model: efficientnet_b7
      --batch-size: 8

  convnext_large:
    <<<: *torchvision
    argv:
      --model: convnext_large
      --batch-size: 16

  # regnet_y_128gf:
  #   <<<: *torchvision
  #   argv:
  #     --model: regnet_y_128gf
  #     --batch-size: 4

  bert:
    <<<: *torchbench

    model: BERT_pytorch

  hf_reformer:
    <<<: *torchbench

    model: hf_Reformer

  # hf_t5:
  #   <<<: *torchbench

  #   model: hf_T5

  dlrm:
    <<<: *torchbench

    model: dlrm

  soft_actor_critic:
    <<<: *torchbench

    model: soft_actor_critic

  speech_transformer:
    <<<: *torchbench

    model: speech_transformer

  super_slomo:
    <<<: *torchbench

    model: Super_SloMo

  # stargan:
  #   <<<: *torchbench

  #   model: pytorch_stargan

  learning_to_paint:
    <<<: *torchbench

    model: LearningToPaint

  ppo:
    <<<: *defaults

    definition: ../benchmarks/stable_baselines3
    venv:
      type: conda

    plan:
      method: njobs
      n: 1

    voir:
      --stop: 20
      --metric: step
      --metric-interval: 100
      --metric-skip: 100

    argv:
      - --algo
      - ppo
      - --env
      - HalfCheetahBulletEnv-v0
      - -n
      - '-1'
      - --num-threads
      - '-1'
      - --seed
      - '0'
      - --vec-env
      - subproc
      - --device
      - auto
      - -params
      - n_envs:16
      - n_steps:512
      - n_epochs:20
      - n_timesteps:50000

  resnet152:
    <<<: *lightning
    argv:
      --backbone: "resnet152"
      --strategy: "dp"
      --precision: 32
      --batch_size: 2048

  vit_l_32:
    <<<: *lightning
    argv:
      --backbone: "vit_l_32"  # (larger model)
      --strategy: "fsdp"  # Fully-Sharded Data-Parallel
      --precision: 32
