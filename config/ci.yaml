defaults: &defaults
  install_variant: "{arch}"

  max_duration: 600

  voir:
    options:
      skip: 1
      stop: 10
      interval: "1s"


torchvision: &torchvision
  <<<: *defaults

  group: torchvision
  install_group: torch

  plan:
    method: per_gpu

  argv:
    --with-amp: true
    --lr: 0.01

  definition: ../benchmarks/torchvision


hf: &hf
  <<<: *defaults

  group: hf
  install_group: torch

  plan:
    method: per_gpu

  tags:
    - rl

  definition: ../benchmarks/huggingface


lightning: &lightning
  <<<: *defaults

  group: lightning
  install_group: torch

  plan:
    method: njobs
    n: 1

  definition: ../benchmarks/pytorch-lightning

  argv:
    --gpus: -1
    --max_epochs: 1
    --max_steps: 100
    --limit_val_batches: 100
    --devices: -1
    --enable_progress_bar: "False"
    --accelerator: "auto"
    --enable_checkpointing: "False"


benchmarks:
  resnet50:
    <<<: *torchvision
    tags:
      - convnet

    argv:
      --model: resnet50

  efficientnet_b4:
    <<<: *torchvision
    tags:
      - convnet
    
    argv:
      --model: efficientnet_b4
      --batch-size: 32

  efficientnet_b7:
    <<<: *torchvision
    tags:
      - convnet
    
    argv:
      --model: efficientnet_b7
      --batch-size: 32

  convnext_large:
    <<<: *torchvision
    tags:
      - convnet

    argv:
      --model: convnext_large
      --batch-size: 16

  regnet_y_128gf:
    <<<: *torchvision
    tags:
      - convnet

    argv:
      --model: regnet_y_128gf
      --batch-size: 4

  bert:
    <<<: *hf
    tags:
      - huggingface
      - transformer
    argv:
      --model: "Bert"
      --batch-size: 8

  t5:
    <<<: *hf
    tags:
      - huggingface
      - transformer
    argv:
      --model: "T5"
      --batch-size: 2

  reformer:
    <<<: *hf
    tags:
      - huggingface
      - transformer
    argv:
      --model: "Reformer"

  resnet152:
    <<<: *lightning
    tags:
      - convnet
      - no-rocm

    argv:
      --backbone: "resnet152"
      --strategy: "dp"
      --precision: 32
      --batch_size: 2048

  accelerate:
    <<<: *defaults

    install_group: torch

    plan:
      method: njobs
      n: 1

    # This is for single-node
    manager_addr: "127.0.0.1"
    manager_port: 10000

    num_processes: 2
    cpus_per_gpu: 8

    model_name: "facebook/bart-base"

    gradient_accumulation_steps: 1
    per_gpu_batch_size: 1
    max_train_steps: 5

    dataset_name: "wikitext"
    dataset_config_name: "wikitext-103-v1"
    validation_split_percentage: 5

    definition: ../benchmarks/accelerate_opt
