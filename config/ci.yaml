defaults: &defaults
  install_variant: "{arch}"

  max_duration: 600

  voir:
    options:
      skip: 1
      stop: 10
      interval: "1s"


torchvision: &torchvision
  <<<: *defaults

  group: torchvision
  install_group: torch

  plan:
    method: per_gpu

  argv:
    --with-amp: true
    --lr: 0.01

  definition: ../benchmarks/torchvision


hf: &hf
  <<<: *defaults

  group: hf
  install_group: torch

  plan:
    method: per_gpu

  definition: ../benchmarks/huggingface


lightning: &lightning
  <<<: *defaults

  group: lightning
  install_group: torch

  plan:
    method: njobs
    n: 1

  definition: ../benchmarks/pytorch-lightning

  argv:
    --gpus: -1
    --max_epochs: 1
    --max_steps: 100
    --limit_val_batches: 100
    --devices: -1
    --enable_progress_bar: "False"
    --accelerator: "auto"
    --enable_checkpointing: "False"


benchmarks:
  resnet50-fp16:
    <<<: *torchvision
    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: resnet50
      --with-amp: True

    mem:
      slope: 82
      intercept: 2728
      multiple: 16

  resnet50-fp32:
    <<<: *torchvision
    tags:
      - vision
      - classification
      - cnn
      - fp32
      - e2e

    argv:
      --model: resnet50
      --with-amp: null

    mem:
      slope: 90
      intercept: 2985
      multiple: 16
  
  efficientnet_b4:
    <<<: *torchvision
    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: efficientnet_b4
      --batch-size: $(bs(gpu, mem, default=32))
    
    mem:
      slope: 115
      intercept: 2765
      multiple: 16

  efficientnet_b7:
    <<<: *torchvision

    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: efficientnet_b7
      --batch-size: $(bs(gpu, mem, default=32))
    
    mem:
      slope: 264
      intercept: 3236
      multiple: 16
  
  convnext_large:
    <<<: *torchvision
    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: convnext_large
      --batch-size: $(bs(gpu, mem, default=16))
  
    mem:
      slope: 190
      intercept: 4090
      multiple: 16
  
  regnet_y_128gf:
    <<<: *torchvision

    tags:
      - vision
      - classification
      - cnn
      - fp32
      - lstm
      - e2e

    argv:
      --model: regnet_y_128gf
      --batch-size: $(bs(gpu, mem, default=4))
      --with-amp: null
  
    mem:
      slope: 826
      intercept: 5290
      multiple: 16
  
  bert:
    <<<: *hf
    tags:
      - nlp
      - language-modeling
      - transformer
      - no-io
      - huggingface
  
    argv:
      --model: "Bert"
      --batch-size: $(bs(gpu, mem, default=8))
    
    mem:
      slope: 1000
      intercept: 3774
      multiple: 8

  t5:
    <<<: *hf
    tags:
      - nlp
      - language_modeling
      - transformer
      - huggingface
      - no-io

    argv:
      --model: "T5"
      --batch-size: $(bs(gpu, mem, default=2))
  
    mem:
      slope: 2683
      intercept: 1916
      multiple: 8

  reformer:
    <<<: *hf
    tags:
      - nlp
      - language-modeling
      - transformer
      - huggingface
      - no-io
  
    argv:
      --model: "Reformer"
      --batch-size: $(bs(gpu, mem, default=8))

    mem:
      slope: 385
      intercept: 1464
      multiple: 8
  
  resnet152:
    <<<: *lightning
    tags:
      - vision
      - classification
      - convnet
      - no-rocm

    argv:
      --backbone: "resnet152"
      --strategy: "dp"
      --precision: 32
      --batch_size: $(bs(gpu, mem, default=12, multi_gpu=True))
  
    mem:
      slope: 4.23
      intercept: 3323
      multiple: 16
  
  accelerate:
    <<<: *defaults

    install_group: torch

    plan:
      method: njobs
      n: 1

    # This is for single-node
    manager_addr: "127.0.0.1"
    manager_port: 10000

    num_processes: 2
    cpus_per_gpu: 8

    model_name: "facebook/bart-base"

    gradient_accumulation_steps: 1
    per_gpu_batch_size: 1
    max_train_steps: 5

    dataset_name: "wikitext"
    dataset_config_name: "wikitext-103-v1"
    validation_split_percentage: 5

    definition: ../benchmarks/accelerate_opt
