_defaults:
  max_duration: 600
  voir:
    options:
      stop: 60
      interval: "1s"

  validation:
    usage:
      gpu_load_threshold: 0.5
      gpu_mem_threshold: 0.5

_torchvision:
  inherits: _defaults
  definition: ../benchmarks/torchvision
  group: torchvision
  install_group: torch
  plan:
    method: per_gpu
  argv:
    --precision: 'tf32-fp16'
    --lr: 0.01
    --no-stdout: true
    --epochs: 50
    --num-workers: "auto({n_worker}, 8)"
    --loader: pytorch
    --data: "{milabench_data}/FakeImageNet"


_torchvision_ddp:
  inherits: _defaults
  definition: ../benchmarks/torchvision_ddp
  group: torchvision
  install_group: torch
  plan:
    method: njobs
    n: 1
  argv:
    --epochs: 10
    --num-workers: "auto({n_worker}, 8)"
    --loader: pytorch
    --data: "{milabench_data}/FakeImageNet"

_flops:
  inherits: _defaults
  definition: ../benchmarks/flops
  group: flops
  install_group: torch
  plan:
    method: per_gpu
  
  tags:
    - diagnostic
    - flops
  
  argv:
    --number: 10
    --repeat: 90

llama:
  inherits: _defaults
  definition: ../benchmarks/llama
  group: llm
  install_group: torch
  max_duration: 800
  tags:
    - nlp
    - llm
    - inference

  voir:
    options:
      stop: 30
      interval: "1s"
    
  plan:
    method: per_gpu

  # Note: when NOT using pretrained model
  # the benchmark becomes much harder as no end token is ever outputted by the model
  # which makes inference much slower
  # argv:
  #  --pretrained: true

_hf:
  inherits: _defaults
  definition: ../benchmarks/huggingface
  group: hf
  install_group: torch
  argv:
    --precision: 'tf32-fp16'
    --num-workers: "auto({n_worker}, 8)"

  plan:
    method: per_gpu

_timm:
  inherits: _defaults
  definition: ../benchmarks/timm
  group: timm
  install_group: torch
  tags:
    - timm
  plan:
    method: per_gpu
  argv:
    --amp: true
    --amp-dtype: bfloat16
    --device: '{arch}'
    --val-split: ''
    --data-dir: "{milabench_data}"
    --dataset: "FakeImageNet"
    --workers: "auto({n_worker}, 8)"


_accelerate_opt:
  inherits: _defaults
  tags:
    - nlp
    - language-modeling
    - transformer
    - huggingface
    - llm
  definition: ../benchmarks/accelerate_opt
  group: opt
  install_group: torch
  plan:
    method: njobs
    n: 1
  
  # Accelerate
  # accelerate:
  #   - --mixed_precision=bf16
  #   - --dynamo_backend=no
  #   - --gradient_accumulation_steps=1

  # Script Args
  argv:
    --max_train_steps: 100
    --dataset_name: "wikitext"
    --dataset_config_name: "wikitext-103-v1"
    --dataset_rev: "b08601e"
    --validation_split_percentage: 5
    --per_gpu_batch_size: 1
    --cpus_per_gpu: "auto({n_worker}, 8)"
    --cache: "{milabench_cache}"
    # --model_name: "facebook/opt-2.7b"
    # --model_name: "facebook/opt-1.3b"
    # --model_name: "facebook/opt-350m"
    # --model_name: "facebook/opt-125m"

  # Accelerate Args
  use_deepspeed: true
  num_machines: 1


fp16:
  inherits: _flops

  argv:
    --number: 30
    --repeat: 90
    --m: 8192
    --n: 8192
    --dtype: fp16


bf16:
  inherits: _flops
 
  argv:
    --m: 8192
    --n: 8192
    --dtype: bf16

tf32:
  inherits: _flops
 
  argv:
    --m: 8192
    --n: 8192
    --dtype: fp32
    --tf32: true

fp32:
  inherits: _flops
 
  argv:
    --m: 8192
    --n: 8192
    --dtype: fp32
  

resnet50:
  inherits: _torchvision
  tags:
    - vision
    - classification
    - convnet
    - resnet
  
  argv:
    --model: resnet50
    --batch-size: 256
    --num-workers: "auto({n_worker}, 8)"
    --loader: pytorch
  
resnet50-noio:
  inherits: _torchvision
  tags:
    - vision
    - classification
    - convnet
    - resnet
    - noio
  
  argv:
    --model: resnet50
    --batch-size: 256
    --loader: synthetic_fixed

resnet152-ddp-gpus:
  inherits: _torchvision_ddp
  tags:
    - vision
    - classification
    - convnet
    - resnet
  
  argv:
    --model: resnet152
    --batch-size: 256
    --num-workers: "auto({n_worker}, 8)"
    --loader: torch

efficientnet_b4:
  inherits: _torchvision

  tags:
    - vision
    - classification
    - convnet

  argv:
    --model: efficientnet_b4
    --batch-size: 256

efficientnet_b7:
  inherits: _torchvision
  tags:
    - vision
    - classification
    - convnet
  argv:
    --model: efficientnet_b7
    --batch-size: 128

_convnext_large-base:
  inherits: _torchvision
  tags:
    - vision
    - classification
    - convnet
    - precision-showcase
  argv:
    --model: convnext_large
    --batch-size: 128
  voir:
    options:
      stop: 30

convnext_large-fp32:
  inherits: _convnext_large-base
  argv:
    --precision: 'fp32'

convnext_large-fp16:
  inherits: _convnext_large-base
  argv:
    --precision: 'fp16'

convnext_large-tf32:
  inherits: _convnext_large-base
  argv:
    --precision: 'tf32'

convnext_large-tf32-fp16:
  inherits: _convnext_large-base
  argv:
    --precision: 'tf32-fp16'

regnet_y_128gf:
  inherits: _torchvision
  tags:
    - vision
    - classification
    - convnet
    - resnet
    - lstm
  argv:
    --model: regnet_y_128gf
    --batch-size: 64

_bert-base:
  inherits: _hf
  tags:
    - nlp
    - language-modeling
    - transformer
    - huggingface
    - precision-showcase
    - noio
  argv:
    --model: "Bert"
    --batch-size: 32
  voir:
    options:
      stop: 30

bert-fp32:
  inherits: _bert-base
  argv:
    --precision: 'fp32'

bert-fp16:
  inherits: _bert-base
  argv:
    --precision: 'fp16'

bert-tf32:
  inherits: _bert-base
  argv:
    --precision: 'tf32'

bert-tf32-fp16:
  inherits: _bert-base
  argv:
    --precision: 'tf32-fp16'

t5:
  inherits: _hf
  tags:
    - nlp
    - language-modeling
    - transformer
    - huggingface
    - noio
  argv:
    --model: "T5"
    --batch-size: 16

reformer:
  inherits: _hf
  tags:
    - nlp
    - language-modeling
    - transformer
    - huggingface
    - noio
  argv:
    --model: "Reformer"
    --batch-size: 64

whisper:
  inherits: _hf
  tags:
    - audio
    - huggingface
    - noio
  argv:
    --model: "Whisper"
    --batch-size: 64

resnet152:
  inherits: _timm
  tags:
    - vision
    - classification
    - convnet
    - resnet
  plan:
    method: per_gpu
  argv:
    --model: resnet152
    --batch-size: 256

resnet152-gpus:
  inherits: resnet152
  tags:
    - multigpu
  plan:
    method: njobs
    n: 1

vit_l_32:
  inherits: _timm
  tags:
    - vision
    - classification
    - transformer
    - multigpu

  plan:
    method: njobs
    n: 1
  argv:
    --model: vit_large_patch32_224
    --batch-size: 256

davit_large:
  inherits: _timm
  tags:
    - vision
    - classification
    - transformer
  plan:
    method: per_gpu
  argv:
    --model: davit_large
    --batch-size: 128
    --lr-base: 0.01

davit_large-gpus:
  inherits: davit_large
  tags:
    - multigpu
  plan:
    method: njobs
    n: 1

focalnet:
  inherits: _timm
  tags:
    - vision
    - classification
    - convnet
  plan:
    method: per_gpu
  argv:
    --model: focalnet_base_lrf

opt-1_3b-gpus:
  inherits: _accelerate_opt
  tags:
    - multigpu
  
  argv:
    --model_name: "facebook/opt-1.3b"
    --per_gpu_batch_size: 1

  use_deepspeed: false
  num_machines: 1

opt-1_3b-nodes:
  inherits: opt-1_3b-gpus

  tags:
    - multinode
  requires_capabilities:
    - "len(nodes) >= ${num_machines}"

  docker_image: "ghcr.io/mila-iqia/milabench:cuda-nightly"
  num_machines: 2

opt-6_7b-gpus:
  inherits: _accelerate_opt
  tags:
    - multigpu

  argv:
    --model_name: "facebook/opt-6.7b"
    --per_gpu_batch_size: 1

  num_machines: 1

opt-6_7b-nodes:
  inherits: opt-6_7b-gpus
  tags:
    - multinode

  requires_capabilities:
    - "len(nodes) >= ${num_machines}"

  docker_image: "ghcr.io/mila-iqia/milabench:cuda-nightly"
  num_machines: 2

stargan:
  inherits: _defaults
  tags:
    - vision
    - gan
    - resnet
    - noio
  definition: ../benchmarks/stargan
  group: stargan
  install_group: torch
  plan:
    method: per_gpu
  argv:
    --image_size: 512
    --c_dim: 5
    --batch_size: 16
    --dataset: "synth"
    --celeba_image_dir: "{milabench_data}"
    --log_dir: "{milabench_extra}/logs"
    --model_save_dir: "{milabench_extra}/models"
    --sample_dir: "{milabench_extra}/samples"
    --result_dir: "{milabench_extra}/results"
    --num_workers: "auto({n_worker}, 8)"

super-slomo:
  inherits: _defaults
  tags:
    - vision
    - video-interpolation
    - unet
    - convnet
  definition: ../benchmarks/super-slomo
  group: super-slomo
  install_group: torch
  plan:
    method: per_gpu
  argv:
    --train_batch_size: 64
    --dataset_root: "{milabench_data}/FakeImageNet"
    --loader: pytorch
    --num_workers: "auto({n_worker}, 8)"


dlrm:
  inherits: _defaults
  tags:
    - nlp
    - rl
    
  definition: ../benchmarks/dlrm
  group: dlrm
  install_group: torch
  plan:
    method: njobs
    n: 1
  argv:
    --num-batches: 1000
    --data-generation: "random"
    --arch-mlp-bot: "512-512-64"
    --arch-mlp-top: "1024-1024-1024-1"
    --arch-sparse-feature-size: 64
    --arch-embedding-size: "1000000-1000000-1000000-1000000-1000000-1000000-1000000-1000000"
    --num-indices-per-lookup: 100
    --arch-interaction-op: "dot"
    --numpy-rand-seed: "727"
    --print-freq: 999999
    --mini-batch-size: 16384
    --test-mini-batch-size: 16384
    --test-num-workers: 0
    --use-gpu: true
    --num-workers: "auto({n_worker}, 8)"

rwkv:
  inherits: _defaults
  definition: ../benchmarks/rwkv
  group: rwkv
  install_group: torch
  tags:
    - llm
    - rnn
    - unsupported-rocm
  plan:
    method: per_gpu
  argv:
    --data_type: "dummy"
    --ctx_len: 128
    --epoch_steps: 1000
    --epoch_count: 20
    --epoch_begin: 0
    --epoch_save: 0
    --micro_bsz: 16
    --n_layer: 12
    --n_embd: 768
    --pre_ffn: 0
    --head_qk: 0
    --lr_init: 6e-4
    --lr_final: 1e-5
    --warmup_steps: 0
    --beta1: 0.9
    --beta2: 0.99
    --adam_eps: 1e-8
    --accelerator: "gpu"
    --devices: 1
    --precision: "tf32"
    --strategy: "ddp_find_unused_parameters_false"
    --grad_cp: 0
    --random_seed: 1234
    --enable_progress_bar: "False"

brax:
  inherits: _defaults
  tags:
    - rl
    - jax
  definition: ../benchmarks/brax
  group: brax
  install_group: torch
  plan:
    method: njobs
    n: 1
  argv:
    --episode-length: 20
    --batch-size: 1024
    --num-minibatches: 32
    --num-envs: 8192


_diffusion:
  inherits: _defaults
  definition: ../benchmarks/diffusion
  install_group: torch

  argv:
    --num_epochs: 5
    --batch_size: 32
    --num_workers: "auto({n_worker}, 8)"

diffusion-gpus:
  inherits: _diffusion

  num_machines: 1
  plan:
    method: njobs
    n: 1


_lightning:
  inherits: _defaults
  definition: ../benchmarks/lightning
  install_group: torch
  argv:
    --epochs: 10
    --num-workers: "auto({n_worker}, 8)"
    --loader: pytorch
    --data: "{milabench_data}/FakeImageNet"
    --model: resnet152
    --batch-size: 16

lightning:
  inherits: _lightning
  num_machines: 1
  plan:
    method: per_gpu

lightning-gpus:
  inherits: _lightning
  num_machines: 1
  plan:
    method: njobs
    n: 1

_dinov2:
  inherits: _defaults
  definition: ../benchmarks/dinov2
  install_group: torch
  plan:
    method: njobs
    n: 1

  argv:
    --output-dir: "{milabench_extra}/output"
    --no-resume: true


dinov2-giant-gpus:
  inherits: _dinov2
  argv:
    --config-file: src/dinov2/configs/train/vitg14.yaml
    # THOSE NEED TO BE LAST
    train.dataset_path=ImageNet:split=TRAIN:root={milabench_data}/FakeImageNet:extra={milabench_data}/FakeImageNet: true
    train.batch_size_per_gpu=32: true
    train.saveckp_freq=100: true
    train.num_workers=10: true
