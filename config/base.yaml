_defaults:
  install_variant: "${arch}"
  max_duration: 600
  voir:
    options:
      stop: 60
      interval: "1s"

_torchvision:
  inherits: _defaults
  definition: ../benchmarks/torchvision
  group: torchvision
  install_group: torch
  plan:
    method: per_gpu
  argv:
    --with-amp: true
    --lr: 0.01
    --no-stdout: true
    --epochs: 50

_hf:
  inherits: _defaults
  definition: ../benchmarks/huggingface
  group: hf
  install_group: torch
  argv:
    --precision: 'tf32'

  plan:
    method: per_gpu

_timm:
  inherits: _defaults
  definition: ../benchmarks/timm
  group: timm
  install_group: torch
  plan:
    method: per_gpu
  argv:
    --amp: true

_sb3:
  inherits: _defaults
  definition: ../benchmarks/stable_baselines3
  group: sb3
  plan:
    method: njobs
    n: 1

resnet50:
  inherits: _torchvision
  tags:
    - vision
    - classification
    - convnet
    - resnet
  
  argv:
    --model: resnet50
    --batch-size: 64

efficientnet_b4:
  inherits: _torchvision
  tags:
  tags:
    - vision
    - classification
    - convnet

  argv:
    --model: efficientnet_b4
    --batch-size: 256

efficientnet_b7:
  inherits: _torchvision
  tags:
    - vision
    - classification
    - convnet
  argv:
    --model: efficientnet_b7
    --batch-size: 128

convnext_large:
  inherits: _torchvision
  tags:
    - vision
    - classification
    - convnet
  argv:
    --model: convnext_large
    --batch-size: 128

regnet_y_128gf:
  inherits: _torchvision
  tags:
    - vision
    - classification
    - convnet
    - resnet
    - lstm
  argv:
    --model: regnet_y_128gf
    --batch-size: 64

_precision-showcase:
  inherits: _hf
  tags:
    - showcase
  argv:
    --model: "Bert"
    --batch-size: 32
  voir:
    options:
      stop: 20

bert-fp32:
  inherits: _precision-showcase
  argv:
    --precision: 'fp32'

bert-fp16:
  inherits: _precision-showcase
  argv:
    --precision: 'fp16'

bert-tf32:
  inherits: _precision-showcase
  argv:
    --precision: 'tf32'

bert-tf32-fp16:
  inherits: _precision-showcase
  argv:
    --precision: 'tf32-fp16'

t5:
  inherits: _hf
  tags:
    - nlp
    - language-modeling
    - transformer
    - huggingface
  argv:
    --model: "T5"
    --batch-size: 16

reformer:
  inherits: _hf
  tags:
    - nlp
    - language-modeling
    - transformer
    - huggingface
  argv:
    --model: "Reformer"
    --batch-size: 64

whisper:
  inherits: _hf
  tags:
    - audio
    - huggingface
  argv:
    --model: "Whisper"
    --batch-size: 64

resnet152:
  inherits: _timm
  tags:
    - vision
    - classification
    - convnet
    - resnet
    - multigpu

  plan:
    method: njobs
    n: 1
  argv:
    --model: resnet152
    --batch-size: 256

vit_l_32:
  inherits: _timm
  tags:
    - vision
    - classification
    - transformer
    - multigpu

  plan:
    method: njobs
    n: 1
  argv:
    --model: vit_large_patch32_224
    --batch-size: 256

davit_large:
  inherits: _timm
  tags:
    - vision
    - classification
    - transformer
    - multigpu

  plan:
    method: njobs
    n: 1
  argv:
    --model: davit_large
    --batch-size: 128

focalnet:
  inherits: _timm
  tags:
    - vision
    - classification
    - convnet
  plan:
    method: per_gpu
  argv:
    --model: focalnet_small_lrf

opt-2_7b:
  inherits: _defaults
  tags:
    - nlp
    - language-modeling
    - transformer
    - huggingface
    - llm
    - multigpu

  definition: ../benchmarks/accelerate_opt
  install_group: torch
  plan:
    method: njobs
    n: 1
  # This is for single-node
  manager_addr: "127.0.0.1"
  manager_port: 10000
  cpus_per_gpu: 8
  model_name: "facebook/opt-2.7b"
  # model_name: "facebook/opt-1.3b"
  # model_name: "facebook/opt-350m"
  # model_name: "facebook/opt-125m"
  gradient_accumulation_steps: 1
  per_gpu_batch_size: 1
  max_train_steps: 100
  dataset_name: "wikitext"
  dataset_config_name: "wikitext-103-v1"
  validation_split_percentage: 5
  num_machines: 1

opt-2_7b-2nodes:
  inherits: opt-2_7b
  tags:
    - multinode
  plan:
    method: njobs
    n: 1

  requires_capabilities:
    - "nodes >= 2"

  docker_image: "ghcr.io/mila-iqia/milabench:cuda-nightly"
  num_machines: 2
  gradient_accumulation_steps: 1
  per_gpu_batch_size: 4

stargan:
  inherits: _defaults
  tags:
    - vision
    - gan
    - resnet
  definition: ../benchmarks/stargan
  group: stargan
  install_group: torch
  plan:
    method: per_gpu
  argv:
    --image_size: 512
    --c_dim: 5
    --batch_size: 16

super-slomo:
  inherits: _defaults
  tags:
    - vision
    - video-interpolation
    - unet
    - convnet
  definition: ../benchmarks/super-slomo
  group: super-slomo
  install_group: torch
  plan:
    method: per_gpu
  argv:
    --train_batch_size: 32

ppo:
  inherits: _sb3
  tags:
    - rl

  argv:
    --algo: ppo
    --env: HalfCheetahBulletEnv-v0
    -n: '-1'
    --num-threads: '-1'
    --seed: '0'
    --vec-env: subproc
    --device: auto
    --: [-params, n_envs:16, n_steps:512, n_epochs:20, n_timesteps:50000]

td3:
  inherits: _sb3
  tags:
    - rl

  argv:
    --algo: td3
    --env: HalfCheetahBulletEnv-v0 # Default: CartPole-v1
    --n-eval-envs: '1'
    --n-timesteps: '50000' # Default: '-1'
    --num-threads: '-1'
    --log-interval: '-1'
    --eval-episodes: '5'
    --save-freq: '-1'
    --seed: '0' # Default: -1
    --vec-env: subproc # Default: dummy
    --device: auto
    --n-trials: '10' # Default: 500
    --n-jobs: '1'

dlrm:
  inherits: _defaults
  tags:
    - nlp
    - rl
    
  definition: ../benchmarks/dlrm
  group: dlrm
  install_group: torch
  plan:
    method: njobs
    n: 1
  argv:
    --num-batches: 1000
    --data-generation: "random"
    --arch-mlp-bot: "512-512-64"
    --arch-mlp-top: "1024-1024-1024-1"
    --arch-sparse-feature-size: 64
    --arch-embedding-size: "1000000-1000000-1000000-1000000-1000000-1000000-1000000-1000000"
    --num-indices-per-lookup: 100
    --arch-interaction-op: "dot"
    --numpy-rand-seed: "727"
    --print-freq: 999999
    --enable-profiling: true
    --mini-batch-size: 16384
    --test-mini-batch-size: 16384
    --test-num-workers: 0
    --use-gpu: true
